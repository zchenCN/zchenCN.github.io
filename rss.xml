<?xml version="1.0" encoding="utf-8"?>






<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>CZ&#39;s Selfpage</title>
        <link>https://zchencn.github.io/</link>
        <description>Notes aboust mathematics and compter science</description>
        <generator>Hugo 0.89.4 https://gohugo.io/</generator>
        
            <language>en</language>
        
        
            <managingEditor>zchen@lsec.ac.cc.cn (zchen)</managingEditor>
        
        
            <webMaster>zchen@lsec.ac.cc.cn (zchen)</webMaster>
        
        
            <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
        
        <lastBuildDate>Sun, 05 Mar 2023 18:03:06 &#43;0800</lastBuildDate>
        
            <atom:link rel="self" type="application/rss&#43;xml" href="https://zchencn.github.io/rss.xml" />
        
        
            <item>
                <title>读史笔记之秦末楚汉</title>
                <link>https://zchencn.github.io/posts/read_history_note_01/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/read_history_note_01/</guid>
                <pubDate>Sun, 05 Mar 2023 17:36:31 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h1 id=&#34;汉&#34;&gt;汉&lt;/h1&gt;
&lt;h1 id=&#34;楚&#34;&gt;楚&lt;/h1&gt;
&lt;h2 id=&#34;项梁&#34;&gt;项梁&lt;/h2&gt;
&lt;h1 id=&#34;秦&#34;&gt;秦&lt;/h1&gt;
&lt;h2 id=&#34;章邯&#34;&gt;章邯&lt;/h2&gt;
&lt;p&gt;二世二年冬，陈王所遣周文等将西至戏，兵数十万。二世大惊，与群臣谋曰：“柰何？”少府章邯曰：“盗已至，众彊，今发近县不及矣。郦山徒多，请赦之，授兵以击之。”二世乃大赦天下，使章邯免骊山徒、人奴产子，悉发以击楚军，大败之。周文走，出关，止屯曹阳，二月余，章邯追败之。复击之渑池，大破之。周文自刎，军遂不战。田臧矫王令诛吴叔，使李归等守荥阳。章邯进兵击李归等荥阳下，破之，杀李归等。阳城人邓说将兵居郯，章邯别将击破之。铚人伍徐（一作伍逢）将兵居许，章邯击破之。两军皆散，走陈，陈王诛邓说。章邯已破伍徐，击陈，柱国房君死。章邯又进兵击陈西张贺军。陈王出监战，军破，张贺死。腊月，陈王之汝阴，还，至下城父，其御庄贾杀陈王以降。&lt;/p&gt;
&lt;p&gt;是时秦将章邯从陈，别将司马（尼）〔[插图]〕[14]将兵北定楚地，屠相，至砀&lt;/p&gt;
&lt;p&gt;陈王初立时，凌人秦嘉、铚人董緤、符离人硃鸡石、取虑人郑布、徐人丁疾等皆特起，将兵围东海守于郯。陈王使武平君畔为将军，监军郯下军。秦嘉自立为大司马，恶属人，因矫王命杀武平君。秦嘉等闻陈王军破出走，乃立景驹为楚王，引兵之方与，欲击秦军定陶下。&lt;/p&gt;
&lt;h1 id=&#34;群雄&#34;&gt;群雄&lt;/h1&gt;
&lt;h2 id=&#34;吴广田臧&#34;&gt;吴广田臧&lt;/h2&gt;
&lt;p&gt;吴广者，字叔，阳夏人也。二世元年七月，陈胜吴广起大泽乡，陈胜自立为将军，吴广为督尉。入据陈，胜乃自立为王，号张楚，以广为假王，监诸将以西击荥阳。吴叔围荥阳，李由为三川守，守荥阳，叔孚能下。田臧等以假王骄，不知兵权，矫陈王令诛吴广，献其守于陈王。陈王赐田臧楚令尹印，使为上将。田臧与章邯战于敖仓，军破，田臧死。&lt;/p&gt;
&lt;h2 id=&#34;周文&#34;&gt;周文&lt;/h2&gt;
&lt;p&gt;周文者，陈之贤人也，尝为项燕军视日，事春申君。时陈王在陈，闻周文贤，习兵，乃与之将军印，使西击秦。行收兵至关，车千乘，卒数十万，至戏，军焉。秦令少府章邯免郦山徒、人奴产子生，悉发以击楚大军，尽败之。周章（名章字文？）出关，止屯曹阳，二月余，章邯追败之。复走渑池，十余日，章邯击，大破之。周文自刎，军遂不战；&lt;/p&gt;
&lt;h2 id=&#34;周巿魏王咎&#34;&gt;周巿魏王咎&lt;/h2&gt;
&lt;p&gt;时陈王在陈，令魏人周巿北徇魏地。周巿徇地至狄，狄城守。狄人田儋杀狄令，自立为齐王，发兵以击周巿。巿军还至魏地，欲立魏咎为魏王。魏咎者，故魏诸公子也，故魏时封为宁陵君，陈胜之起王也，咎往从之。时咎在陈，不得之魏。魏地已定，诸侯皆欲立周巿为魏王。巿曰：“天下昏乱，忠臣乃见。今天下共畔秦，其义必立魏王后乃可。”诸侯固请立巿，巿终辞不受，迎魏咎于陈，五反，陈王乃遣之，立咎为魏王，巿为魏相。后章邯破陈王，进兵击魏王于临济。魏王使周巿出，请救于齐、楚。齐王儋及楚将项它皆将兵随巿救魏。章邯夜衔枚击，大破齐、楚军于临济下，杀齐王及周巿。魏王咎为其民约降，约定，自烧杀。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/%E5%8E%86%E5%8F%B2/">历史</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/%E7%A7%A6%E6%B1%89%E5%8F%B2/">秦汉史</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/%E5%8E%86%E5%8F%B2/">历史</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/%E4%B8%AD%E5%9B%BD%E5%8F%A4%E4%BB%A3%E5%8F%B2/">中国古代史</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>读史笔记之前言</title>
                <link>https://zchencn.github.io/posts/read_history_note_00/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/read_history_note_00/</guid>
                <pubDate>Sun, 05 Mar 2023 17:05:47 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;最近入睡前总是在喜马拉雅上听王立群老师的《读史记之大风歌》，在这之前，我对这段历史的了解除了高中课本上的《鸿门宴》解近乎是空白的。前一两年我阅读的兴趣主要是春秋战国这段时间的历史，沿着时间顺序，正好也差不多到了楚汉风云之际。趁这个机会，我开始阅读《史记》。&lt;/p&gt;
&lt;p&gt;《史记》是中国历史上第一部纪传体通史，全书共一百三十篇，包括十二本纪、十表、八书、三十世家和七十列传。看书先看目录，史记的目录就让我产生了诸多疑惑——为什么既有《秦本纪》，又有《秦始皇本纪》？为什么项羽和吕后不是帝王却有《项羽本纪》和《吕后本纪》？为什么汉惠帝刘盈连单独的传记都没有？等等&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;纪传体史书不像编年体史书，并不是按时间顺序编排的，这有利于完整地叙述一个人的生平经历，然而对于很多相对次要的人物，司马迁没有单独编写传记，而是将他的事迹穿插在相关重要人物的传记中。比如项梁和章邯，一位是秦末起义军的领袖之一，一位是秦国抵抗起义军的大将，他们均没有单独的传记，项梁的事迹大多记叙在《项羽本纪》中，章邯的众多事迹穿插在《陈涉世家》、《项羽本纪》等等篇章中。&lt;/p&gt;
&lt;p&gt;为了更好的梳理历史人物之间的关系和历史事件之间的因果，帮助自己更好地读懂《史记》，我想出一个给小人物编写传记的读书方法。即以《史记》为基础，参考《汉书》和《资治通鉴》，将没有传记的部分人物的事迹整理，略加修改使行文流程，整理成一个“小传”。&lt;/p&gt;
&lt;p&gt;主要有以下几个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zchencn.github.io/posts/read_history_note_01/&#34;&gt;读史笔记之秦末楚汉&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                    
                
            </item>
        
            <item>
                <title>读《失败者的春秋》</title>
                <link>https://zchencn.github.io/posts/readingnotes/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/readingnotes/</guid>
                <pubDate>Sun, 13 Nov 2022 22:19:28 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;脉络&#34;&gt;脉络&lt;/h2&gt;
&lt;h2 id=&#34;新颖的观点&#34;&gt;新颖的观点&lt;/h2&gt;
&lt;h2 id=&#34;有意思的地方&#34;&gt;有意思的地方&lt;/h2&gt;
&lt;h3 id=&#34;不学诗无以言&#34;&gt;不学《诗》，无以言&lt;/h3&gt;
&lt;p&gt;《论语》中多次提到了《诗》，也就是《诗经》。我以前一直不明白，为什么孔子会说”不学习《诗》，就没法说话“呢？第九章223页引用了《左传》中描讲秦穆公送重耳返晋时饮宴唱和的故事，这是一个很具体的”以《诗》言“的例子。在宴会中，重耳借《河水》（这里作者认为是《诗经·小雅·沔水》）表达对晋国多年乱局的感喟和对晋国的思念，也表示了对秦国的称颂以及返国后归附秦国的意愿。而后秦穆公用《诗经·小雅·六月》回应了重耳。在先秦时代的外交场合，《诗经》总是被”断章取义“的使用，这大概就是贵族的一种仪式感吧。联想到前几日外交部某新闻发言人在回答记者关于防疫政策的提问时长达近一分钟的沉默，很想推荐赵发言人回家读读《诗》。&lt;/p&gt;
&lt;h3 id=&#34;重瞳骈胁&#34;&gt;重瞳骈胁&lt;/h3&gt;
&lt;p&gt;据说晋文公路过曹国时，曹共公听说重耳是天生胼胁，想一睹究竟，居然去偷看重耳洗澡。”胼胁“是指肋骨连成一片，经常一起被提起的还有”重瞳“，也就是一个眼睛有两个瞳孔，想想甚是可怖。除了重耳外，史料上具有”重瞳胼胁“这种异象的名人还有舜和项羽等等。这大概是和史书中各种描写皇帝出生前的诸如电闪雷鸣等异常现象类似的一种手法，古人倾向于认为圣人有异象，于是给他们安排上了这种戏码，不知道从现代科学的角度，是否真的存在肋骨连起来的这种情况。&lt;/p&gt;
&lt;h3 id=&#34;摘录&#34;&gt;摘录&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;礼法是一条悬索，下面就是政治危机的万丈深渊，他们只能摔得粉身碎骨。没有走钢丝的本事，又不甘心摔得粉碎的君主，就只有拒绝走上悬索。他们不再虚伪，也就是这个时代注定的“礼崩乐坏”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;为应对当时的一系列危机，齐桓公设计了一个重建旧体制的方案：霸政。到宋襄公这里，证明了想通过这个方案回到旧体制完全行不通。而到晋文公时代，霸政体系对大国非常有利，则体现得非常明显。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/%E5%85%B6%E4%BB%96/">其他</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/%E8%AF%BB%E5%90%8E%E6%84%9F/">读后感</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F-%E5%8E%86%E5%8F%B2/">读后感, 历史</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Derivative of Trace and Determinant</title>
                <link>https://zchencn.github.io/posts/derivativetracedeterminant/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/derivativetracedeterminant/</guid>
                <pubDate>Wed, 02 Mar 2022 23:05:12 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;The derivative of trace or determinant with respect to the matrix is vital when calculating the derivate of lagrangian in matrix optimization problems and finding the  maximum likelihood estimation of multivariate gaussian distribution.&lt;/p&gt;
&lt;h2 id=&#34;matrix-valued-derivative&#34;&gt;Matrix-Valued Derivative&lt;/h2&gt;
&lt;p&gt;Let $f$ be a scaler function of a matrix $X \in \mathbb{R}^{n\times n}$, the derivative of it with respect to $X$ can be defined as following
$$
\left(\frac{\partial f}{\partial X}\right)_{ij} = \frac{\partial f}{\partial X_{ij}}
$$
That is to say, the derivative is a matrix, the element of which is the derivative with respect to the element of matrix $X$.&lt;/p&gt;
&lt;h2 id=&#34;derivative-of-trace&#34;&gt;Derivative of Trace&lt;/h2&gt;
&lt;p&gt;Now, let $f$ be the trace of $X$
$$
f(X) = tr(X) = \sum_{i}X_{ii}
$$
Then, it&amp;rsquo;s easy to find that
$$
\frac{\partial f}{\partial X_{ii}} = 1
$$
We can write in the matrix form
$$
\frac{\partial tr(X)}{\partial X} = I
$$
Moreover,
$$
f(X) = tr(AXB) = \sum_{ijk}A_{ij}X_{jk}B_{ki}
$$
Then
$$
\frac{\partial f}{\partial X_{jk}} = \sum_{i}A_{ij}B_{ki} = (BA)_{kj} = (A^TB^T)_{jk}
$$
So that
$$
\frac{\partial tr(AXB)}{\partial X} = A^TB^T
$$
Similarly, if $f$ be the trace of square of the matrix, then
$$
f(X) = tr(X^2) = \sum_{i}(X^2)_{ii} = \sum_{ik}X_{ik}X_{ki} = \sum_{i}X^2_{ii} + \sum_{k&amp;gt;i}2X_{ik}X_{ki}
$$
so
$$
\frac{\partial tr(X^2)}{\partial X_{ik}} = 2X_{ki}
$$
Thus, we have
$$
\frac{\partial tr(X^2)}{\partial X} = 2X^T
$$&lt;/p&gt;
&lt;h2 id=&#34;derivative-of-determinant&#34;&gt;Derivative of Determinant&lt;/h2&gt;
&lt;p&gt;The determinant of a matrix is complicated to expressed as the summation of its elements,  however, from the Laplace expansion, also known as cofactor expansion, we have
$$
det(X) = \sum_{j}(-1)^{i+j}X_{ij}M_{ij}
$$
so
$$
\frac{\partial det(X)}{\partial X_{ij}} = (-1)^{i+j}M_{ij} = (adj(A)^T)_{ij}
$$
where $adj(A)$ is the adjugate matrix of $A$, so
$$
\frac{\partial det(X)}{\partial X} = adj(A)^T = det(A^T)A^{-T} = det(A)A^{-T}
$$&lt;/p&gt;
&lt;h2 id=&#34;maximum-likelihood-estimation&#34;&gt;Maximum Likelihood Estimation&lt;/h2&gt;
&lt;p&gt;Given a data set ${x_1, x_2, \cdots, x_n}$ sampled from a multivariate Gaussian distribution. We want to estimate the parameters of the distribution via maximum likelihood.&lt;/p&gt;
&lt;p&gt;The probability density function of multivariate Gaussian distribution is
$$
f(x; \mu, \Sigma) = \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}e^{\frac{-(x-\mu)\Sigma^{-1}(x-\mu)^T}{2}}
$$
We form the log likelihood function by taking the logarithm of product of $n$ Gaussian distributions:
$$
l(x; \mu, \Sigma) = -\frac{nd}{2}\log{2\pi} - \frac{n}{2}\log{|\Sigma|} - \frac{1}{2}\prod_{i=1}^n(x_i-\mu)\Sigma^{-1}(x_i-\mu)^T
$$
We need to take the derivative with respect to $\Sigma$ an set to zero.&lt;/p&gt;
&lt;p&gt;As previously mentioned,
$$
\frac{\partial \log{|\Sigma|}}{\partial \Sigma^{-1}} = \frac{1}{|\Sigma|}\frac{\partial |\Sigma|}{\partial \Sigma^{-1}} = \frac{1}{|\Sigma|}\frac{\partial}{\partial \Sigma^{-1}}\frac{1}{|\Sigma^{-1}|} = -\Sigma^T
$$
and
$$
\frac{\partial x\Sigma x^T}{\partial \Sigma} = \frac{\partial tr( x\Sigma x^T)}{\partial \Sigma} = \frac{\partial tr( xx^T\Sigma)}{\partial \Sigma} = (xx^T)^T=xx^T
$$
so
$$
\frac{\partial l}{\partial \Sigma^{-1}} = \frac{n}{2}\Sigma^T - \frac{1}{2}\prod_{i=1}^n(x_i-\mu)(x_i-\mu)^T
$$
Finally, setting to zero yield the maximum likelihood estimator:
$$
\Sigma_{ML} = \frac{1}{n}\prod_{i=1}^n(x_i-\mu)(x_i-\mu)^T
$$&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://paulklein.ca/newsite/teaching/matrix%20calculus.pdf&#34;&gt;Matrix Calculus - Notes on the Derivative of a Trace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Laplace_expansion&#34;&gt;Laplace expansion - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Adjugate_matrix&#34;&gt;Adjugate matrix - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf&#34;&gt;The Multivariate Gaussian&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/mle/">MLE</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/derivative/">Derivative</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Methods to Solve Nonhomogeneous PDE problems</title>
                <link>https://zchencn.github.io/posts/nonhomogeneous/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/nonhomogeneous/</guid>
                <pubDate>Sun, 19 Dec 2021 20:22:08 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;利用&lt;strong&gt;分离变量法&lt;/strong&gt;可以求解具有齐次边界条件的齐次波动方程、热传导方程和拉普拉斯方程。接下来我们讨论如何处理非齐次方程和非齐次边界条件的情况。我们将介绍&lt;strong&gt;齐次化原理&lt;/strong&gt;和&lt;strong&gt;本征函数法&lt;/strong&gt;两种方法用来求解带有齐次边界条件的非齐次方程，再介绍通过构造辅助函数的方法将非齐次边界条件的问题，转化为求解非齐次方程的问题。&lt;/p&gt;
&lt;h2 id=&#34;齐次化原理&#34;&gt;齐次化原理&lt;/h2&gt;
&lt;p&gt;先考虑非齐次方程的情况。我们可以使用齐次化原理求解。回忆微积分课程中学过的积分微商定理，设
$$
U(x) = \int_a^xf(x, \tau)d\tau
$$
$a$ 是一个常数，则有
$$
\frac{d}{dx}U(x) = f(x, x) + \int_a^x\frac{\partial }{\partial x}f(x, \tau)d\tau
$$
考虑以下无界弦的强迫振动的定界问题
$$
\begin{equation}
\begin{cases}
\frac{\partial^2u}{\partial t^2} = a^2\frac{\partial^2u}{\partial x^2} + f(x, t), \quad -\infty&amp;lt;x&amp;lt;\infty, t&amp;gt;0\
u(x, 0) = \frac{\partial}{\partial t}u(x, 0) = 0, \quad -\infty &amp;lt; x &amp;lt; \infty
\end{cases}
\end{equation}
$$
设 $\Omega(x, t, \tau)$ 是如下齐次方程的解
$$
\begin{equation}
\begin{cases}
\frac{\partial^2\Omega}{\partial t^2} = a^2\frac{\partial^2\Omega}{\partial x^2}, \quad -\infty&amp;lt;x&amp;lt;\infty, t&amp;gt;\tau\
\Omega(x, \tau) =0,  \frac{\partial}{\partial t}\Omega(x, \tau) = f(x, \tau), \quad -\infty &amp;lt; x &amp;lt; \infty
\end{cases}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;令
$$
u(x, t) = \int_0^t\Omega(x, t, \tau)d\tau
$$
则首先容易发现
$$
u(x, 0) = \int_0^0\Omega(x, t, \tau)d\tau = 0
$$
利用前面的引理和 $\Omega$ 方程的初始条件可以验证
$$
\frac{\partial u}{\partial t}(x, 0) = \Omega(x, t, t) + \left[\int_0^t\frac{\partial}{\partial t}\Omega(x, t, \tau)d\tau\right]&lt;em&gt;{t=0} = 0
$$
最后对上式在求一次时间的导数，同样有
$$
\begin{equation}
\begin{aligned}
\frac{\partial^2u}{\partial t^2} &amp;amp;= \left[\frac{\partial \Omega}{\partial t}(x, t, \tau)\right]&lt;/em&gt;{\tau=t} + \int_0^t\frac{\partial^2}{\partial t^2}\Omega(x, t, \tau)d\tau\
&amp;amp;= f(x, t) + \int_0^ta^2\frac{\partial^2}{\partial x^2}\Omega(x, t, \tau)d\tau\
&amp;amp;= f(x, t) + a^2\frac{\partial^2}{\partial x^2}\int_0^t\Omega(x, t, \tau)d\tau\
&amp;amp;= f(x, t) + a^2\frac{\partial^2}{\partial x^2}u(x, t)
\end{aligned}
\end{equation}
$$
也即 $u$ 是原来非齐次方程的解。以上就是所谓齐次化原理，也叫&lt;strong&gt;冲量原理&lt;/strong&gt;或者&lt;strong&gt;Duhamel&amp;rsquo;s Principle&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;本征函数法&#34;&gt;本征函数法&lt;/h2&gt;
&lt;p&gt;第二种要介绍的方法是本征函数法。利用分离变量法需要使用叠加原理，这要求方程必须是齐次的且有齐次边界条件。在处理非齐次方程时，直接根据齐次的边界条件选取本征值写出级数形式的解，再利用方程和初始条件来确定技术展开中的系数，这种方法就是本征函数法。考虑两端固定的弦振动问题
$$
\begin{equation}
\begin{cases}
\frac{\partial^2u}{\partial t^2} = a^2\frac{\partial^2u}{\partial x^2} + f(x, t), \quad 0&amp;lt;x&amp;lt;l, t&amp;gt;0\
u(x, 0) = \frac{\partial}{\partial t}u(x, 0) = 0, \quad 0 &amp;lt; x &amp;lt; l\
u(0, t) = u(l, t) = 0
\end{cases}
\end{equation}
$$
本征函数集由对应齐次方程和边界条件给出，所以容易知道对应级数形式的解为
$$
u(x,t) = \sum_{n\geq 1}g_n(t)\sin\frac{n\pi}{l}x
$$&lt;/p&gt;
&lt;p&gt;其中
$$
g_n(t) = \frac{2}{l}\int_0^lu(x, t)\sin\frac{n\pi}{l}xdx
$$
所以容易有
$$
g_n(0) = g^{&#39;}_n(0) = 0
$$&lt;/p&gt;
&lt;p&gt;带入方程得到
$$
\sum_{t\geq1}\left[g^{&#39;&#39;}&lt;em&gt;n(t) + \left(\frac{na\pi}{l}\right)^2g_n(t)\right]\sin\frac{n\pi}{l}x = f(x, t)
$$
对 $f$ 做半幅傅里叶级数展开
$$
f(x, t) = \sum&lt;/em&gt;{t\geq 1}f_n(t)\sin\frac{n\pi}{l}x\
f_n(t) = \frac{2}{l}\int_0^lf(x, t)\sin\frac{n\pi}{l}xdx
$$
对比可得关于 $g_n(t)$ 的二阶常系数非齐次微分方程
$$
g^{&#39;&#39;}_n + \left(\frac{na\pi}{l}\right)^2g_n - f_n(t) = 0
$$
两边对时间作拉普拉斯变换
$$
p^2G_n(p) +  \left(\frac{na\pi}{l}\right)^2G_n(p) - F_n(p) = 0
$$
得到
$$
G_n(p) = \frac{F_n(p)}{p^2 +  \left(\frac{na\pi}{l}\right)^2}
$$
利用拉普拉斯变换卷积的性质和平移性质以及 $\sin t$ 的拉普拉斯变化，容易看出
$$
g_n(t) = \frac{l}{na\pi}\int_0^tf_n(\tau)\sin \frac{na\pi}{l}(t-\tau)d\tau
$$
代入级数展开我们就得到了原非齐次方程的解。&lt;/p&gt;
&lt;h2 id=&#34;非齐次边界条件&#34;&gt;非齐次边界条件&lt;/h2&gt;
&lt;p&gt;以上处理的都是齐次边界的情况，接下来考虑方程有如下非齐次边界条件
$$
u(0, t) = \alpha(t), \quad u(l, t) = \beta(t)
$$
引入辅助函数
$$
\gamma(x, t) = (1 - \frac{x}{l})\alpha(t) + \frac{x}{l}\beta(t)
$$
设
$$
v(x, t) = u(x, t) - \gamma(x, t)
$$
那么容易验证 $v$ 满足齐次边界条件且
$$
\begin{aligned}
\frac{\partial^2v}{\partial t^2} - a^2\frac{\partial^2v}{\partial x^2} &amp;amp;= \frac{\partial^2u}{\partial t^2} - \frac{\partial^2\gamma}{\partial t^2} - a^2\left(\frac{\partial^2u}{\partial x^2}-\frac{\partial^2\gamma}{\partial x^2}\right)\
&amp;amp;= f(x, t) - \frac{\partial^2\gamma}{\partial t^2} + a^2\frac{\partial^2\gamma}{\partial x^2}
\end{aligned}
$$
这样我们把非齐次边界问题转化为了带齐次边界条件的非齐次方程的问题，前面我们已经介绍过了。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/pde/">PDE</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/pde/">PDE</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>CrossValidation</title>
                <link>https://zchencn.github.io/posts/crossvalidation/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/crossvalidation/</guid>
                <pubDate>Thu, 02 Dec 2021 21:40:00 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;Apart from the parameters that will be adjusted during the process of training, there exits some parameters, that are not learned and have to be configured by ourselves in advance. These parameters are also referred to as &lt;strong&gt;hyper-parameters&lt;/strong&gt; which have immense impact on the final results.  Given a set of hyper-parameters, we have to assess our final trained machine learning model while testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called &lt;strong&gt;overfitting&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;One way to overcome this problem is to not use the entire data set when training a learner. Some of the data is removed before training begins. Then when training is done, the data that was removed can be used to test the performance of the learned model on new data. This is the basic idea for a whole class of model evaluation methods called &lt;strong&gt;cross validation&lt;/strong&gt; which allows us to compare different machine learning models and get a sense of how well they will work in practice.  The best parameters can be determined by grid search.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://scikit-learn.org/stable/_images/grid_search_workflow.png&#34; alt=&#34;Grid search workflow&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;holdout-method&#34;&gt;Holdout Method&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;holdout method&lt;/strong&gt; is the simplest kind of cross validation. The data set is separated into two sets, called the training set and the testing set. The training process using the training set only., then the model  is asked to predict the output values for the data in the testing set that never seen before. The errors on the testing data set is used to evaluate the model. The advantage of this method is that it is usually preferable to the residual method and takes no longer to compute. However, its evaluation can have a high variance. The evaluation may depend heavily on which data points end up in the training set and which end up in the test set, and thus the evaluation may be significantly different depending on how the division is made.&lt;/p&gt;
&lt;h2 id=&#34;k-fold-cross-validation&#34;&gt;K-fold Cross Validation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;K-fold cross validation&lt;/strong&gt; is one way to improve over the holdout method. The data set is divided into &lt;em&gt;k&lt;/em&gt; subsets, and the holdout method is repeated &lt;em&gt;k&lt;/em&gt; times. Each time, one of the &lt;em&gt;k&lt;/em&gt; subsets is used as the test set and the other &lt;em&gt;k-1&lt;/em&gt; subsets are put together to form a training set. Then the average error across all &lt;em&gt;k&lt;/em&gt; trials is computed. The advantage of this method is that it matters less how the data gets divided. Every data point gets to be in a test set exactly once, and gets to be in a training set &lt;em&gt;k-1&lt;/em&gt; times. The variance of the resulting estimate is reduced as &lt;em&gt;k&lt;/em&gt; is increased. The disadvantage of this method is that the training algorithm has to be rerun from scratch &lt;em&gt;k&lt;/em&gt; times, which means it takes &lt;em&gt;k&lt;/em&gt; times as much computation to make an evaluation. A variant of this method is to randomly divide the data into a test and training set &lt;em&gt;k&lt;/em&gt; different times. The advantage of doing this is that you can independently choose how large each test set is and how many trials you average over.&lt;/p&gt;
&lt;h2 id=&#34;leave-one-out-cross-validation&#34;&gt;Leave-one-out Cross Validation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;leave-one-out cross validation&lt;/strong&gt; is K-fold cross validation taken to its logical extreme, with K equal to N, the number of data points in the set. That means that N separate times, the model is trained on all the data except for one point and a prediction is made for that point. As before the average error is computed and used to evaluate the model. The evaluation given by leave-one-out cross validation error  is good, but at first pass it seems very expensive to compute.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~schneide/tut5/node42.html&#34;&gt;Cross Validation (cmu.edu)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/cross_validation.html&#34;&gt;3.1. Cross-validation: evaluating estimator performance — scikit-learn 1.0.1 documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cross-validation_(statistics)&#34;&gt;Cross-validation (statistics) - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/machine-learning/">Machine Learning</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/model-selection/">Model Selection</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/machine-learning/">Machine Learning</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/cross-validation/">Cross Validation</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Linear Regression</title>
                <link>https://zchencn.github.io/posts/linearregression/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/linearregression/</guid>
                <pubDate>Fri, 26 Nov 2021 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;mathematic-model&#34;&gt;Mathematic model&lt;/h2&gt;
&lt;p&gt;We assume a sample $x$ has n features $x_i(i = 1, 2, \cdots, n),$ and the goal is to minimize the cost funtion:
$$J_{\theta} = \frac{1}{2m}\sum_{i=1}^{m}[\theta_0+\theta_1x_1^{(i)}+\cdots+\theta_nx_n^{(i)}-y^{(i)}]^2$$
$m$ is the number of sample, the supscript $i$ represent the $i-th$ sample, $y^{(i)}$ is the label of each sample and $\theta=(\theta_0, \theta_1, \cdots, \theta_n)^T$ is the parameter of cost function $J$.&lt;/p&gt;
&lt;h2 id=&#34;gradient-desent&#34;&gt;Gradient desent&lt;/h2&gt;
&lt;h3 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h3&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Step1: Choose a start point $\theta$;&lt;/li&gt;
&lt;li&gt;Step2: Take a step to the direction of minus gradient with the step size of $\alpha$, i.e $\theta_{new} = \theta_{old} - \alpha\nabla J$;&lt;/li&gt;
&lt;li&gt;Step3: Repeat step2 until $J_{\theta}(x)$ is samll enough;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;data-preprocessing&#34;&gt;Data preprocessing&lt;/h3&gt;
&lt;p&gt;To accelerate the speed of convergence, some preprocessing can be applied the data set.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Feature scaling: $\frac{x_i}{r},$ $r = x_i^{max}-x_i^{min}$ is the range value of feature $i$;&lt;/li&gt;
&lt;li&gt;Mean normalization: $x_i-\mu_i, \mu_i$ is the mean value of feature $i$;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;learning-rate&#34;&gt;Learning rate&lt;/h3&gt;
&lt;p&gt;We call the step size $\alpha$ learnig rate.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;If $\alpha$ is too large, the cost function may not decrease on every  iteration, and  the algorithm may not converge;&lt;/li&gt;
&lt;li&gt;If $\alpha$ is too small, the algorithm may converge slowly;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;feature-and-polynomial-regression&#34;&gt;Feature and polynomial regression&lt;/h3&gt;
&lt;p&gt;We can create the new feature from the existing feature, for example $x_i^n$. Then it become a polynomial regression problem, but we can solve it by the same methods of linear regression.&lt;/p&gt;
&lt;h2 id=&#34;normal-equation&#34;&gt;Normal equation&lt;/h2&gt;
&lt;h3 id=&#34;matrix-form&#34;&gt;Matrix form&lt;/h3&gt;
&lt;p&gt;The problem can be expressed in the matrix form, let $x=(x_0,x_1,\cdots,x_n)^T,\ x_0=1,\ X^T=(x^{(1)},x^{(2)},\cdots,x^{(n)}),Y=(y^{(1)},y^{(2)},\cdots,y^{(n)})^T,$ then:
$$J_{\theta}=\frac{1}{2m}||X\theta-Y||^2=\frac{1}{2m}(X\theta-Y)^T(X\theta-Y)$$
$||\cdot||$ is the Euclidean norm, the problem become:
$$\min_{\theta}J_{\theta}$$
$J$ is a convex function, so the local minimum is also the unique global minimum, and the stationary point is the very global minimum:
$$\arg\min_{\theta}J_{\theta}=(X^TX)^{-1}X^TY$$&lt;/p&gt;
&lt;h3 id=&#34;comparision&#34;&gt;Comparision&lt;/h3&gt;
&lt;p&gt;If we use normal equation to solve regression problem, feature scaling is not necesssary, but when the data set is too large we tend to use gradient desent rather than solving normal equation.&lt;br&gt;
If $X^TX$ is non-invertible we can delete some features, use pseudoinverse or use regulization which we will talk about later.&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/machine-learning/">Machine Learning</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/regression/">Regression</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/regression/">Regression</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>An Introduction to Optimal Transport</title>
                <link>https://zchencn.github.io/posts/sinkhorn/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/sinkhorn/</guid>
                <pubDate>Sun, 31 Oct 2021 16:38:57 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;optimal-transport-overview&#34;&gt;Optimal Transport Overview&lt;/h2&gt;
&lt;p&gt;Optimal transportation (OT) problem was first study by Gaspard Monge in 1781: A worker with a shovel in hand want to move a large pile of sand lying on a construction site and wish to minimize her total effort.  OT arouse the interest of mathematicians because it can compare two probability distribution. OT has been rediscovered in many settings and under different forms, giving it a rich history. Kantorovich in 1940s established its significance to logistics and economics. Dantzig solved it numerically in 1949 within the framework of linear programming, giving OT a firm footing in optimization. In recent years, thanks to the emergence of approximate solvers that can scale to large problem dimension, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), graphics (for shape manipulation) or machine learning (for regression, classification and generative modeling).&lt;/p&gt;
&lt;p&gt;We mainly focus on the numerical aspect of OT, for more theoretical detail, please reference the work of Villani.&lt;/p&gt;
&lt;h2 id=&#34;monge-problem&#34;&gt;Monge Problem&lt;/h2&gt;
&lt;p&gt;We say $\textbf{a}$ is an histogram or probability vector if  it belongs to the probability simplex:
$$
\Sigma_n = \left{\textbf{a}\in\mathbb{R}^n_+: \sum_{i=1}^na_i = 1\right}
$$
That is to say, the elements of $\textbf{a}$ is nonnegative and the sum of them is one. A discrete measure with weights $\textbf{a}$ and locations $x_1, x_2, \cdots, x_n$ reads:
$$
\alpha = \sum_{i=1}^na_i\delta_{x_i}
$$
where $\delta_x$ is the Dirac at  position $x$  intuitively a unit of mass which is infinitely concentrated at location $x$.  For discrete measure:
$$
\alpha = \sum_{i=1}^na_i\delta_{x_i}\quad \text{and}\quad\beta = \sum_{i=1}^mb_i\delta_{y_i}
$$
the Monge problem seeks a map the associates to each point $x_i$ a single point $y_i$ and which must push the mass of $\alpha$ toward the mass of $\beta$, namely, such a map $T:{x_1, \cdots, x_n} \rightarrow {y_1, \cdots, y_m}$ must verify that:
$$
\forall j \in {1, 2, \cdots, m}, b_j = \sum_{T(x_i)=y_j}a_i
$$
which we write in compact form as:
$$
T_{\sharp}\alpha = \beta
$$
Given a cost function $c(x, y)$, the Monge problem is to find the map that minimize the total cost of the transportation:
$$
\min_T\left{\sum_{i}c(x_i, T(x_i)): T_{\sharp}\alpha=\beta\right}
$$
Monge maps may not even exist between a discrete measure to another.&lt;/p&gt;
&lt;h2 id=&#34;kantorovich-relaxation&#34;&gt;Kantorovich Relaxation&lt;/h2&gt;
&lt;p&gt;The key idea of Kantorovich is to relax the deterministic nature of transportation, namely the fact that a source point $x_i$ can only be assigned to another point or location $T(x_i)$ only.  Kantorovich proposed instead that the mass at any point $x_i$ be potentially dispatched across several locations. This flexibility is encoded using a coupling matrix $P \in \mathbb{R}^{n\times m}&lt;em&gt;+$, where $P&lt;/em&gt;{ij}$ describes the amount of mass flowing from bin $i$ to bin $j$.  Admissible couplings admit a simple characterization that:
$$
U(\textbf{a}, \textbf{b}) = \left{P\in\mathbb{R}^{n\times m}&lt;em&gt;+: \sum_jP&lt;/em&gt;{ij}=a_i, \sum_iP_{ij}=b_j\right}
$$
The set of matrices $U(\textbf{a}, \textbf{b})$ is bounded and defined by $n+m$ equality constraints, and therefore is a convex polytope.&lt;/p&gt;
&lt;p&gt;Given a cost matrix $C$, Kantorovich&amp;rsquo;s OT problem now reads:
$$
L_C(\textbf{a}, \textbf{b}) = \min_{P\in U(\textbf{a}, \textbf{b})}\left&amp;lt;P, C\right&amp;gt; = \sum_{i,j}C_{ij}P_{ij}
$$
This is a linear program and as is usually the case with such programs, its optimal solutions are not necessarily unique.&lt;/p&gt;
&lt;h2 id=&#34;wasserstein-distance&#34;&gt;Wasserstein Distance&lt;/h2&gt;
&lt;p&gt;An import feature if OT is that it defines a distance between histograms and probability measures as soon as the cost matrix satisfies certain suitable properties. We suppose $n=m$ and that for some $p\geq 1$, $C = D^p$ where $D\in \mathbb{R}^{n\times n}_+$ is a distance matrix, that is to say $D$ satisfy following properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$D$ is symmetric&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$D_{ij} = 0$ if and only if $i=j$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\forall i, j, k, D_{ik} \leq D_{ij} + D_{jk}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then we can define so-called Wasserstein distance on probability simplex $\Sigma_n$,
$$
W_p(\textbf{a}, \textbf{b}) = L_{D^p}(\textbf{a}, \textbf{b})^{1/p}
$$&lt;/p&gt;
&lt;h2 id=&#34;entropic-regularization&#34;&gt;Entropic Regularization&lt;/h2&gt;
&lt;p&gt;We will introduce a family of numerical schemes to approximate solutions to Kantorovich formulation of OT. It operates by adding an entropic regularization to the original problem. The minimization of the regularized problem can be solved by using a simple alternate minimization scheme which are iterations of simple matrix-vector products. The resulting approximate distance is smooth with respect to input histogram weights and can be differentiated using automatic differentiation.&lt;/p&gt;
&lt;p&gt;The discrete entropy of the coupling matrix is defined as:
$$
H(P) = -\sum_{i, j}P_{ij}(\log(P_{ij})-1)
$$
The idea of the entropic regularization of OT is to use $-H$ as a regularization function to obtain approximate solutions to the origin Kantorovich OT problem:
$$
L^{\epsilon}&lt;em&gt;C(\textbf{a}, \textbf{b}) = \min&lt;/em&gt;{P\in U(\textbf{a, \textbf{b}})}\left&amp;lt;P, C\right&amp;gt; - \epsilon H(P)
$$
Since the objective is an $\epsilon-strongly$ convex function, the problem mentioned above has a unique optimal solution.&lt;/p&gt;
&lt;p&gt;It has been proved that:
$$
L^{\epsilon}_C(\textbf{a}, \textbf{b})\stackrel{\epsilon\rightarrow0}{\longrightarrow}L_C(\textbf{a}, \textbf{b})
$$&lt;/p&gt;
&lt;h2 id=&#34;sinkhorns-algorithm&#34;&gt;Sinkhorn&amp;rsquo;s Algorithm&lt;/h2&gt;
&lt;p&gt;Let $K$ denote the Gibbs kernel associated to the cost matrix $C$ as:
$$
K_{ij} = e^{-\frac{C_{ij}}{\epsilon}}
$$
The solution of the regularized OT problem has the form:
$$
P_{ij} = u_iK_{ij}v_j
$$
for two (unknow) scaling variable $(\textbf{u}, \textbf{v}) \in \mathbb{R}^n_+\times\mathbb{R}^m_+$.&lt;/p&gt;
&lt;p&gt;The factorization of the optimal solution can be conveniently rewritten in matrix form as:
$$
P = diag(\textbf{u})Kdiag(\textbf{v})
$$
The scaling variables must therefore satisfy the following nonlinear equations which correspond to the mass conservation constraints inherent to $U(\textbf{a}, \textbf{b})$:
$$
\textbf{u}\odot(K\textbf{v}) = \textbf{a}, \quad \textbf{v}\odot(K^T\textbf{u}) = \textbf{b}
$$
where $\odot$ corresponds to entrywise multiplication of vectors. That problem is known as matrix scaling problem which can be solved iteratively by modifying first $\textbf{u}$ so that it satisfies the left-hand side of above equations and then $\textbf{v}$ to satisfy its right-hand side. These two updates define Sinkhorn&amp;rsquo;s algorithm:
$$
\textbf{u}^{(l+1)} = \frac{\textbf{a}}{K\textbf{v}^(l)}, \quad \textbf{v}^{(l+1)} = \frac{\textbf{b}}{K^T\textbf{u}^{(l+1)}}
$$
initialized with an arbitrary positive vector $\textbf{v}^{(0)} = \mathbb{1}_m$. The division operator used above between two vectors is to be understood entrywise.&lt;/p&gt;
&lt;p&gt;In order to speed up the Sinkhorn&amp;rsquo;s iterations, we can compute several regularized Wasserstein distances between pairs of histograms simultaneously. Let $N$ be an integer, $\textbf{a}_1, \cdots, \textbf{a}_N$ be histograms in $\Sigma_n$, and $\textbf{b}_1, \cdots, \textbf{b}_N$ be histograms in $\Sigma_m$. We seek to compute all $N$ approximate distances $L_C^{\epsilon}(\textbf{a}_1, \textbf{b}_1), \cdots, L_C^{\epsilon}(\textbf{a}_N, \textbf{b}_N).$  In that case, writing $A = [\textbf{a}_1, \cdots, \textbf{a}_N]$ and $B = [\textbf{b}_1, \cdots, \textbf{b}&lt;em&gt;N]$ for the $n\times N$ and $m\times N$ matrices storing all histograms,  one can notice that all Sinkhorn iterations for all these $N$ pairs can be carried out in parallel, by setting, for instance,
$$
\textbf{U}^{(l+1)} = \frac{\textbf{A}}{K\textbf{V}^(l)}, \quad \textbf{V}^{(l+1)} = \frac{\textbf{B}}{K^T\textbf{U}^{(l+1)}}
$$
initialized with $\textbf{V}^{(0)} = \mathbb{1}&lt;/em&gt;{m\times N}.$&lt;/p&gt;
&lt;h2 id=&#34;log-domain-stabilized-sinkhorn&#34;&gt;Log-domain Stabilized Sinkhorn&lt;/h2&gt;
&lt;p&gt;The Sinkhorn algorithm suffers from numerical overflow when the regularization parameter $\epsilon$ is small compared to the entries of the cost matrix $C$. This concern can be alleviated to some extent be carrying out computations in log domain.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://optimaltransport.github.io/&#34;&gt;Computational Optimal Transport&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/optimal-transport/">Optimal Transport</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/optimal-transport/">Optimal Transport</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/machine-learning/">Machine Learning</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Bias and Variance</title>
                <link>https://zchencn.github.io/posts/variancebias/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/variancebias/</guid>
                <pubDate>Wed, 08 Sep 2021 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;在监督学习中，我们使用特定的算法在给定的带标记的训练集 $D={(x_i, y_i)}_{i=1}^N$ 上训练得到一个模型 $f(x; D)$ . 泛化能力是评价一个模型好坏的重要标准，我们希望得到的模型能够在它没有见过的输入 $x$ 上有更准确的预测能力. 在模型训练时，我们总是通过特定的算法去减小训练误差，但是在实践中我们发现，更小的训练误差并不就意味着更小的泛化误差，往往随着训练误差的减小，泛化误差呈现一个先下降后上升的趋势，我们称之为&lt;strong&gt;过拟合&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bias&lt;/strong&gt; 和 &lt;strong&gt;Variance&lt;/strong&gt; 能够帮助我们去理解模型的泛化能力.  给定测试样本 $x$ ，令 $y_{D}$ 为 $x$ 在训练集中的标记，$y$ 为真实标记，则学习算法的期望预测为
$$
\bar{f}(x) = E_{D}[f(x; D)]
$$&lt;/p&gt;
&lt;h2 id=&#34;what-is-bias&#34;&gt;What Is Bias?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Bias&lt;/strong&gt; 是衡量模型与真实标记偏差的量，数学上如下定义
$$
bias^2 = (\bar{f}(x)-y)^2
$$
通常，一个简单模型的 $bias$ 会比复杂模型的大。比如在多项式回归中，极端地，我们使用0次多项式也即常数作为模型，那么它的输出和真实标记的偏差显然比我们使用高次多项式作为模型得到的偏差要大，因为总是存在一个 $N-1$ 次多项式能够完全拟合给定的 $N$ 个数据点.&lt;/p&gt;
&lt;h2 id=&#34;what-is-variance&#34;&gt;What Is Variance?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt; 是衡量训练集扰动对模型产生的影响的量，数学定义如下
$$
variance = E_{D}[(f(x; D)-\bar{f}(x))^2]
$$
高的 Variance 说明当训练集发生扰动时，训练得到的模型会有很大的改变，也就是说鲁棒性比较差，这是我们不希望看到的，因为训练集的标记总是和真实标记之间存在误差。通常，一个简单模型的 Variance 会比复杂模型的小。同样以上文中多项式回归为例子，用常数作为模型无论训练集的输入如何变化得到的最终模型都不会改变，但是扰动对高次多项式的影响是较大的。&lt;/p&gt;
&lt;h2 id=&#34;decomposition&#34;&gt;Decomposition&lt;/h2&gt;
&lt;p&gt;假设训练集标记和真实标记之间的误差的期望为0，方差为 $\epsilon^2$ ，即
$$
E_{D}[y-y_D] = 0, E_{D}[(y-y_D)^2] = \epsilon^2
$$
我们对期望泛化误差可以作如下分解
$$
\begin{align}
E_D[(f(x; D) - y_D)^2] &amp;amp;= E_D[(f(x; D) -\bar{f}(x) + \bar{f}(x)- y_D)^2]\\
&amp;amp;= E_D[(f(x; D)-\bar{f}(x))^2] + E_D[(\bar{f}(x)-y+y-y_D)^2] + 2E_D[(f(x; D)-\bar{f}(x))(\bar{f}(x)-y_D)]\\
&amp;amp;= variance + E_D[(\bar{f}(x)-y)^2] + E_D[(y-y_D)^2] + 2E_D[(\bar{f}(x)-y)(y-y_D)]\\
&amp;amp;= variance + bias^2 + \epsilon^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;也就是说，泛化误差可以分解为偏差、方差与噪声之和. 噪声刻画了泛化误差的下界，反应了学习问题本身的难度.&lt;/p&gt;
&lt;h2 id=&#34;trade-off&#34;&gt;Trade-off&lt;/h2&gt;
&lt;p&gt;监督学习的希望得到一个 bias 和 Variance 都较低的模型，但是一般来说，这两者是冲突的。在训练不足时，模型的拟合能力不足，训练数据扰动不足以对模型产生显著影响，此时 bias 主导了泛化误差；随着训练程度的加深，模型的拟合能力逐渐增强，训练数据的扰动能够被算法学习到，发生了过拟合，此时 Variance 主导了泛化误差. 我们需要在这两者中找到一个好的平衡点，使得得到的模型效果足够令人满意.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;《机器学习》，周志华，清华大学出版社&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Gentle Introduction to the Bias-Variance Trade-Off in Machine Learning (machinelearningmastery.com)](&lt;a href=&#34;https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/#:~:text=Bias&#34;&gt;https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/#:~:text=Bias&lt;/a&gt; is the simplifying assumptions,the bias and the variance.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.mastersindatascience.org/learning/difference-between-bias-and-variance/&#34;&gt;What Is the Difference Between Bias and Variance? (mastersindatascience.org)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff&#34;&gt;Bias–variance tradeoff - Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/machine-learning/">Machine Learning</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/machine-learning/">Machine Learning</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Mutable and Immutable Objects in Python</title>
                <link>https://zchencn.github.io/posts/mutableandimmutableobjects/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/mutableandimmutableobjects/</guid>
                <pubDate>Thu, 21 Jan 2021 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;Python 是一门面向对象语言，Python 中包括内置类型在内的一切都是对象。Python 对象分为可变对象(Mutable Object)和不可变对象(Immutable Object).&lt;/p&gt;
&lt;h2 id=&#34;id-and-type&#34;&gt;ID and Type&lt;/h2&gt;
&lt;p&gt;Python 中的对象再被实例化时会被分配一个与内存位置相关的id, 可以用内置的&lt;code&gt;id()&lt;/code&gt;函数查看对象的id, 用&lt;code&gt;type()&lt;/code&gt;函数查看对象的类型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;140279384729648&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;mutable-and-immutable&#34;&gt;Mutable and Immutable&lt;/h2&gt;
&lt;p&gt;Python 的内置类型也分为可变和不可变两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mutable:  int  float complex sting tuple&lt;/li&gt;
&lt;li&gt;immutable:  list set dict&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看一段代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;首先，我们在内存中创建了一个类型为&lt;code&gt;int&lt;/code&gt;, 值为&lt;code&gt;10&lt;/code&gt;的对象，并把它赋给变量&lt;code&gt;x&lt;/code&gt; （或者说给这个对象起了一个名字&lt;code&gt;x&lt;/code&gt;）， 再把变量&lt;code&gt;x&lt;/code&gt;表示的对象与&lt;code&gt;y&lt;/code&gt;绑定（或者说起了一个别名&lt;code&gt;y&lt;/code&gt;）.  所以&lt;code&gt;x, y, 10&lt;/code&gt; 的id是相同的。然后， 因为&lt;code&gt;int&lt;/code&gt;是不可变对象，&lt;code&gt;x + 1&lt;/code&gt;会创建一个值为&lt;code&gt;11&lt;/code&gt; 类型为 &lt;code&gt;int&lt;/code&gt; 的新对象，再把这个新对象重新与 &lt;code&gt;x&lt;/code&gt; 绑定，此时 &lt;code&gt;y&lt;/code&gt; 还是 &lt;code&gt;10&lt;/code&gt; 这个对象，所以 &lt;code&gt;x, y&lt;/code&gt; 的id不相等。&lt;/p&gt;
&lt;p&gt;再看下面一段代买：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;s1&#34;&gt;&amp;#39;c&amp;#39;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同样我们创建一个对象并把它赋给两个变量 &lt;code&gt;l1, 12&lt;/code&gt;, 由于 &lt;code&gt;list&lt;/code&gt; 是可变对象，  &lt;code&gt;pop&lt;/code&gt; 可以直接改变它的状态，并不用重新创建一个新的 &lt;code&gt;&#39;list&lt;/code&gt;&#39; 对象，所以 &lt;code&gt;l1, l2&lt;/code&gt; 的id还是相同的。&lt;/p&gt;
&lt;p&gt;但是，不可变对象的不可变不是绝对的，看下面一个例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;abcd&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;abcd&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们首先创建了一个  &lt;code&gt;tuple&lt;/code&gt;  对象，在 Python 中， &lt;code&gt;tuple&lt;/code&gt; 是不可变对象，它的第二个成员是一个可变的 &lt;code&gt;list&lt;/code&gt; 对象， 我们改变了这个 &lt;code&gt;list&lt;/code&gt; 对象，从内容上看，&lt;code&gt;tuple&lt;/code&gt; 被改变了，但是它仍然绑定的是创建时的那个 &lt;code&gt;string&lt;/code&gt; 和 &lt;code&gt;list&lt;/code&gt; ，从这个角度看，它是没有被改变的。&lt;/p&gt;
&lt;h2 id=&#34;custom-class&#34;&gt;Custom Class&lt;/h2&gt;
&lt;p&gt;用户自定义的类默认是可变的.&lt;/p&gt;
&lt;h2 id=&#34;passed-to-function&#34;&gt;Passed to Function&lt;/h2&gt;
&lt;p&gt;不严谨地说，传递可变对象类似引用传递(Call by Reference), 传递不可变对象类似值传递(Call by Value).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;func1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
 
&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# [0, 1, 2, 3]&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;
    
&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;func2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/computer-science/">Computer Science</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/programming-language/">Programming Language</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/python/">Python</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/python/">Python</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Different Derivatives in Mathematics</title>
                <link>https://zchencn.github.io/posts/derivatives/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/derivatives/</guid>
                <pubDate>Mon, 18 Jan 2021 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;一元函数、多元函数和泛函的导数相关概念。以下均假设导数存在。&lt;/p&gt;
&lt;h2 id=&#34;一元函数&#34;&gt;一元函数&lt;/h2&gt;
&lt;p&gt;$f:\mathbb{R} \rightarrow \mathbb{R}$ 是实数域上的一元函数，函数在某点的导数是函数值在该点关于自变量的变化率，定义如下：
$$
\frac{df(x)}{dx} = \lim_{h\to0}\frac{f(x + h) - f(x)}{h} \tag{1}
$$
上式极限存在称函数 $f$ 在 $x$ 处可导，相应的可以定义映射$f^{&#39;}:x \mapsto \frac{df(x)}{dx}$ 称 $f$ 的导函数，一般记为 $f^{&#39;}(x)$ .&lt;/p&gt;
&lt;h2 id=&#34;多元函数&#34;&gt;多元函数&lt;/h2&gt;
&lt;p&gt;$f:\mathbb{R}^n \rightarrow \mathbb{R}$ 是定义在 $n$ 维欧氏空间上的函数。&lt;/p&gt;
&lt;h3 id=&#34;偏导数&#34;&gt;偏导数&lt;/h3&gt;
&lt;p&gt;对于多变量函数，如果我们固定除某一个变量外的其他变量，此时它可以看作一个单变量函数，此时该函数关于未固定这个变量的导数，就是多元函数的偏导数：
$$
\frac{\partial f(x_1, x_2, \cdots, x_n )}{\partial x_k} = \lim_{h\to0}\frac{f(x_1, \cdots, x_k + h, \cdots, x_n) - f(x_1, \cdots, x_k, \cdots, x_n)}{h}
$$&lt;/p&gt;
&lt;h3 id=&#34;梯度&#34;&gt;梯度&lt;/h3&gt;
&lt;p&gt;假设 $f$ 在 $\mathbf{p}$ 点的偏导数都存在，则可以定义它在该点的梯度向量：
$$
grad f(\mathbf{p}) = \nabla f(\mathbf{p}) =
\begin{bmatrix}
\frac{\partial f(\mathbf{p})}{\partial x_1}\
\frac{\partial f(\mathbf{p})}{\partial x_2}\
\vdots \
\frac{\partial f(\mathbf{p})}{\partial x_n}
\end{bmatrix}
$$
$\nabla f: \mathbf{R}^n \rightarrow \mathbf{R}^n, \mathbf{p} \mapsto \nabla f(\mathbf{p})$ 是函数 $f$ 的梯度场。&lt;/p&gt;
&lt;h3 id=&#34;方向导数&#34;&gt;方向导数&lt;/h3&gt;
&lt;p&gt;为了衡量多变量函数在某点沿着某个方向的变化率，可以引入方向导数的概念，$f$ 在 $\mathbf{x}$ 点沿 $ \mathbf{p}$ 方向的方向导数为：
$$
\nabla_{\mathbf{v}}f(\mathbf{x}) = \lim_{h\to0}\frac{f(\mathbf{x} + h\mathbf{v}) -f(\mathbf{x})}{h}
$$
特别地，偏导数可以看作函数沿 $\mathbf{e_k}$ 方向的方向导数：
$$
\nabla_{\mathbf{e_k}}f(\mathbf{x}) = \lim_{h\to0}\frac{f(\mathbf{x} + h\mathbf{e_k}) - f(\mathbf{x})}{h} = \lim_{h\to0}\frac{f(x_1, \cdots, x_k + h, \cdots, x_n) - f(x_1, \cdots, x_k, \cdots, x_n)}{h} = \frac{\partial f(\mathbf{x})}{\partial x_k}
$$
另外：
$$
f(x_1 + h v_1, x_2 + hv_2) = f(x_1, x_2) + \frac{\partial f}{\partial x_1}hv_1 + \frac{\partial f}{\partial x_2}hv_2 + o(h)
$$
所以：
$$
\nabla_{\mathbf{v}}f(x) = \nabla f(\mathbf{x})\cdot \mathbf{v} = \nabla f(\mathbf{x})^T\mathbf{v}
$$&lt;/p&gt;
&lt;h3 id=&#34;全微分&#34;&gt;全微分&lt;/h3&gt;
&lt;p&gt;偏导数和方向导数衡量的都可以看作是函数沿着某一方向的近似，而全微分可以看作是函数在某点的最佳线性逼近，和方向无关：
$$
f(\mathbf{x} + \mathbf{h}) = f(\mathbf{x}) + df_{\mathbf{x}}(\mathbf{h}) + o(||\mathbf{h}||)
$$
$df_{\mathbf{x}}: \mathbb{R}^n \rightarrow R$ 是 $f$ 在 $\mathbf{x}$ 的线性全微分算子。&lt;/p&gt;
&lt;p&gt;另有：
$$
0 = \lim_{t\to 0}\frac{f(\mathbf{x} + t\mathbf{h}) - f(\mathbf{x}) - df_{\mathbf{x}}(t\mathbf{h})}{t} = \nabla_{\mathbf{h}}f(\mathbf{x}) - df_{\mathbf{x}}(\mathbf{h})
$$
即：$\nabla_{\mathbf{h}}f(\mathbf{x}) = df_{\mathbf{x}}(\mathbf{h}) = \nabla f(\mathbf{x})^T\mathbf{h}$.&lt;/p&gt;
&lt;p&gt;由希尔伯特空间上的Riesz表示定理， 存在 $\mathbf{p_x} \in \mathbb{R}^n$ 使得：
$$
df_{\mathbf{x}}(\mathbf{h}) = \mathbf{p_x}^T\mathbf{h}
$$
也即 $f$ 在该点的梯度，所以全微分可以看作是梯度的对偶。&lt;/p&gt;
&lt;h2 id=&#34;g导数&#34;&gt;G导数&lt;/h2&gt;
&lt;p&gt;设 $F: U\rightarrow R$ 是线性空间 $U$ 上的实泛函。从方向导数推广，可以定义泛函的G导数(Gateaux):
$$
dF(u; v) = \lim_{t \to 0}\frac{F(u + tv) - F(u)}{t}
$$&lt;/p&gt;
&lt;h2 id=&#34;f导数&#34;&gt;F导数&lt;/h2&gt;
&lt;p&gt;进一步假设 $U$ 是Banach空间，可以定义泛函的F导数(Frechet):
$$
F(u + h) = F(u) + Df_u(h) + o(||h||)
$$
$Df_u : U \rightarrow R$&lt;/p&gt;
&lt;p&gt;F可导一定G可导，G可导不一定F可导。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/caculus/">Caculus</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/derivatives/">Derivatives</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Matric Caculus</title>
                <link>https://zchencn.github.io/posts/matriccaculus/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/matriccaculus/</guid>
                <pubDate>Mon, 18 Jan 2021 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;Assume that all vectors are column vector, and we use numerator layout&lt;/p&gt;
&lt;h2 id=&#34;scalar-by-vector&#34;&gt;Scalar-by-Vector&lt;/h2&gt;
&lt;p&gt;$f$ is a scalar function of $\mathbf{x}\in \mathbb{R}^n$, then the gradient vector of $f$ with respect to $\mathbf{x}$ is:
$$
\frac{\partial f}{\partial \mathbf{x}}=\left[\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \cdots, \frac{\partial f}{\partial x_n} \right]
$$
then the gradient vector of f is:
$$
\nabla f = \sum_{i=1}^n\frac{\partial f}{\partial x_i}e_i = \left(\frac{\partial f}{\partial \mathbf{x}}\right)^T
$$&lt;/p&gt;
&lt;h2 id=&#34;vector-by-scalar&#34;&gt;Vector-by-Scalar&lt;/h2&gt;
&lt;p&gt;$\mathbf{y} \in\mathbb{R}^n$ is a n dimensional vector each component of  which is a scalar function of x, then:
$$
\frac{\partial \mathbf{y}}{\partial x} = \left[\frac{\partial y_1}{\partial x}, \frac{\partial y_2}{\partial x}, \cdots, \frac{\partial y_n}{\partial x} \right]^T
$$&lt;/p&gt;
&lt;h2 id=&#34;vector-by-vector&#34;&gt;Vector-by-Vector&lt;/h2&gt;
&lt;p&gt;$\mathbf{y} \in \mathbb{R}^m$ is a vector of $\mathbf{x} \in \mathbb{R}^n$ , the Jacobian matrix of it is a m-by-n matrix:
$$
\begin{equation}
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \left[\nabla y_1, \nabla y_2, \cdots, \nabla y_m  \right]^T =
\begin{bmatrix}
\frac{\partial y_1}{\partial x_1} &amp;amp; \frac{\partial y_1}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial y_1}{\partial x_n} \
\frac{\partial y_2}{\partial x_1} &amp;amp; \frac{\partial y_2}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial y_2}{\partial x_n} \
\vdots							  &amp;amp; \vdots                            &amp;amp; \ddots &amp;amp; \vdots                            \
\frac{\partial y_m}{\partial x_1} &amp;amp; \frac{\partial y_m}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial y_m}{\partial x_1}
\end{bmatrix}
\end{equation}
$$
Let $\mathbf{y} = \mathbf{Ax}$ , $\mathbf{A}$ is independent of $\mathbf{x}$, then:
$$
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \frac{\partial \mathbf{Ax}}{\partial \mathbf{x}} = \mathbf{A}
$$
If $y = \mathbf{x^TAx}$ ,
$$
\frac{\partial y}{\partial \mathbf{x}} = \frac{\partial \mathbf{x^TAx}}{\partial \mathbf{x}} = \frac{\partial \sum a_{ij}x_ix_j}{\partial \mathbf{x}} = \left[\sum a_{1j}x_j + \sum a_{i1}x_i, \sum a_{2j}x_j + \sum a_{i2}x_i, \cdots, \sum a_{nj}x_j + \sum a_{in}x_i\right] = \mathbf{x}^T(\mathbf{A} + \mathbf{A}^T)
$$&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Matrix_calculus#Vector-by-vector_identities&#34;&gt;Wikipedia: Matrix Calculus&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/matrix-caculus/">Matrix Caculus</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Static Library and Dynamic Link Library</title>
                <link>https://zchencn.github.io/posts/staticlibanddynamiclib/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/staticlibanddynamiclib/</guid>
                <pubDate>Thu, 03 Dec 2020 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;静态库和动态库&#34;&gt;静态库和动态库&lt;/h2&gt;
&lt;p&gt;将频繁复用的程序打包成库文件，并在使用时链接到项目中可以有效的节省编译时间，避免频繁的复制，提高编程的效率。 常用有静态库(static library)和动态库(shared library or dynamic library). &lt;br&gt;
程序的编译运行可分为下面四个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预编译；处理预编译指导语句，也就是程序中以#开头的行，如#include和#define等；&lt;/li&gt;
&lt;li&gt;编译；将程序的源文件(.c)转化为目标文件(.o);&lt;/li&gt;
&lt;li&gt;链接；将库和所有目标文件链接成可执行程序。对静态库来说，实际的文件被打包进了最终的可执行程序，然而动态库只是把标记放入的可执行程序；&lt;/li&gt;
&lt;li&gt;装载；程序被装载程序(loader)装载后开始执行，所有动态库的标记都会被解析被映射到程序中；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;动态库&#34;&gt;动态库&lt;/h3&gt;
&lt;p&gt;编译和链接使用动态库有如下步骤：&lt;/p&gt;
&lt;h4 id=&#34;step-1-compiling-with-position-independent-code&#34;&gt;Step 1: Compiling with Position Independent Code&lt;/h4&gt;
&lt;p&gt;我们需要将库的源文件编译成位置独立的代码(PIC):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;gcc -c -Wall -Werror -fpic source_file.c
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;step-2-creating-a-shared-library-from-an-object-file&#34;&gt;Step 2: Creating a shared library from an object file&lt;/h4&gt;
&lt;p&gt;将目标文件打包成动态库：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;gcc -shared -o libshared_lib_name.so source_file.o
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;step-3-linking-with-a-shared-library&#34;&gt;Step 3: Linking with a shared library&lt;/h4&gt;
&lt;p&gt;经过前两步我们已经有了一个动态库了。现在main.c文件需要使用动态库，我们使用-L选项告诉编译器库所在的目录，并用-l选型指定库的名字：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;gcc -Wall -L directory_of_library -o &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; main.c -lshared_lib_name
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;step-4-making-the-library-available-at-runtime&#34;&gt;Step 4: Making the library available at runtime&lt;/h4&gt;
&lt;p&gt;然而此时执行程序还是会报错：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;error while loading shared libraries: shared_lib_name.so: cannot open shared object file: No such file or directory
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有两种方法解决这个问题，一种是将库目录加到LD_LIBRARY_PATH变量中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;directory_of_library:&lt;span class=&#34;nv&#34;&gt;$LD_LIBRARY_PATH&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;一种是在编译链接时加上：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;-Wl,-rpath=directory_of_library
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;-Wl是将后面的参数传给链接器的意思，“,”用来处理参数中的空格。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/computer-science/">Computer Science</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/programming-language/">Programming Language</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/cc-/">C&amp;C&#43;&#43;</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/static-library/">Static Library</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/dynamic-link-library/">Dynamic Link Library</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>An Introduction to Perfectly Matched Layer</title>
                <link>https://zchencn.github.io/posts/pml/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/pml/</guid>
                <pubDate>Sun, 29 Nov 2020 16:38:57 &#43;0800</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;Free-space simulation happens in many problems and especially in wave-structure interactions. The key question is how to perform spatial truncation without introducing significant artifacts into the computation when solving the PDE numerically. Various techniques, such as &amp;ldquo;radiating boundary&amp;rdquo;, &amp;ldquo;matched layer&amp;rdquo; and  &amp;ldquo;one-way approximation of the wave equation&amp;rdquo;， have been used in computer code. In 1994, Berenger invented a new technique as PML technique to tackle this issue, he put a layer of artificial absorbing material around the grid to absorb the outgoing wave.&lt;/p&gt;
&lt;h3 id=&#34;wave-equation&#34;&gt;Wave Equation&lt;/h3&gt;
&lt;p&gt;Acoustic wave equation has the following form:
$$
\begin{cases}
\frac{\partial v}{\partial t} = -\frac{1}{\rho}\nabla p\
\frac{\partial p}{\partial t} = -\kappa\nabla \cdot v
\end{cases}
$$
In two dimensional case, it can be written as:
$$
\frac{\partial^2 p}{\partial t^2} = c^2\nabla^2p = c^2\left(\frac{\partial^2 p}{\partial x^2}+\frac{\partial^2 p}{\partial z^2}\right)
$$
We will numerically solve it to demonstrate some ideas in the following article. Code can be found &lt;a href=&#34;https://github.com/zchenCN/fdwave/blob/master/acoustic2d.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;numerical-reflection&#34;&gt;Numerical Reflection&lt;/h3&gt;
&lt;p&gt;Numerical reflection will pollute the solution if we simply truncate the grid with hard-wall(zero condition on the boundary).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./figs/reflection.jpg&#34; alt=&#34;reflection&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;complex-coordinate-stretching&#34;&gt;Complex Coordinate Stretching&lt;/h3&gt;
&lt;p&gt;Consider a plane wave solution of the wave equation with the form:
$$
w(x, t) = e^{i(kx - wt)}
$$
The amplitude of it is invariant as it travel along the real axis:
$$
||w(x, t)|| = ||e^{i(kx-wt)}|| = 1
$$
Things change  if we analytically continue it, evaluate the plane wave solution at complex values:
$$
w(x, t) = e^{i(k(Rex + iImx)-wt)} = e^{-kImx}e^{i(kRex-wt)}
$$
The amplitude decay exponentially as the growing of  the imaginary part of x, while the solution is not changed out of the absorbing material. So, it not  only acts like an absorbing material, but also like a reflectionless material.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;figs/absorbing.jpg&#34; alt=&#34;absorbing&#34;&gt;&lt;/p&gt;
&lt;p&gt;The analytically continued solution satisfied the same differential equation. We assume the differential equation was x-invariant in this region, so x only appeared in derivative $\frac{\partial}{\partial x}$ .  The entire process of PML can be conceptually summed up by a single transformation of original differential equation:
$$
\frac{\partial }{\partial x} \rightarrow \frac{1}{s_x}\frac{\partial}{\partial x}, s_x = 1 + i\frac{\sigma_x(x)}{w}
$$&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://math.mit.edu/~stevenj/18.369/pml.pdf&#34;&gt;Notes on Perfectly Matched Layer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/pde/">PDE</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/pde/">PDE</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Vector in STL</title>
                <link>https://zchencn.github.io/posts/vector/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/vector/</guid>
                <pubDate>Sun, 29 Nov 2020 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;vector是c++的一个标准类模板，可以用来动态地存储相同类型的实例或基本类型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#inlucde &amp;lt;vector&amp;gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Include the header file
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;using&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Using declaration
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;vector是模板(template)不是具体的类(class)，在使用时，应该声明具体对象的类型：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Declare a vector v for int
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因为引用不是具体的对象，所以不能定义由引用组成的vector。特别地，可以定义成员是vector的vector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// T is a type 
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; 	&lt;span class=&#34;c1&#34;&gt;// Some compile require a space before closing angle bracket
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;初始化&#34;&gt;初始化&lt;/h2&gt;
&lt;p&gt;c++提供了不同的构造函数用来初始化vector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Default initialization, v1 is empty
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Copy construction, v2 has a copy of each element of v1
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// Equivalent to vector&amp;lt;T&amp;gt; v2(v1)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// v3 has n elements with value val
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// If T is a primitive type, v4 has n default value of T;
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;				 &lt;span class=&#34;c1&#34;&gt;// If T is a class, v4 has n objects initialize by default constructor
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...};&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// v5 has the element created by the corresponding initializers
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...};&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Equivalent to vector&amp;lt;T&amp;gt; v5{a, b, c...}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;容量&#34;&gt;容量&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;empty&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Return if the vector is empty, bool type
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Return the number of objects in vector, not necessary equal to the capacity
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;capacity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Return the size of storage currently allocated for the vector, capacity is equal to or great than size
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;			  &lt;span class=&#34;c1&#34;&gt;// When the capacity is exhausted, it will reallocate memory and copy the current objects 
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reserve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Reserve the capacity to be at least enpugh to contain n objects
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;访问&#34;&gt;访问&lt;/h2&gt;
&lt;p&gt;同数组(raw array)类似，可以通过方括号和指标访问vector的成员，它返回对该成员的引用，需要注意的一点是，这种方式并不会进行&lt;strong&gt;边界检测(bound-check)&lt;/strong&gt;，可能会导致未定义行为，at方法的作用是相同的，但是会进行边界检测，若出界，则会抛出一个异常：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// v is a vector of T type
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Return a reference to the element at position n, if n is
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;     &lt;span class=&#34;c1&#34;&gt;// out of range, it will causes undefined behavior
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// The same as [] but it will check bounds
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其他常用访问元素的操作包括：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;front&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Return a reference to the first element of v, if v is empty, it will causes undefined behavior
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;back&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// Return a reference to the last element of v, if v is empty, it will causes undefined behavior
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;修改&#34;&gt;修改&lt;/h2&gt;
&lt;p&gt;通常，我们会初始化一个空的vector，然后向其中添加成员：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push_back&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Add val to the end of v
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这种方法会调用到拷贝构造函数，在v内存的相应位置复制一个新的对象。如果增加成员导致新的size超过原先的capacity，那么需要重新分配足够的内存并将原来的成员全都复制过去。另一种方法可以避免插入时拷贝构造函数的调用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;emplace_back&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arg1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arg2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Construct a element at the end of vector according to the args
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pop_back&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eraser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;swap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;emplace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/computer-science/">Computer Science</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/programming-language/">Programming Language</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/cc-/">C&amp;C&#43;&#43;</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/c-/">C&#43;&#43;</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/stl/">STL</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>An Introduction to Constrained Optimization Problems</title>
                <link>https://zchencn.github.io/posts/constrainedoptimization/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/constrainedoptimization/</guid>
                <pubDate>Fri, 23 Oct 2020 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;约束优化问题(optimization problems)一般可以表示为如下形式：
$$
\min_{x\in R^n} f(x)\ s.t
\begin{cases}
c_i(x) = 0, i\in \mathcal{E}\
c_i(x) \geq 0, i \in \mathcal{I}
\end{cases}
$$
定义如下集合为可行域：
$$
\Omega = {x|c_i(x) = 0, i \in \mathcal{E}; c_i(x) \geq 0 , i\in\mathcal{I}}
$$
那么上述优化问题可以表示为：
$$
\min_{x\in \Omega}f(x)
$$&lt;/p&gt;
&lt;p&gt;同无约束问题类似，可以引入如下几个定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是全局最优解(global minimizer)如果$; f(x^&lt;/em&gt;)\leq f(x),\ \forall x \in \Omega;$;&lt;/li&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是局部最优解(local minimizer)如果存在$;x^&lt;/em&gt;;$的一个领域$;\mathcal{N};$使得$; f(x^*)\leq f(x),\ \forall x \in \mathcal{N}\cap\Omega;$;&lt;/li&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是严格局部最优解(strict local minimizer)如果存在$;x^&lt;/em&gt;;$的一个领域$;\mathcal{N};$使得$; f(x^&lt;em&gt;)&amp;lt; f(x),\ \forall x \neq x^&lt;/em&gt;\in \mathcal{N}\cap\Omega;$;&lt;/li&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是孤立局部最优解(strict local minimizer)如果存在$;x^&lt;/em&gt;;$的一个领域$;\mathcal{N};$使得$; x^*;$是该领域中的唯一局部最优解；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;例子&#34;&gt;例子&lt;/h2&gt;
&lt;h3 id=&#34;等式约束&#34;&gt;等式约束&lt;/h3&gt;
&lt;p&gt;考虑如下等式约束问题：
$$
\min f(x_1, x_2) = x_1 + x_2, s.t \quad c(x_1, x_2) = x_1^2 + x_2^2 - 2 = 0
$$
显然它的最优解是$;x^* = (-1, -1);$, 可以计算目标函数和约束在最优解处的梯度，$;\nabla f(x^&lt;em&gt;) = (1, 1)^T, \nabla c(x^&lt;/em&gt;) = (-2, -2) ;$， 可以发现这两个向量是平行的，也就是说存在$;\lambda  = \frac{1}{2};$使得$;\nabla f(x^&lt;em&gt;) = -\lambda \nabla c(x^&lt;/em&gt;);$.&lt;br&gt;
对$;c(x+d);$作一阶近似：
$$
c(x)\approx c(x) + \nabla c(x)^Td = \nabla c(x)^Td
$$
若要使得$;x+d;$仍然在可行域内，$;c(x)^Td = 0;$. 同样对$;f(x+d);$作一阶近似：
$$
f(x + d) = f(x) + \nabla f(x)^Td
$$
若要使得函数值得到下降，要求$;\nabla f(x)^Td &amp;lt; 0;$. 若要$;x;$是最优解，则不存在$;d;$同时满足上述两个条件，那么只能是$;\nabla f(x);$和$;\nabla c(x);$平行。&lt;br&gt;
引入拉格朗日(Lagrange)函数：
$$
L(x, \lambda) = f(x) + \lambda c(x)
$$
上述条件等价于要求存在$;\lambda;$使得$\nabla_x L(x^*, \lambda) = 0$.&lt;/p&gt;
&lt;h3 id=&#34;不等式约束&#34;&gt;不等式约束&lt;/h3&gt;
&lt;p&gt;考虑如下不等式约束问题：
$$
\min f(x_1, x_2) = x_1 + x_2, s.t \quad c(x_1, x_2) = x_1^2 + x_2^2 - 2 \leq 0
$$
同样的，若要使得$;x + d;$的函数值得到下降，则：
$$
\nabla f(x)^Td &amp;lt; 0
$$
又要保持$;x+d;$在可行域内，则：
$$
c(x) + \nabla c(x)^Td \leq 0
$$
假如$;x;$在可行域的内部，即$;c(x) &amp;lt; 0;$, 那么对任意一个向量，只要它的模足够小，都能使$;x+d;$在可行域内，取：
$$
d = -\alpha \nabla f(x)
$$
要使得不存在这样的向量同时满足上述两个条件，只能是$;\nabla f(x) = 0;$; 假如$;x;$在可行域的边界，即$;c(x) = 0;$, 那么第二个式子变成：
$$
\nabla c(x)^Td \leq 0
$$
同样的，要使两个条件不能同时满足，只能是$;\nabla f(x) = -\mu \nabla c(x), \mu \geq 0;$.&lt;br&gt;
引入拉格朗日函数：
$$
L(x, \mu) = f(x) + c(x)
$$
上述条件等价于要求在最优解处：
$$
\nabla_x L(x^&lt;em&gt;, \mu) = 0, \mu \geq 0
$$
且$;\mu c(x^&lt;/em&gt;)=0;$,这个条件称为互补条件。&lt;/p&gt;
&lt;h2 id=&#34;约束限制&#34;&gt;约束限制&lt;/h2&gt;
&lt;p&gt;我们首先引入几个概念。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对可行域内一点$;x;$, 称$;\mathcal{A}(x) = \mathcal{E} \cup {i\in\mathcal{I}, c_i(x) = 0 };$为积极集(active set)。也就是说在该点为0的约束是积极约束(active constraint)，非零的是非积极约束(inactive constraint).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;我们称$;{z_k};$是一个逼近$;x;$的可行序列(feasible sequence)如果$;z_k \in \Omega;$且对充分大的$;k;$有$;k\to x;$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;向量$;d;$ 是可行域$;\Omega;$在$;x;$的切(tagent)如果存在一个逼近$;x;$的可行序列$;{z_k};$和一个逼近0的正实数序列$;t_k;$使得$;\lim_{k\to\infty}\frac{z_k-x}{t_k} = d;$. 记所有这样的向量$;d;$构成的集合为$;T_{\Omega}(x);$, 它是一个锥($;d\in T_{\Omega}(x), \Rightarrow\alpha d \in T_{\Omega}(x), \alpha &amp;gt; 0;$), 称为切锥。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据上面例子的演示，我们利用约束函数的一阶近似，来估计它在某点附近的行为，所以引进下面的线性可行方向集合(linearized feasible direction set):
$$
\mathcal{F(x)} = {d| \nabla c_i(x)^Td = 0, i \in \mathcal{E}; \nabla c_i(x)^Td \geq 0, i\in\mathcal{A}\cap \mathcal
{I}}
$$
同样容易验证, $;\mathcal{F}(x);$也是一个锥。后面我们会证明，在某些特殊情况，$;\mathcal{F}(x) = T_{\Omega}(x);$.&lt;br&gt;
最后介绍一个约束限制条件，线性无关约束限制(Linearly Independent Constraint Qualification), 称LICQ成立如果${\nabla c_i(x), i\in\mathcal{A}}$线性无关。&lt;/p&gt;
&lt;h2 id=&#34;一阶必要条件&#34;&gt;一阶必要条件&lt;/h2&gt;
&lt;p&gt;对于一般的约束优化问题，我们称如下函数是它的拉格朗日函数：
$$
L(x, \lambda) = f(x) - \sum_{i\in \mathcal{I}\cup\mathcal
{E}}\lambda_ic_i(x)
$$
一阶必要性条件又称KKT条件，它是很多约束优化问题算法的基础。如果$;x^&lt;em&gt;;$是约束优化问题的局部最优解，且在该点处LICQ条件成立，$;f,c_i;$连续可微，那么存在拉格朗日乘子向量(Lagrange multiplier vector)$;\lambda^&lt;/em&gt; ;$使得：
$$
\begin{cases}
\nabla L(x^&lt;em&gt;, \lambda^&lt;/em&gt;) = 0\
c_i(x^&lt;em&gt;) = 0, i\in\mathcal{E}\
c_i(x^&lt;/em&gt;) \geq 0, i\in\mathcal{I}\
\lambda^&lt;em&gt;_i\geq 0, i\in\mathcal{I}\
\lambda^&lt;/em&gt;_ic_i(x^*) = 0, i\in\mathcal{E}\cup\mathcal{I}
\end{cases}
$$
其中最后一个条件称为互补条件，这意味着，非积极约束对应的拉格朗日乘子均为0。进一步的，如果对任意的约束和对应的拉格朗日乘子，一定有一个为0，我们称满足严格互补条件。&lt;br&gt;
下面我们简要概述一阶必要性条件的证明。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/optimization/">Optimization</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/optimization/">Optimization</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>An Introduction to Unconstrained Optimization Problems</title>
                <link>https://zchencn.github.io/posts/unconstrainedoptimization/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/unconstrainedoptimization/</guid>
                <pubDate>Fri, 23 Oct 2020 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;p&gt;优化问题(optimization problems)一般可以表示为如下形式：
$$
\min_{x\in R^n} f(x)\ s.t
\begin{cases}
c_i(x) = 0, i\in \mathcal{E}\
c_i(x) \geq 0, i \in \mathcal{I}
\end{cases}
$$
称$;f;$为目标函数(object function), $; x;$为决策变量(decision variable), $; c_i;$为约束函数(constraint function).&lt;/p&gt;
&lt;h2 id=&#34;凸性&#34;&gt;凸性&lt;/h2&gt;
&lt;p&gt;称集合$; S;$是凸(convex)集，如果连接集合内任何两点的线段全都包含在该集合内，即：
$$
\forall x, y \in S, \alpha x + (1-\alpha)y \in S, \forall \alpha \in [0, 1]
$$
称函数$; f;$是凸函数，如果它的定义域是凸集且对定义域内的任意两点$; x, y;$有如下性质：
$$
f(\alpha x + (1-\alpha)y)\leq \alpha f(x) + (1-\alpha)f(y), \forall \alpha \in [0, 1]
$$
如果上述不等式在$; x\neq y, \alpha\in(0, 1);$时严格成立，则称函数是严格凸(strictly convex)的。称函数是凹(concave)的，如果$; -f;$是凸的。&lt;br&gt;
接下来我们考虑无约束优化问题，即$;\mathcal{I}=\mathcal{E}=\empty;$,
$$
\min_{x\in R^n}\ f(x)
$$&lt;/p&gt;
&lt;h2 id=&#34;定解条件&#34;&gt;定解条件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是全局最优解(global minimizer)如果$; f(x^&lt;/em&gt;)\leq f(x),\ \forall x \in R^n;$;&lt;/li&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是局部最优解(local minimizer)如果存在$;x^&lt;/em&gt;;$的一个领域$;\mathcal{N};$使得$; f(x^*)\leq f(x),\ \forall x \in \mathcal{N};$;&lt;/li&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是严格局部最优解(strict local minimizer)如果存在$;x^&lt;/em&gt;;$的一个领域$;\mathcal{N};$使得$; f(x^&lt;em&gt;)&amp;lt; f(x),\ \forall x \neq x^&lt;/em&gt;\in \mathcal{N};$;&lt;/li&gt;
&lt;li&gt;称$;x^&lt;em&gt;;$是孤立局部最优解(strict local minimizer)如果存在$;x^&lt;/em&gt;;$的一个领域$;\mathcal{N};$使得$; x^*;$是该领域中的唯一局部最优解；
一般来说，要得到全局最优解是十分困难的，但是当目标函数$;f;$是凸函数时，可以证明局部最优就是全局最优。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;（一阶必要性条件）如果$;x^&lt;em&gt;;$是一个局部最优解，且$;f;$在$;x;$的一个开领域内连续可微，那么$;\nabla f(x^&lt;/em&gt;) = 0;$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假设$;\nabla f(x^&lt;em&gt;)\neq 0;$,我们可以沿着负梯度方向，设为$;p;$, 找到一个的点有更小的函数值，由泰勒展开可得：
$$
f(x^&lt;/em&gt; + tp) = f(x^&lt;em&gt;) +  tp^T\nabla f(x^&lt;/em&gt; + \overline{t}p), \overline{t}\in (0, t)
$$
而由于$;p = -\nabla f(x^&lt;em&gt;)$, $; p^T\nabla f(x^&lt;/em&gt;) = - ||\nabla f(x^&lt;em&gt;)||^2_2 &amp;lt; 0$，由连续可微的条件可知，我们可以选取足够小的$t;$，使得：
$$
tp^T\nabla f(x^&lt;/em&gt; + \overline{t}p) &amp;lt; 0
$$
此时$; f(x^* + tp) &amp;lt; f(x^&lt;em&gt;)$, 与$;x^&lt;/em&gt;;$是局部最优解矛盾。由此，我们证明了一阶必要性条件。&lt;br&gt;
我们称梯度为零的点为稳定点(stationary point), 那么由一阶必要性条件可知，局部最优解必定是稳定点。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（二阶必要性条件）如果$;x^&lt;em&gt;;$是一个局部最优解，且$;\nabla^2 f(x^&lt;/em&gt;);$存在并且在$;x^&lt;em&gt;;$的一个开领域内连续，那么$;\nabla f(x^&lt;/em&gt;) = 0, \nabla^2f(x^*)$半正定。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假如$;\nabla^2 f(x^&lt;em&gt;);$不是半正定的，则可以选取向量$;p;$使得：
$$
p^T\nabla^2 f(x^&lt;/em&gt;)p &amp;lt; 0
$$
对$;f(x^* + tp);$作泰勒展开：
$$
f(x^* + tp) = f(x^&lt;em&gt;) + tp^T\nabla f(x^&lt;/em&gt;) + \frac{t^2}{2}p^T\nabla^2 f(x^* + \overline{t}p)p, \overline{t}\in (0, t)
$$
同样的可以选取足够小的$t;$使得$;f(x^&lt;em&gt;+tp)&amp;lt;f(x^&lt;/em&gt;);$, 从而得到矛盾。&lt;br&gt;
特殊的，我们还可以导出一个充分条件。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（二阶充分条件）假设$;\nabla^2 f(x^&lt;em&gt;);$在$;x^&lt;/em&gt;;$的一个开领域内连续且$;\nabla f(x^&lt;em&gt;) = 0;$以及$;\nabla^2 f(x^&lt;/em&gt;);$正定，那么$;x^*;$是一个严格局部最优解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同样的作泰勒展开：
$$
f(x^* + p) = f(x^&lt;em&gt;) + p^T\nabla f(x^&lt;/em&gt;) + \frac{1}{2}p^T\nabla^2 f(z)p &amp;gt; f(x^&lt;em&gt;)
$$
注意，充分条件不是必要条件，也就是说存在$;x^&lt;/em&gt;;$是严格局部最优解但是不满足二阶充分条件的情况，比如$;f(x)=x^4, x^*=0.;$&lt;/p&gt;
&lt;p&gt;当$;f(x);$是凸函数时，局部最优解和全局最优解的刻画会变得很容易。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当$;f(x);$是凸函数时，局部最优解就是全局最优解。进一步，如果$;f(x);$是可微的，那么稳定点就是全局最优解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假设$;x^&lt;em&gt;;$不是全局最优解，那么存在$;z;$使得$;f(z) &amp;lt; f(x);$, 取$;x = \lambda z + (1 - \lambda)x^&lt;/em&gt;, \lambda \in (0, 1);$, 那么由凸性：
$$
f(x) = f(\lambda z + (1 - \lambda)x^&lt;em&gt;) &amp;lt; \lambda f(z) + (1-\lambda)f(x^&lt;/em&gt;) &amp;lt; f(x^&lt;em&gt;)
$$
对$;x^&lt;/em&gt;;$的任一个领域，都可以选取合适的$;\lambda;$使得$;x;$在里面，这与$;x^&lt;em&gt;;$是局部最优解矛盾。&lt;br&gt;
假如$;f(x);$是可微的，若稳定点$;x^&lt;/em&gt;;$不是全局最优解，那么：
$$
\begin{array}{ll}
\nabla f(x^&lt;em&gt;)^T(z - x^&lt;/em&gt;) &amp;amp;= \frac{d}{d\lambda}f(x^* + \lambda (z - x^&lt;em&gt;))|&lt;em&gt;{\lambda = 0}\
&amp;amp;= \lim&lt;/em&gt;{\lambda\to 0}\frac{f(x^&lt;/em&gt; + \lambda (z-x^&lt;em&gt;)) - f(x^&lt;/em&gt;)}{\lambda}\
&amp;amp;&amp;lt; f(z) - f(x^&lt;em&gt;) &amp;lt; 0
\end{array}
$$
这与$;\nabla f(x^&lt;/em&gt;) = 0;$矛盾。&lt;/p&gt;
&lt;p&gt;因此，无约束凸优化问题全局最优解的充要条件就是$;\nabla f(x^*) = 0;$。后续的算法，也是在寻找这样的稳定点。&lt;/p&gt;
&lt;h2 id=&#34;算法概述&#34;&gt;算法概述&lt;/h2&gt;
&lt;p&gt;通常我们用迭代法求解无约束优化问题。也就是说，算法需要一个初始点$;x_0;$，我们可以利用对问题的已知信息来得到一个解的估计作为初始点，或者任意选取。求解算法利用当前点或已求出点的信息，依次求出$;x_1, x_2, \cdots,x_k,\cdots;$从而得到一个对解的逼近序列，当$;k;$足够大时，$;x_k;$可以作为解的良好估计。&lt;br&gt;
通常的求解算法可以分为两类：线搜索方法和信赖域方法。&lt;/p&gt;
&lt;h3 id=&#34;线搜索&#34;&gt;线搜索&lt;/h3&gt;
&lt;p&gt;线搜索方法概括的说就是从当前点沿着某一个方向走一定的步长从而使得函数值降低（这个不一定每步都需要）得到新的点，即：
$$
x_{k+1} = x_k + \alpha_k p_k
$$
其中$;p_k;$称为搜索方向(search direction), $;\alpha_k;$称为步长(step length).  &lt;br&gt;
如何选取搜索方向？最自然的选择就是当前点下降最快的方向，最速下降方向(steepest desent direction), 即$;p_k = -\nabla f(x_k);$，且满足$;p_k^T\nabla f(x_k) &amp;lt; 0;$(称下降条件，满足该条件的称下降方向)，但是问题复杂时，最速下降方向的计算效率可能很低。其他通常的搜索方向选取还有牛顿方向$;p_k = -(\nabla^2f(x_k))^{-1}\nabla f(x_k) ;$和拟牛顿(quasi-Newton)方向$;p_k = -(B_k)^{-1}\nabla f(x_k);$.&lt;/p&gt;
&lt;h3 id=&#34;信赖域&#34;&gt;信赖域&lt;/h3&gt;
&lt;p&gt;信赖域方法的基本思想是在当前点的附近用一个模型$;m_k(x);$来近似目标函数，求解的问题为：
$$
\min_{||p||&amp;lt;\Delta} m_k(x_k + p) = f(x_k) + \nabla f(x_k)^Tp + \frac{1}{2}p^TB_kp
$$
其中$;\Delta;$称为信赖域半径，$;x_{k+1} = x_k + p;$. 当$;f(x_{k+1};$m没有使$;f;$产生充分的减小的话，我们认为模型对原目标函数近似的不是很好，从而应该缩小信赖域半径。当$;B_k = \nabla^2 f(x_k);$时，称之为信赖域牛顿法。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/optimization/">Optimization</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/optimization/">Optimization</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>SEM</title>
                <link>https://zchencn.github.io/posts/sem/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/sem/</guid>
                <pubDate>Fri, 23 Oct 2020 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h1 id=&#34;谱元法简介&#34;&gt;谱元法简介&lt;/h1&gt;
&lt;p&gt;谱元法(&lt;strong&gt;S&lt;/strong&gt;pectral &lt;strong&gt;E&lt;/strong&gt;lement &lt;strong&gt;M&lt;/strong&gt;ethod)结合了谱方法的高精度性和有限元方法对于不规则求解区域的灵活性。&lt;br&gt;
谱元法的求解一般可以分为五个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将PDE改写成弱形式(Weak Form)&lt;/li&gt;
&lt;li&gt;将求解区域分隔为若干个小的单元&lt;/li&gt;
&lt;li&gt;用有限空间内的分片多项式函数近未知函数&lt;/li&gt;
&lt;li&gt;代入弱形式并数值求解上述过程得到的积分得到单元上的矩阵表示&lt;/li&gt;
&lt;li&gt;将矩阵拼装得到最后求解的线性方程组&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面用一个例子具体说明这些步骤。&lt;br&gt;
考虑如下赫姆霍兹方程(Helmholtz Equation)：
$$
-\nabla^2u + ku = f, x\in \Omega = [a, b]
$$
以及如下迪利克雷边界条件(Dirchlet Boundary Condition)：
$$
u(a) = u(b) = 0
$$&lt;/p&gt;
&lt;h2 id=&#34;弱形式&#34;&gt;弱形式&lt;/h2&gt;
&lt;p&gt;设好的函数$v$同样满足迪利克雷边界条件，我们称它为测试函数(Test Function). 在方程两端同时乘上$v$并且在整个求解区域上做积分，运用分部积分公式可得：
$$
\int_a^b\frac{\partial u}{\partial x}\frac{\partial v}{\partial x} \ dx + k\int_a^buv \ dx = \int_a^b fv \ dx
$$
可以证明，对任意测试函数都满足上式的$u$与原方程的解等价。&lt;br&gt;
严谨的证明参考有限元方法数学理论的相关书籍。&lt;/p&gt;
&lt;h2 id=&#34;剖分&#34;&gt;剖分&lt;/h2&gt;
&lt;p&gt;将$\Omega = [a, b]$剖分成$N_e$个小单元，$\Omega = \cup_{e=1}^{N_e}\Omega_e, \Omega_e = [X_{e-1}, X_e], X_0 = a, X_{N_e} = b.$ 为方便后续的讨论和求积分，建立一个标准单元（参考单元）到$\Omega_e$的映射：
$$
F^e:  [-1, 1] \longrightarrow \Omega_e, x = F^e(\xi) = \frac{X_{e} - X_{e-1}}{2}\xi + \frac{X_e + X_{e-1}}{2}
$$
相反的有：
$$
\xi = (F^e)^{-1}(x) = \frac{2x - X_e - X_{e-1}}{X_e - X_{e-1}}
$$
二维的情况类似, 其中$\Omega_e$变成顶点为$P^e_1, P^e_2, P^e_3, P^e_4$(从左下按逆时针顺序编号)的四边形，同样的可以建立标准单元到$\Omega_e$的映射：
$$
F^e:  [-1, 1]^2 \longrightarrow \Omega_e, F^e(\xi, \eta) = \sum_{a=1}^4P^e_aN_a(\xi, \eta)
$$
其中：
$$
N_1 = \frac{1-\xi}{2}\cdot\frac{1-\eta}{2}, \ N_2 = \frac{1 + \xi}{2}\cdot\frac{1 - \eta}{2} \ N_3 = \frac{1 + \xi}{2}\cdot\frac{1 + \eta}{2}, \ N_4 = \frac{1 - \xi}{2}\cdot \frac{1 + \eta}{2}
$$&lt;/p&gt;
&lt;h2 id=&#34;多项式近似&#34;&gt;多项式近似&lt;/h2&gt;
&lt;p&gt;在每个单元上我们使用GLL(Gauss-Legendre-Labotto)求积公式节点的拉格朗日(Lagrange)多项式来近似函数。假设GLL点为$\xi_0 = -1, \xi_1, \cdots, \xi_n = 1$，则各个单元上的节点为：
$$
x^e_i = F^e(\xi_i), i=0,1, \cdots,n
$$
记全局节点为：
$$
x_I = x^e_i , I = I(e, i) = (e - 1)n + i
$$
$I$可以取从$0$到$N_e\times n$的所有整数，共$N_e\times n + 1$个。
在每个单元上，我们有：
$$
u(x) = u(x(\xi)) = u(F^e(\xi)) \coloneqq u^e(\xi) \approx \sum_{i=0}^nu^e_il_i(\xi) = \sum_{i=0}^nu^e_il_i((F^e)^{-1}(x)) \coloneqq \sum_{i=0}^nu^e_i\phi^e_i
$$
其中：
$$
u^e_i = u^e(\xi_i) = u(F^e(\xi_i)), \phi_i^e(x) = l_i((F^e)^{-1}(x))
$$
对于一阶导数，我们有:&lt;/p&gt;
&lt;!--
$$
\frac{\partial u}{\partial x} = \frac{\partial u^e(\xi)}{\partial \xi}\frac{\partial \xi}{\partial x} = \frac{2}{L_e}\frac{\partial u^e(\xi)}{\partial \xi} \approx \frac{2}{L_e}\sum_{i=0}^nu^e_i\frac{\partial l_i}{\partial \xi}, \ L_e = X_e - X_{e-1} 
$$
--&gt;
&lt;p&gt;$$
\frac{\partial u}{\partial x} \approx \sum_{i=0}^n
u^e_i\frac{\partial \phi^e_i}{\partial x}$$&lt;/p&gt;
&lt;p&gt;对于二维的情况，我们选择的插值基函数是拉格朗日多项式的乘积，记：
$$
\phi_I(\xi, \eta) = l_i(\xi)l_j(\eta), I = i + j(n + 1)
$$
则在每个子区域上：
$$
u(x, y) = u(F^e(\xi, \eta)) = u^e(\xi, \eta) \approx \sum_{i,j=0}^{1+n}u^e_{i,j}l_i(\xi)l_j(\eta) = \sum_{I=0}^{(n+1)^2}u^e_I\phi_I(\xi, \eta) = \sum_{I=0}^{(n+1)^2}u^e_I\phi_I^e(x, y)
$$
其中：
$$
u^e_{i,j} = u^e(\xi_i, \eta_j) = u(F^e(\xi_i, \eta_j)), u^e_I = u^e_{i, j} \
\phi_I^e(x, y) = \phi_I((F^e)^{-1}(x, y)), I = i + j(n + 1),\ i,j = 0, 1, \cdots, n
$$
对于偏导数：&lt;/p&gt;
&lt;!--
$$
\frac{\partial u}{\partial x} = \frac{\partial u^e}{\partial \xi}\frac{\partial \xi}{\partial x} + \frac{\partial u^e}{\partial \eta}\frac{\partial \eta}{\partial x} \approx \sum_{i,j = 0}^{n+1}u^e_{i,j}\left(\frac{\partial l_i(\xi)}{\partial \xi}l_j(\eta)\frac{\partial \xi}{\partial x} + \frac{\partial l_j(\eta)}{\partial \eta}l_i(\xi)\frac{\partial \eta}{\partial x}\right) \\

\frac{\partial u}{\partial y} = \frac{\partial u^e}{\partial \xi}\frac{\partial \xi}{\partial y} + \frac{\partial u^e}{\partial \eta}\frac{\partial \eta}{\partial y} \approx \sum_{i,j = 0}^{n+1}u^e_{i,j}\left(\frac{\partial l_i(\xi)}{\partial \xi}l_j(\eta)\frac{\partial \xi}{\partial y} + \frac{\partial l_j(\eta)}{\partial \eta}l_i(\xi)\frac{\partial \eta}{\partial y}\right)
$$
--&gt;
&lt;p&gt;$$
\frac{\partial u}{\partial x} \approx \sum_{I=0}^{(n+1)^2}u^e_I\frac{\partial \phi^e_I}{\partial x}, \frac{\partial u}{\partial y} \approx \sum_{I=0}^{(1+n)^2}u^e_I\frac{\partial \phi^e_I}{\partial y}
$$&lt;/p&gt;
&lt;h2 id=&#34;数值积分&#34;&gt;数值积分&lt;/h2&gt;
&lt;p&gt;在每个单元上, 选取测试函数为任意插值基函数，由方程的弱形式可以得到：
$$
\int_{\Omega_e} u\phi^e_j\ dx \approx \sum_{i=0}^nu^e_i\int_{\Omega_e} \phi^e_i\phi^e_j\ dx \coloneqq \sum_{i=0}^nM^e_{j ,i}u^e_i, \forall j = 0, 1, \cdots, n
$$
其中：
$$
M^e_{j,i} = \int_{\Omega_e}\phi^e_i\phi^e_j\ dx = \int_{-1}^1l_i(\xi)l_j(\xi)\frac{\partial x}{\partial \xi}\ d\xi \approx \frac{L_e}{2}w_i\delta_{j, i}
$$
所以单元质量矩阵(Mass Matrix)是一个对角矩阵。&lt;br&gt;
再考虑含有导数的部分：
$$
\int_{\Omega_e}\frac{\partial u}{\partial x}\frac{\partial \phi^e_j}{\partial x}\ dx \approx \sum_{i=0}^nu^e_i\int_{\Omega_e}\frac{\partial \phi^e_i}{\partial x}\frac{\partial \phi^e_j}{\partial x}\ dx \coloneqq \sum_{i=0}^nK^e_{j, i}u^e_i, \forall j = 0, 1, \cdots, n
$$
其中：
$$
K^e_{j, i} = \int_{\Omega_e}\frac{\partial \phi^e_i}{\partial x}\frac{\partial \phi^e_j}{\partial x}\ dx = \int_{-1}^1\left(\frac{\partial \xi}{\partial x}\right)^2\frac{\partial l_i}{\partial \xi}\frac{\partial l_j}{\partial \xi}\frac{\partial x}{\partial \xi}\ d\xi = \frac{2}{L_e}\sum_{k=0}^nw_kd_{i,k}d_{j, k}\
d_{i, k} = l&#39;&lt;em&gt;i(\xi_k), d&lt;/em&gt;{j, k} = l_j&#39;(\xi_k)
$$
我们有：
$$
K^e = \left(\frac{2}{L_e}\right)^2DM^eD^t
$$
单元刚度矩阵(Stifness Matrix)$K^e$是对称矩阵。
最后，右端项：
$$
f^e_j \coloneqq \int_{\Omega_e}f\phi^e_j\ dx = \frac{L_e}{2}\int_{-1}^1f(F^e(\xi))l_j(\xi)\ d\xi \approx \frac{w_jL_e}{2}f(F^e(\xi_j))
$$
对于二维的情况：
$$
\int_{\Omega_e}u\phi^e_J\ dS \approx \sum_{I=0}^{(1+n)^2}u^e_I\int_{\Omega_e}\phi^e_I\phi^e_J\ dS = \sum_{I=0}^{(1+n)^2}M^e_{J, I}u^e_I
$$
其中：
$$
M^e_{J, I} = \int_{\Omega_e}\phi^e_I\phi^e_J\ dS = \int_{-1}^1\int_{-1}^1\phi_I\phi_J J^e\ d\xi d\eta = w_iw_jJ^e(\xi_i, \xi_j)\delta_{I, J}, I = I(i, j) = J
$$&lt;/p&gt;
&lt;h2 id=&#34;线性方程组&#34;&gt;线性方程组&lt;/h2&gt;
&lt;p&gt;弱形式经过上面的近似和数值积分，得到：
$$
\sum_{e=1}^{N_e}\sum_{i=0}^nK^e_{j,i}u^e_i + k\sum_{e=1}^{N_e}\sum_{i=0}^{n}M^e_{j,i}u^e_i = \sum_{e=1}^{N_e}f^e_j
$$
全局质量矩阵：
$$
M = \sum_{e=1}^{Ne}M^e =
\begin{pmatrix}
M^1_{0,0} &amp;amp;        &amp;amp;                     &amp;amp; \
&amp;amp; \ddots &amp;amp;                     &amp;amp; \
&amp;amp;        &amp;amp; M^1_{n,n}+M^2_{0,0} &amp;amp; \
&amp;amp;        &amp;amp;                     &amp;amp; \ddots&lt;/p&gt;
&lt;p&gt;\end{pmatrix}
$$
$M$是一个$n\times N_e + 1$的方阵。&lt;br&gt;
全局刚度矩阵：
$$
K = \sum_{e=1}^{Ne}K^e =
\begin{pmatrix}
K^1_{0,0} &amp;amp; \cdots &amp;amp; K^1_{0, n}                     &amp;amp; \
\vdots        &amp;amp; \ddots &amp;amp;         \vdots            &amp;amp; \
K^1_{n, 0}        &amp;amp; \cdots       &amp;amp; M^1_{n,n}+M^2_{0,0} &amp;amp; \
&amp;amp;        &amp;amp;                     &amp;amp; \ddots&lt;/p&gt;
&lt;p&gt;\end{pmatrix}
$$
同样也是一个$n\times N_e + 1$的方阵。&lt;br&gt;
则最终的线性方程组是：
$$
(K +kM)\underline{u} = \underline{f}
$$
其中：
$$
\underline{u} = (u_0, u_1, \cdots, u_{n\times N_e + 1})^t \
\underline{f} = (f^1_0, \cdots,f^1_n + f^2_0, \cdots, f^{N_e}_n)^t
$$&lt;/p&gt;
&lt;p&gt;二维的情况类似，这里就不再赘述。&lt;/p&gt;
&lt;p&gt;求解上述得到的线性方程组，就可以得到微分方程的数值解。&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/numerical-analysis/">Numerical Analysis</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/numerical-quadrature/">Numerical Quadrature</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/sem/">SEM</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/pde/">PDE</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Gaussian Quadrature</title>
                <link>https://zchencn.github.io/posts/gaussianquadrature/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/gaussianquadrature/</guid>
                <pubDate>Sat, 27 Jun 2020 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h1 id=&#34;高斯求积&#34;&gt;高斯求积&lt;/h1&gt;
&lt;h2 id=&#34;数值积分&#34;&gt;数值积分&lt;/h2&gt;
&lt;p&gt;考虑带权的积分如下：
$$
\int_a^bf(x)w(x)dx
$$
其中 $w(x) \geq 0, \int_a^bw(x)dx &amp;gt; 0$，称$w(x)$为权。一般的数值积分公式有如下的形式：
$$
\int_a^bw(x)f(x)dx \approx \sum_{i=0}^nw_if(x_i)
$$
即用$n+1$ 个函数值的加权和来近似积分的值。&lt;/p&gt;
&lt;p&gt;我们记以$x_i(i=0,1,\cdots,n)$ 为节点的拉格朗日(Langrange)插值多项式为：
$$
L_n(x)=\sum_{i=1}^nf(x_i)l_i(x)
$$
其中$l_i(x)$是拉格朗日插值基函数，即：
$$
l_i(x) = \frac{\prod_{k=0,k\neq i}^n(x-x_k)}{\prod_{k=0,k\neq i}^n(x_i-x_k)}
$$
则：
$$
f(x)=L_n(x)+R[f],\quad R[f]=\frac{1}{(n+1)!}f^{(n+1)}(\xi)(x-x_0)(x-x_1)\cdots(x-x_n)
$$&lt;/p&gt;
&lt;p&gt;有：
$$
\int_a^bw(x)f(x)dx=\left(\sum_{i=0}^n\int_a^bw(x)l_i(x)dx\right)f(x_i)+\int_a^bw(x)R[f]dx
$$&lt;/p&gt;
&lt;p&gt;一般我们取$w_i =\int_a^bw(x)l_i(x)dx$ ，则数值积分公式的误差就是上式等号右侧的第二项，当$f(x)$ 是不超过$n$ 次的多项式时，容易看出误差为0。若数值积分公式对不超过$k$ 次的多项式精确成立，我们就称它的&lt;strong&gt;代数精度&lt;/strong&gt;为$k$ 。所以上述数值积分公式的代数精度至少为$n$。&lt;/p&gt;
&lt;p&gt;另一方面，数值积分公式中含有$n+1$ 个$w_i$ 和$n+1$个$x_i$ ，共$2n+2$ 个自由度，所以可以想象通过适当选取节点$x_i$ ，它的代数精度最多可以为$2n+1$ 。我们把具有$2n+1$ 次代数精度的求积公式称为&lt;strong&gt;高斯求积公(GaussianQuadrature)&lt;/strong&gt;，其节点$x_i(i=0,1,\cdots,n)$ 称为&lt;strong&gt;高斯点&lt;/strong&gt;。接下来讨论怎么选取合适的点作为高斯点。&lt;/p&gt;
&lt;h2 id=&#34;正交多项式与高斯点&#34;&gt;正交多项式与高斯点&lt;/h2&gt;
&lt;p&gt;称多项式$p(x), q(x)$ （带权）正交如果：
$$
\int_a^bw(x)p(x)q(x)dx=0
$$
假设以$x_i(i=0,1,\cdots,n)$ 为零点的多项式$p(x)=(x-x_0)(x-x_1)\cdots(x-x_n)$ 与任何不超过$n$次的多项式正交，由多项式的带余除法可知，对于不超过$2n+1$次的多项式$f(x)$ ，有不超过$n$ 次的多项式$q(x), r(x)$ 使得：
$$
f(x)=p(x)q(x)+r(x)
$$
那么：
$$
\int_a^bw(x)f(x)dx=\int_a^bw(x)p(x)q(x)dx+\int_a^bw(x)r(x)dx=\int_a^bw(x)r(x)dx=\sum_{i=0}^nw_ir(x_i)
$$
又：
$$
f(x_i)=p(x_i)q(x_i)+r(x_i)=r(x_i)
$$
所以：
$$
\int_a^bw(x)f(x)dx=\sum_{i=0}^nw_if(x_i)
$$
通过这种方式，我们发现只要选取节点为正交多项式的零点就可以得到高斯求积公式。&lt;/p&gt;
&lt;h2 id=&#34;gauss-legendre&#34;&gt;Gauss-Legendre&lt;/h2&gt;
&lt;p&gt;取$[a,b]=[-1,1],w(x)=1$，由${1,x,x^2,\cdots}$ 正交化得到的多项式称为勒朗德(Legendre)多项式，一般记为$L_n(x)$ 。我们只要选取节点为$L_{n+1}(x)$ 的零点就可以得到高斯-勒朗德求积公式。&lt;/p&gt;
&lt;h2 id=&#34;gauss-chebyshev&#34;&gt;Gauss-Chebyshev&lt;/h2&gt;
&lt;p&gt;取$[a,b]=[-1,1],w(x)=\frac{1}{\sqrt{1-x^2}}$，由${1,x,x^2,\cdots}$ 正交化得到的多项式称为切比雪夫(chebyshev)多项式，一般记为$T_n(x)$ 。我们只要选取节点为$T_{n+1}(x)$ 的零点就可以得到高斯-切比雪夫求积公式。&lt;/p&gt;
&lt;!--

## Gauss-Radau

取$[a,b]=[-1,1]$ ，且固定$x_0=-1$ ，取：
$$
p(x)=p_{n+1}(x)+ap_n(x)
$$
取合适的$a$ 使得$p(-1)=0$ ，$x_1,x_2,\cdots,x_n$ 是$p(x)$剩余的零点，则对任意次数不超过$2n$ 的多项式$f(x)$ ：
$$
f(x)=p(x)q(x)+r(x),
$$
$r(x)$ 的次数不超过$n$ ，$q(x)$ 的次数不超过$n-1$ ，且$f(x_i)=r(x_i)$ ，那么
$$
\sum_{i=0}^nw_if(x_i)=\sum_{i=0}^nw_ir(x_i)=\int_{-1}^1w(x)r(x)dx=\int_{-1}^1w(x)f(x)-w(x)p(x)q(x)dx
$$
其中：
$$
\int_{-1}^1w(x)p(x)q(x)dx=\int_{-1}^1w(x)p_{n+1}(x)q(x)dx+a\int_{-1}^1w(x)p_n(x)q(x)dx=0
$$
于是有：
$$
\int_{-1}^1w(x)f(x)dx=\sum_{i=1}^nw_if(x_i),\quad \forall f(x)\in P_{2n}
$$
--&gt;
&lt;h2 id=&#34;gauss-labotto&#34;&gt;Gauss-Labotto&lt;/h2&gt;
&lt;p&gt;取$[a,b]=[-1,1]$ ，如果我们想在求积节点中包含两个区间端点，即固定$x_0=-1,x_n=1$，这种方式称为Gauss-Labotto求积。此时，自由度只有$2n$($n+1$个权和$n-1$节点)，可以想象至多达到$2n-1$阶代数精度。&lt;br&gt;
对任意2n-1次多项式$p_{2n-1}$，同样由多项式的带余除法可以得到：
$$
p_{2n-1} - L_n= (1-x^2)(x-x_1)\cdots(x-x_{n-1})q(x) + r(x),
$$
其中$q(x)\in P_{n-2}, r(x)\in P_n$，且$r(x_i) = 0(i = 0, 1, \cdots,n)$，所以$r(x) \equiv 0$，那么数值积分的误差项为：
$$
E(x) = \int_{-1}^1(1-x^2)(x-x_1)\cdots(x-x_{n})q(x)
$$
我们选取$x_1, x_2, \cdots, x_{n-1}$是$n-1$次Labotto多项式的零点，有$E(x)=0$.&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/math/">Math</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/numerical-analysis/">Numerical Analysis</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/numerical-quadrature/">Numerical Quadrature</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/numerical-quadrature/">Numerical Quadrature</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>An Introduction to Make</title>
                <link>https://zchencn.github.io/posts/makefiles/</link>
                <guid isPermaLink="true">https://zchencn.github.io/posts/makefiles/</guid>
                <pubDate>Sat, 21 Dec 2019 00:00:00 &#43;0000</pubDate>
                
                    <author>zchen@lsec.ac.cc.cn (zchen)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)</copyright>
                
                    <description>&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;p&gt;make是控制如何从源文件(source file)生成可执行文件(excutable)及其他非源文件(non-source file)的一种工具。make工具通过makefile中说明的方式，构建(build)整个程序(program)。在一个庞大的项目中可能包含很多个源文件，修改少部分源文件可能需要重新编译整个程序，这个过程耗时耗力，通过使用make工具可以只重新编译依赖于修改过的文件的部分，从而提升效率；&lt;/p&gt;
&lt;h2 id=&#34;makefile&#34;&gt;makefile&lt;/h2&gt;
&lt;h3 id=&#34;makefile的基本语法&#34;&gt;makefile的基本语法&lt;/h3&gt;
&lt;p&gt;makefile主要由一条条如下的规则组成：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-makefile&#34; data-lang=&#34;makefile&#34;&gt;&lt;span class=&#34;nf&#34;&gt;target ... &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prerequisite&lt;/span&gt; ...
	&lt;span class=&#34;nb&#34;&gt;command&lt;/span&gt;
	...
	...
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意其中命令行前面是&lt;strong&gt;Tab&lt;/strong&gt;。
如果一条规则的目标属于以下情况之一，就称为需要更新：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;目标没有生成；&lt;/li&gt;
&lt;li&gt;某个条件需要更新；&lt;/li&gt;
&lt;li&gt;某个条件的修改时间比目标晚；&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;在一条规则被执行前，规则的条件可能处于以下三种状态之一：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;需要更新。能够找到以该条件为目标的规则，且该规则中目标需要更新；&lt;/li&gt;
&lt;li&gt;不需要更新。能够找到以该条件为目标的规则，但是该规则中目标不需要更新；或者不能找到以该条件为目标的规则且该条件已经生成；&lt;/li&gt;
&lt;li&gt;错误。不能找到以该条件为目标的规则，并且该条件没有生成；&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;执行一条规则A的步骤如下&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;检查它的每个条件P：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;如果P需要更新，则执行以P为目标的规则B。之后无论是否生成文件P都认为P已经被更新；&lt;/li&gt;
&lt;li&gt;如果找不到规则B，并且文件P已经存在，则表示P不需要更新；&lt;/li&gt;
&lt;li&gt;如果找不到规则B，并且文件P不存在，则报错退出；&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;检查完A的所有条件后，检查它的目标T，如果属于一下情况之一，就执行命令列表：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;文件T不存在；&lt;/li&gt;
&lt;li&gt;文件T存在，但是某个条件的修改时间比它晚；&lt;/li&gt;
&lt;li&gt;某个条件P已将被更新（并不一定生成文件P，只要执行了命令列表就视为已经更新）；&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;在shell中通过以下命令执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ make &lt;span class=&#34;c1&#34;&gt;# 从缺省目标开始更新，即makefile中第一条规则的目标&lt;/span&gt;
$ make target &lt;span class=&#34;c1&#34;&gt;# 更新target这个目标&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;变量&#34;&gt;变量&lt;/h3&gt;
&lt;p&gt;makefile可以用‘=’定义变量和&#39;$&amp;lsquo;读取变量的值：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-makefile&#34; data-lang=&#34;makefile&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; gcc &lt;span class=&#34;c1&#34;&gt;# 定义变量CC，值是gcc&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 取出CC的值
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;$ CC &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;= &lt;span class=&#34;n&#34;&gt;gcc&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 读到$(CC)时立刻展开
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;?=&lt;/span&gt; gcc &lt;span class=&#34;c1&#34;&gt;# CC没有定义过则等同&amp;#39;=&amp;#39;，否则什么也不做&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; gcc &lt;span class=&#34;c1&#34;&gt;# CC可以追加定义&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;makefile中还有一些特殊变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-makefile&#34; data-lang=&#34;makefile&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$@&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 表示规则中的目标
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$&amp;lt;&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 表示规则中的第一个条件
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$?&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 表示规则中所有比目标新的条件，组成一个列表，以空格分隔
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$^&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 表示规则中所有的条件，组成一个列表，以空格分隔
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;makefile中的隐含变量，有的变量已经定义了缺省值：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-makefile&#34; data-lang=&#34;makefile&#34;&gt;&lt;span class=&#34;err&#34;&gt;AR&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;静态库打包命令，缺省值ar&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;ARFLAGS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;静态库打包命令的选型，缺省值rv&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;AS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;汇编器的名字，缺省值as&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;ASFLAGS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;汇编器的选项，没有定义&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;CC&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;C编译器的名字，缺省值是cc&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;CFLAGS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;C编译器的选项，没有定义&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;CXX&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;C++编译器的名字，缺省值是g++&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;CXXFLAGS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;C++编译器的选项，没有定义&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;CPP&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;C预处理器的名字，缺省值是&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;-E&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;CPPFLAGS&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;C预处理器的选项，没有定义&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;LD&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;链接器的名字，缺省值是ld&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;OUTPUT_OPTION&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;输出的命令行选项，缺省值是-o&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$@&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;RM&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;删除命令的名字，缺省值是rm&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;-f&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;常用make命令选项&#34;&gt;常用make命令选项&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-makefile&#34; data-lang=&#34;makefile&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;make&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;-n&lt;/span&gt; 
&lt;span class=&#34;c&#34;&gt;# 打印要执行的命令而不执行
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 这个命令可以用于查看命令的执行顺序，确认无误了再执行命令
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;make&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;-C&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;# 可以切换到另一个目录执行makefile
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;例子&#34;&gt;例子&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-makefile&#34; data-lang=&#34;makefile&#34;&gt;&lt;span class=&#34;c&#34;&gt;# A sample Makefile
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# This Makefile demonstrates and explains 
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Make Macros, Macro Expansions,
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Rules, Targets, Dependencies, Commands, Goals
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Artificial Targets, Pattern Rule, Dependency Rule.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;c&#34;&gt;# Comments start with a # and go to the end of the line.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;c&#34;&gt;# Here is a simple Make Macro.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;LINK_TARGET&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; test_me.exe

&lt;span class=&#34;c&#34;&gt;# Here is a Make Macro that uses the backslash to extend to multiple lines.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;OBJS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;  &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; Test1.o &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; Test2.o &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; Main.o

&lt;span class=&#34;c&#34;&gt;# Here is a Make Macro defined by two Macro Expansions.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# A Macro Expansion may be treated as a textual replacement of the Make Macro.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Macro Expansions are introduced with $ and enclosed in (parentheses).
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;REBUILDABLES&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;OBJS&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;LINK_TARGET&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c&#34;&gt;# Here is a simple Rule (used for &amp;#34;cleaning&amp;#34; your build environment).
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# It has a Target named &amp;#34;clean&amp;#34; (left of the colon &amp;#34;:&amp;#34; on the first line),
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# no Dependencies (right of the colon),
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# and two Commands (indented by tabs on the lines that follow).
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The space before the colon is not required but added here for clarity.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;clean &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; 
  rm -f &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;REBUILDABLES&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
  &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; Clean &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;

&lt;span class=&#34;c&#34;&gt;# There are two standard Targets your Makefile should probably have:
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# &amp;#34;all&amp;#34; and &amp;#34;clean&amp;#34;, because they are often command-line Goals.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Also, these are both typically Artificial Targets, because they don&amp;#39;t typically
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# correspond to real files named &amp;#34;all&amp;#34; or &amp;#34;clean&amp;#34;.  
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;c&#34;&gt;# The rule for &amp;#34;all&amp;#34; is used to incrementally build your system.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# It does this by expressing a dependency on the results of that system,
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# which in turn have their own rules and dependencies.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;all &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;LINK_TARGET&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
  &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; All &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;

&lt;span class=&#34;c&#34;&gt;# There is no required order to the list of rules as they appear in the Makefile.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Make will build its own dependency tree and only execute each rule only once
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# its dependencies&amp;#39; rules have been executed successfully.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;c&#34;&gt;# Here is a Rule that uses some built-in Make Macros in its command:
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# $@ expands to the rule&amp;#39;s target, in this case &amp;#34;test_me.exe&amp;#34;.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# $^ expands to the rule&amp;#39;s dependencies, in this case the three files
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# main.o, test1.o, and  test2.o.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;$(LINK_TARGET) &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;OBJS&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
  g++ -g -o &lt;span class=&#34;nv&#34;&gt;$@&lt;/span&gt; $^

&lt;span class=&#34;c&#34;&gt;# Here is a Pattern Rule, often used for compile-line.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# It says how to create a file with a .o suffix, given a file with a .cpp suffix.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The rule&amp;#39;s command uses some built-in Make Macros:
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# $@ for the pattern-matched target
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# $&amp;lt; for the pattern-matched dependency
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;%.o &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; %.&lt;span class=&#34;n&#34;&gt;cpp&lt;/span&gt;
  g++ -g -o &lt;span class=&#34;nv&#34;&gt;$@&lt;/span&gt; -c $&amp;lt;

&lt;span class=&#34;c&#34;&gt;# These are Dependency Rules, which are rules without any command.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Dependency Rules indicate that if any file to the right of the colon changes,
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# the target to the left of the colon should be considered out-of-date.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The commands for making an out-of-date target up-to-date may be found elsewhere
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# (in this case, by the Pattern Rule above).
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Dependency Rules are often used to capture header file dependencies.
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Main.o &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Main&lt;/span&gt;.&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Test&lt;/span&gt;1.&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Test&lt;/span&gt;2.&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;Test1.o &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Test&lt;/span&gt;1.&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Test&lt;/span&gt;2.&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;Test2.o &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Test&lt;/span&gt;2.&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;

&lt;span class=&#34;c&#34;&gt;# Alternatively to manually capturing dependencies, several automated
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# dependency generators exist.  Here is one possibility (commented out)...
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# %.dep : %.cpp
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#   g++ -M $(FLAGS) $&amp;lt; &amp;gt; $@
&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# include $(OBJS:.o=.dep)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://akaedu.github.io/book/index.html&#34;&gt;Linux C编程一站式学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.gnu.org/software/make/manual/make.html#Wildcards&#34;&gt;GNU make tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www3.ntu.edu.sg/home/ehchua/programming/cpp/gcc_make.html&#34;&gt;GCC and Make Compiling, Linking and BuildingC/C++ Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://prateekvjoshi.com/2014/02/01/cmake-vs-make/&#34;&gt;CMake VS Make&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
                
                
                
                
                
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/categories/computer-science/">Computer Science</category>
                                
                            
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/c/">C</category>
                                
                            
                                
                                
                                
                                    <category domain="https://zchencn.github.io/tags/make-file/">Make File</category>
                                
                            
                        
                    
                
            </item>
        
    </channel>
</rss>
