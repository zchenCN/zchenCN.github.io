[{"categories":["其他","“古代汉语”"],"content":"用词委婉  簠簋（音辅轨）不饰：“簠簋”是两种盛黍稷稻粱的礼器，字面意思是“盛祭品的器皿不修饰”，用来指高级官员有贪污行为，是对做官不廉正者的一种婉转的说法； 帷薄不修：“帷薄”指帷幕和帘子，引申指男女合欢，是家门淫乱的讳语； 采薪之忧：“采薪”即砍柴，指身患疾病,不能外出打柴。作为婉称有病而无法亲赴之辞；  用典故  箕山之节：相传尧访贤禅让天下，在箕山附近访得许由，尧让其治天下，许由以为是一种羞辱而不肯接受，遁耕于箕山之下。用来指隐居不仕的节操； 结草：出自《左传》，晋将魏颗不以父亲爱妾殉葬而让她改嫁，妾父的鬼魂在一次战斗中结草绊倒秦将，使魏颗获胜。用来指受人大恩,死后也要报答； 请缨：出自《汉书·终军转》，“军自请,愿受长缨,必羁南越王而致之阙下。” 比喻主动请求担当重任；  ","tags":["古代汉语"],"title":"古文笔记","uri":"/post/%E5%8F%A4%E6%96%87%E7%AC%94%E8%AE%B0/"},{"categories":["Math"],"content":"The derivative of trace or determinant with respect to the matrix is vital when calculating the derivate of lagrangian in matrix optimization problems and finding the maximum likelihood estimation of multivariate gaussian distribution.\nMatrix-Valued Derivative Let $f$ be a scaler function of a matrix $X \\in \\mathbb{R}^{n\\times n}$, the derivative of it with respect to $X$ can be defined as following $$ \\left(\\frac{\\partial f}{\\partial X}\\right)_{ij} = \\frac{\\partial f}{\\partial X_{ij}} $$ That is to say, the derivative is a matrix, the element of which is the derivative with respect to the element of matrix $X$.\nDerivative of Trace Now, let $f$ be the trace of $X$ $$ f(X) = tr(X) = \\sum_{i}X_{ii} $$ Then, it’s easy to find that $$ \\frac{\\partial f}{\\partial X_{ii}} = 1 $$ We can write in the matrix form $$ \\frac{\\partial tr(X)}{\\partial X} = I $$ Moreover, $$ f(X) = tr(AXB) = \\sum_{ijk}A_{ij}X_{jk}B_{ki} $$ Then $$ \\frac{\\partial f}{\\partial X_{jk}} = \\sum_{i}A_{ij}B_{ki} = (BA)_{kj} = (A^TB^T)_{jk} $$ So that $$ \\frac{\\partial tr(AXB)}{\\partial X} = A^TB^T $$ Similarly, if $f$ be the trace of square of the matrix, then $$ f(X) = tr(X^2) = \\sum_{i}(X^2)_{ii} = \\sum_{ik}X_{ik}X_{ki} = \\sum_{i}X^2_{ii} + \\sum_{k\u003ei}2X_{ik}X_{ki} $$ so $$ \\frac{\\partial tr(X^2)}{\\partial X_{ik}} = 2X_{ki} $$ Thus, we have $$ \\frac{\\partial tr(X^2)}{\\partial X} = 2X^T $$\nDerivative of Determinant The determinant of a matrix is complicated to expressed as the summation of its elements, however, from the Laplace expansion, also known as cofactor expansion, we have $$ det(X) = \\sum_{j}(-1)^{i+j}X_{ij}M_{ij} $$ so $$ \\frac{\\partial det(X)}{\\partial X_{ij}} = (-1)^{i+j}M_{ij} = (adj(A)^T)_{ij} $$ where $adj(A)$ is the adjugate matrix of $A$, so $$ \\frac{\\partial det(X)}{\\partial X} = adj(A)^T = det(A^T)A^{-T} = det(A)A^{-T} $$\nMaximum Likelihood Estimation Given a data set ${x_1, x_2, \\cdots, x_n}$ sampled from a multivariate Gaussian distribution. We want to estimate the parameters of the distribution via maximum likelihood.\nThe probability density function of multivariate Gaussian distribution is $$ f(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}e^{\\frac{-(x-\\mu)\\Sigma^{-1}(x-\\mu)^T}{2}} $$ We form the log likelihood function by taking the logarithm of product of $n$ Gaussian distributions: $$ l(x; \\mu, \\Sigma) = -\\frac{nd}{2}\\log{2\\pi} - \\frac{n}{2}\\log{|\\Sigma|} - \\frac{1}{2}\\prod_{i=1}^n(x_i-\\mu)\\Sigma^{-1}(x_i-\\mu)^T $$ We need to take the derivative with respect to $\\Sigma$ an set to zero.\nAs previously mentioned, $$ \\frac{\\partial \\log{|\\Sigma|}}{\\partial \\Sigma^{-1}} = \\frac{1}{|\\Sigma|}\\frac{\\partial |\\Sigma|}{\\partial \\Sigma^{-1}} = \\frac{1}{|\\Sigma|}\\frac{\\partial}{\\partial \\Sigma^{-1}}\\frac{1}{|\\Sigma^{-1}|} = -\\Sigma^T $$ and $$ \\frac{\\partial x\\Sigma x^T}{\\partial \\Sigma} = \\frac{\\partial tr( x\\Sigma x^T)}{\\partial \\Sigma} = \\frac{\\partial tr( xx^T\\Sigma)}{\\partial \\Sigma} = (xx^T)^T=xx^T $$ so $$ \\frac{\\partial l}{\\partial \\Sigma^{-1}} = \\frac{n}{2}\\Sigma^T - \\frac{1}{2}\\prod_{i=1}^n(x_i-\\mu)(x_i-\\mu)^T $$ Finally, setting to zero yield the maximum likelihood estimator: $$ \\Sigma_{ML} = \\frac{1}{n}\\prod_{i=1}^n(x_i-\\mu)(x_i-\\mu)^T $$\nReference  Matrix Calculus - Notes on the Derivative of a Trace Laplace expansion - Wikipedia Adjugate matrix - Wikipedia The Multivariate Gaussian  ","tags":["MLE","Derivative"],"title":"Derivative of Trace and Determinant","uri":"/post/derivativetracedeterminant/"},{"categories":["Math","PDE"],"content":"利用分离变量法可以求解具有齐次边界条件的齐次波动方程、热传导方程和拉普拉斯方程。接下来我们讨论如何处理非齐次方程和非齐次边界条件的情况。我们将介绍齐次化原理和本征函数法两种方法用来求解带有齐次边界条件的非齐次方程，再介绍通过构造辅助函数的方法将非齐次边界条件的问题，转化为求解非齐次方程的问题。\n齐次化原理 先考虑非齐次方程的情况。我们可以使用齐次化原理求解。回忆微积分课程中学过的积分微商定理，设 $$ U(x) = \\int_a^xf(x, \\tau)d\\tau $$ $a$ 是一个常数，则有 $$ \\frac{d}{dx}U(x) = f(x, x) + \\int_a^x\\frac{\\partial }{\\partial x}f(x, \\tau)d\\tau $$ 考虑以下无界弦的强迫振动的定界问题 $$ \\begin{equation} \\begin{cases} \\frac{\\partial^2u}{\\partial t^2} = a^2\\frac{\\partial^2u}{\\partial x^2} + f(x, t), \\quad -\\infty\u003cx\u003c\\infty, t\u003e0\\ u(x, 0) = \\frac{\\partial}{\\partial t}u(x, 0) = 0, \\quad -\\infty \u003c x \u003c \\infty \\end{cases} \\end{equation} $$ 设 $\\Omega(x, t, \\tau)$ 是如下齐次方程的解 $$ \\begin{equation} \\begin{cases} \\frac{\\partial^2\\Omega}{\\partial t^2} = a^2\\frac{\\partial^2\\Omega}{\\partial x^2}, \\quad -\\infty\u003cx\u003c\\infty, t\u003e\\tau\\ \\Omega(x, \\tau) =0, \\frac{\\partial}{\\partial t}\\Omega(x, \\tau) = f(x, \\tau), \\quad -\\infty \u003c x \u003c \\infty \\end{cases} \\end{equation} $$\n令 $$ u(x, t) = \\int_0^t\\Omega(x, t, \\tau)d\\tau $$ 则首先容易发现 $$ u(x, 0) = \\int_0^0\\Omega(x, t, \\tau)d\\tau = 0 $$ 利用前面的引理和 $\\Omega$ 方程的初始条件可以验证 $$ \\frac{\\partial u}{\\partial t}(x, 0) = \\Omega(x, t, t) + \\left[\\int_0^t\\frac{\\partial}{\\partial t}\\Omega(x, t, \\tau)d\\tau\\right]{t=0} = 0 $$ 最后对上式在求一次时间的导数，同样有 $$ \\begin{equation} \\begin{aligned} \\frac{\\partial^2u}{\\partial t^2} \u0026= \\left[\\frac{\\partial \\Omega}{\\partial t}(x, t, \\tau)\\right]{\\tau=t} + \\int_0^t\\frac{\\partial^2}{\\partial t^2}\\Omega(x, t, \\tau)d\\tau\\ \u0026= f(x, t) + \\int_0^ta^2\\frac{\\partial^2}{\\partial x^2}\\Omega(x, t, \\tau)d\\tau\\ \u0026= f(x, t) + a^2\\frac{\\partial^2}{\\partial x^2}\\int_0^t\\Omega(x, t, \\tau)d\\tau\\ \u0026= f(x, t) + a^2\\frac{\\partial^2}{\\partial x^2}u(x, t) \\end{aligned} \\end{equation} $$ 也即 $u$ 是原来非齐次方程的解。以上就是所谓齐次化原理，也叫冲量原理或者Duhamel’s Principle.\n本征函数法 第二种要介绍的方法是本征函数法。利用分离变量法需要使用叠加原理，这要求方程必须是齐次的且有齐次边界条件。在处理非齐次方程时，直接根据齐次的边界条件选取本征值写出级数形式的解，再利用方程和初始条件来确定技术展开中的系数，这种方法就是本征函数法。考虑两端固定的弦振动问题 $$ \\begin{equation} \\begin{cases} \\frac{\\partial^2u}{\\partial t^2} = a^2\\frac{\\partial^2u}{\\partial x^2} + f(x, t), \\quad 0\u003cx\u003cl, t\u003e0\\ u(x, 0) = \\frac{\\partial}{\\partial t}u(x, 0) = 0, \\quad 0 \u003c x \u003c l\\ u(0, t) = u(l, t) = 0 \\end{cases} \\end{equation} $$ 本征函数集由对应齐次方程和边界条件给出，所以容易知道对应级数形式的解为 $$ u(x,t) = \\sum_{n\\geq 1}g_n(t)\\sin\\frac{n\\pi}{l}x $$\n其中 $$ g_n(t) = \\frac{2}{l}\\int_0^lu(x, t)\\sin\\frac{n\\pi}{l}xdx $$ 所以容易有 $$ g_n(0) = g^{'}_n(0) = 0 $$\n带入方程得到 $$ \\sum_{t\\geq1}\\left[g^{''}n(t) + \\left(\\frac{na\\pi}{l}\\right)^2g_n(t)\\right]\\sin\\frac{n\\pi}{l}x = f(x, t) $$ 对 $f$ 做半幅傅里叶级数展开 $$ f(x, t) = \\sum{t\\geq 1}f_n(t)\\sin\\frac{n\\pi}{l}x\\ f_n(t) = \\frac{2}{l}\\int_0^lf(x, t)\\sin\\frac{n\\pi}{l}xdx $$ 对比可得关于 $g_n(t)$ 的二阶常系数非齐次微分方程 $$ g^{''}_n + \\left(\\frac{na\\pi}{l}\\right)^2g_n - f_n(t) = 0 $$ 两边对时间作拉普拉斯变换 $$ p^2G_n(p) + \\left(\\frac{na\\pi}{l}\\right)^2G_n(p) - F_n(p) = 0 $$ 得到 $$ G_n(p) = \\frac{F_n(p)}{p^2 + \\left(\\frac{na\\pi}{l}\\right)^2} $$ 利用拉普拉斯变换卷积的性质和平移性质以及 $\\sin t$ 的拉普拉斯变化，容易看出 $$ g_n(t) = \\frac{l}{na\\pi}\\int_0^tf_n(\\tau)\\sin \\frac{na\\pi}{l}(t-\\tau)d\\tau $$ 代入级数展开我们就得到了原非齐次方程的解。\n非齐次边界条件 以上处理的都是齐次边界的情况，接下来考虑方程有如下非齐次边界条件 $$ u(0, t) = \\alpha(t), \\quad u(l, t) = \\beta(t) $$ 引入辅助函数 $$ \\gamma(x, t) = (1 - \\frac{x}{l})\\alpha(t) + \\frac{x}{l}\\beta(t) $$ 设 $$ v(x, t) = u(x, t) - \\gamma(x, t) $$ 那么容易验证 $v$ 满足齐次边界条件且 $$ \\begin{aligned} \\frac{\\partial^2v}{\\partial t^2} - a^2\\frac{\\partial^2v}{\\partial x^2} \u0026= \\frac{\\partial^2u}{\\partial t^2} - \\frac{\\partial^2\\gamma}{\\partial t^2} - a^2\\left(\\frac{\\partial^2u}{\\partial x^2}-\\frac{\\partial^2\\gamma}{\\partial x^2}\\right)\\ \u0026= f(x, t) - \\frac{\\partial^2\\gamma}{\\partial t^2} + a^2\\frac{\\partial^2\\gamma}{\\partial x^2} \\end{aligned} $$ 这样我们把非齐次边界问题转化为了带齐次边界条件的非齐次方程的问题，前面我们已经介绍过了。\n","tags":["Math","PDE"],"title":"Methods to Solve Nonhomogeneous PDE problems","uri":"/post/nonhomogeneous/"},{"categories":["Machine Learning"],"content":"Apart from the parameters that will be adjusted during the process of training, there exits some parameters, that are not learned and have to be configured by ourselves in advance. These parameters are also referred to as hyper-parameters which have immense impact on the final results. Given a set of hyper-parameters, we have to assess our final trained machine learning model while testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting.\nOne way to overcome this problem is to not use the entire data set when training a learner. Some of the data is removed before training begins. Then when training is done, the data that was removed can be used to test the performance of the learned model on new data. This is the basic idea for a whole class of model evaluation methods called cross validation which allows us to compare different machine learning models and get a sense of how well they will work in practice. The best parameters can be determined by grid search.\nHoldout Method The holdout method is the simplest kind of cross validation. The data set is separated into two sets, called the training set and the testing set. The training process using the training set only., then the model is asked to predict the output values for the data in the testing set that never seen before. The errors on the testing data set is used to evaluate the model. The advantage of this method is that it is usually preferable to the residual method and takes no longer to compute. However, its evaluation can have a high variance. The evaluation may depend heavily on which data points end up in the training set and which end up in the test set, and thus the evaluation may be significantly different depending on how the division is made.\nK-fold Cross Validation K-fold cross validation is one way to improve over the holdout method. The data set is divided into k subsets, and the holdout method is repeated k times. Each time, one of the k subsets is used as the test set and the other k-1 subsets are put together to form a training set. Then the average error across all k trials is computed. The advantage of this method is that it matters less how the data gets divided. Every data point gets to be in a test set exactly once, and gets to be in a training set k-1 times. The variance of the resulting estimate is reduced as k is increased. The disadvantage of this method is that the training algorithm has to be rerun from scratch k times, which means it takes k times as much computation to make an evaluation. A variant of this method is to randomly divide the data into a test and training set k different times. The advantage of doing this is that you can independently choose how large each test set is and how many trials you average over.\nLeave-one-out Cross Validation leave-one-out cross validation is K-fold cross validation taken to its logical extreme, with K equal to N, the number of data points in the set. That means that N separate times, the model is trained on all the data except for one point and a prediction is made for that point. As before the average error is computed and used to evaluate the model. The evaluation given by leave-one-out cross validation error is good, but at first pass it seems very expensive to compute.\nReference  Cross Validation (cmu.edu) 3.1. Cross-validation: evaluating estimator performance — scikit-learn 1.0.1 documentation Cross-validation (statistics) - Wikipedia  ","tags":["Model Selection","Machine Learning","Cross Validation"],"title":"CrossValidation","uri":"/post/crossvalidation/"},{"categories":["Machine Learning","Regression"],"content":"Mathematic model We assume a sample $x$ has n features $x_i(i = 1, 2, \\cdots, n),$ and the goal is to minimize the cost funtion: $$J_{\\theta} = \\frac{1}{2m}\\sum_{i=1}^{m}[\\theta_0+\\theta_1x_1^{(i)}+\\cdots+\\theta_nx_n^{(i)}-y^{(i)}]^2$$ $m$ is the number of sample, the supscript $i$ represent the $i-th$ sample, $y^{(i)}$ is the label of each sample and $\\theta=(\\theta_0, \\theta_1, \\cdots, \\theta_n)^T$ is the parameter of cost function $J$.\nGradient desent Algorithm   Step1: Choose a start point $\\theta$; Step2: Take a step to the direction of minus gradient with the step size of $\\alpha$, i.e $\\theta_{new} = \\theta_{old} - \\alpha\\nabla J$; Step3: Repeat step2 until $J_{\\theta}(x)$ is samll enough;   Data preprocessing To accelerate the speed of convergence, some preprocessing can be applied the data set.\n  Feature scaling: $\\frac{x_i}{r},$ $r = x_i^{max}-x_i^{min}$ is the range value of feature $i$; Mean normalization: $x_i-\\mu_i, \\mu_i$ is the mean value of feature $i$;   Learning rate We call the step size $\\alpha$ learnig rate.\n  If $\\alpha$ is too large, the cost function may not decrease on every iteration, and the algorithm may not converge; If $\\alpha$ is too small, the algorithm may converge slowly;   Feature and polynomial regression We can create the new feature from the existing feature, for example $x_i^n$. Then it become a polynomial regression problem, but we can solve it by the same methods of linear regression.\nNormal equation Matrix form The problem can be expressed in the matrix form, let $x=(x_0,x_1,\\cdots,x_n)^T,\\ x_0=1,\\ X^T=(x^{(1)},x^{(2)},\\cdots,x^{(n)}),Y=(y^{(1)},y^{(2)},\\cdots,y^{(n)})^T,$ then: $$J_{\\theta}=\\frac{1}{2m}||X\\theta-Y||^2=\\frac{1}{2m}(X\\theta-Y)^T(X\\theta-Y)$$ $||\\cdot||$ is the Euclidean norm, the problem become: $$\\min_{\\theta}J_{\\theta}$$ $J$ is a convex function, so the local minimum is also the unique global minimum, and the stationary point is the very global minimum: $$\\arg\\min_{\\theta}J_{\\theta}=(X^TX)^{-1}X^TY$$\nComparision If we use normal equation to solve regression problem, feature scaling is not necesssary, but when the data set is too large we tend to use gradient desent rather than solving normal equation.\nIf $X^TX$ is non-invertible we can delete some features, use pseudoinverse or use regulization which we will talk about later.\n","tags":["Regression"],"title":"Linear Regression","uri":"/post/linearregression/"},{"categories":["Math","Optimal Transport"],"content":"Optimal Transport Overview Optimal transportation (OT) problem was first study by Gaspard Monge in 1781: A worker with a shovel in hand want to move a large pile of sand lying on a construction site and wish to minimize her total effort. OT arouse the interest of mathematicians because it can compare two probability distribution. OT has been rediscovered in many settings and under different forms, giving it a rich history. Kantorovich in 1940s established its significance to logistics and economics. Dantzig solved it numerically in 1949 within the framework of linear programming, giving OT a firm footing in optimization. In recent years, thanks to the emergence of approximate solvers that can scale to large problem dimension, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), graphics (for shape manipulation) or machine learning (for regression, classification and generative modeling).\nWe mainly focus on the numerical aspect of OT, for more theoretical detail, please reference the work of Villani.\nMonge Problem We say $\\textbf{a}$ is an histogram or probability vector if it belongs to the probability simplex: $$ \\Sigma_n = \\left{\\textbf{a}\\in\\mathbb{R}^n_+: \\sum_{i=1}^na_i = 1\\right} $$ That is to say, the elements of $\\textbf{a}$ is nonnegative and the sum of them is one. A discrete measure with weights $\\textbf{a}$ and locations $x_1, x_2, \\cdots, x_n$ reads: $$ \\alpha = \\sum_{i=1}^na_i\\delta_{x_i} $$ where $\\delta_x$ is the Dirac at position $x$ intuitively a unit of mass which is infinitely concentrated at location $x$. For discrete measure: $$ \\alpha = \\sum_{i=1}^na_i\\delta_{x_i}\\quad \\text{and}\\quad\\beta = \\sum_{i=1}^mb_i\\delta_{y_i} $$ the Monge problem seeks a map the associates to each point $x_i$ a single point $y_i$ and which must push the mass of $\\alpha$ toward the mass of $\\beta$, namely, such a map $T:{x_1, \\cdots, x_n} \\rightarrow {y_1, \\cdots, y_m}$ must verify that: $$ \\forall j \\in {1, 2, \\cdots, m}, b_j = \\sum_{T(x_i)=y_j}a_i $$ which we write in compact form as: $$ T_{\\sharp}\\alpha = \\beta $$ Given a cost function $c(x, y)$, the Monge problem is to find the map that minimize the total cost of the transportation: $$ \\min_T\\left{\\sum_{i}c(x_i, T(x_i)): T_{\\sharp}\\alpha=\\beta\\right} $$ Monge maps may not even exist between a discrete measure to another.\nKantorovich Relaxation The key idea of Kantorovich is to relax the deterministic nature of transportation, namely the fact that a source point $x_i$ can only be assigned to another point or location $T(x_i)$ only. Kantorovich proposed instead that the mass at any point $x_i$ be potentially dispatched across several locations. This flexibility is encoded using a coupling matrix $P \\in \\mathbb{R}^{n\\times m}+$, where $P{ij}$ describes the amount of mass flowing from bin $i$ to bin $j$. Admissible couplings admit a simple characterization that: $$ U(\\textbf{a}, \\textbf{b}) = \\left{P\\in\\mathbb{R}^{n\\times m}+: \\sum_jP{ij}=a_i, \\sum_iP_{ij}=b_j\\right} $$ The set of matrices $U(\\textbf{a}, \\textbf{b})$ is bounded and defined by $n+m$ equality constraints, and therefore is a convex polytope.\nGiven a cost matrix $C$, Kantorovich’s OT problem now reads: $$ L_C(\\textbf{a}, \\textbf{b}) = \\min_{P\\in U(\\textbf{a}, \\textbf{b})}\\left\u003cP, C\\right\u003e = \\sum_{i,j}C_{ij}P_{ij} $$ This is a linear program and as is usually the case with such programs, its optimal solutions are not necessarily unique.\nWasserstein Distance An import feature if OT is that it defines a distance between histograms and probability measures as soon as the cost matrix satisfies certain suitable properties. We suppose $n=m$ and that for some $p\\geq 1$, $C = D^p$ where $D\\in \\mathbb{R}^{n\\times n}_+$ is a distance matrix, that is to say $D$ satisfy following properties:\n  $D$ is symmetric\n  $D_{ij} = 0$ if and only if $i=j$\n  $\\forall i, j, k, D_{ik} \\leq D_{ij} + D_{jk}$\n  Then we can define so-called Wasserstein distance on probability simplex $\\Sigma_n$, $$ W_p(\\textbf{a}, \\textbf{b}) = L_{D^p}(\\textbf{a}, \\textbf{b})^{1/p} $$\nEntropic Regularization We will introduce a family of numerical schemes to approximate solutions to Kantorovich formulation of OT. It operates by adding an entropic regularization to the original problem. The minimization of the regularized problem can be solved by using a simple alternate minimization scheme which are iterations of simple matrix-vector products. The resulting approximate distance is smooth with respect to input histogram weights and can be differentiated using automatic differentiation.\nThe discrete entropy of the coupling matrix is defined as: $$ H(P) = -\\sum_{i, j}P_{ij}(\\log(P_{ij})-1) $$ The idea of the entropic regularization of OT is to use $-H$ as a regularization function to obtain approximate solutions to the origin Kantorovich OT problem: $$ L^{\\epsilon}C(\\textbf{a}, \\textbf{b}) = \\min{P\\in U(\\textbf{a, \\textbf{b}})}\\left\u003cP, C\\right\u003e - \\epsilon H(P) $$ Since the objective is an $\\epsilon-strongly$ convex function, the problem mentioned above has a unique optimal solution.\nIt has been proved that: $$ L^{\\epsilon}_C(\\textbf{a}, \\textbf{b})\\stackrel{\\epsilon\\rightarrow0}{\\longrightarrow}L_C(\\textbf{a}, \\textbf{b}) $$\nSinkhorn’s Algorithm Let $K$ denote the Gibbs kernel associated to the cost matrix $C$ as: $$ K_{ij} = e^{-\\frac{C_{ij}}{\\epsilon}} $$ The solution of the regularized OT problem has the form: $$ P_{ij} = u_iK_{ij}v_j $$ for two (unknow) scaling variable $(\\textbf{u}, \\textbf{v}) \\in \\mathbb{R}^n_+\\times\\mathbb{R}^m_+$.\nThe factorization of the optimal solution can be conveniently rewritten in matrix form as: $$ P = diag(\\textbf{u})Kdiag(\\textbf{v}) $$ The scaling variables must therefore satisfy the following nonlinear equations which correspond to the mass conservation constraints inherent to $U(\\textbf{a}, \\textbf{b})$: $$ \\textbf{u}\\odot(K\\textbf{v}) = \\textbf{a}, \\quad \\textbf{v}\\odot(K^T\\textbf{u}) = \\textbf{b} $$ where $\\odot$ corresponds to entrywise multiplication of vectors. That problem is known as matrix scaling problem which can be solved iteratively by modifying first $\\textbf{u}$ so that it satisfies the left-hand side of above equations and then $\\textbf{v}$ to satisfy its right-hand side. These two updates define Sinkhorn’s algorithm: $$ \\textbf{u}^{(l+1)} = \\frac{\\textbf{a}}{K\\textbf{v}^(l)}, \\quad \\textbf{v}^{(l+1)} = \\frac{\\textbf{b}}{K^T\\textbf{u}^{(l+1)}} $$ initialized with an arbitrary positive vector $\\textbf{v}^{(0)} = \\mathbb{1}_m$. The division operator used above between two vectors is to be understood entrywise.\nIn order to speed up the Sinkhorn’s iterations, we can compute several regularized Wasserstein distances between pairs of histograms simultaneously. Let $N$ be an integer, $\\textbf{a}_1, \\cdots, \\textbf{a}_N$ be histograms in $\\Sigma_n$, and $\\textbf{b}_1, \\cdots, \\textbf{b}_N$ be histograms in $\\Sigma_m$. We seek to compute all $N$ approximate distances $L_C^{\\epsilon}(\\textbf{a}_1, \\textbf{b}_1), \\cdots, L_C^{\\epsilon}(\\textbf{a}_N, \\textbf{b}_N).$ In that case, writing $A = [\\textbf{a}_1, \\cdots, \\textbf{a}_N]$ and $B = [\\textbf{b}_1, \\cdots, \\textbf{b}N]$ for the $n\\times N$ and $m\\times N$ matrices storing all histograms, one can notice that all Sinkhorn iterations for all these $N$ pairs can be carried out in parallel, by setting, for instance, $$ \\textbf{U}^{(l+1)} = \\frac{\\textbf{A}}{K\\textbf{V}^(l)}, \\quad \\textbf{V}^{(l+1)} = \\frac{\\textbf{B}}{K^T\\textbf{U}^{(l+1)}} $$ initialized with $\\textbf{V}^{(0)} = \\mathbb{1}{m\\times N}.$\nLog-domain Stabilized Sinkhorn The Sinkhorn algorithm suffers from numerical overflow when the regularization parameter $\\epsilon$ is small compared to the entries of the cost matrix $C$. This concern can be alleviated to some extent be carrying out computations in log domain.\nReferences  Computational Optimal Transport  ","tags":["Optimal Transport","Machine Learning"],"title":"An Introduction to Optimal Transport","uri":"/post/sinkhorn/"},{"categories":["Machine Learning"],"content":"在监督学习中，我们使用特定的算法在给定的带标记的训练集 $D={(x_i, y_i)}_{i=1}^N$ 上训练得到一个模型 $f(x; D)$ . 泛化能力是评价一个模型好坏的重要标准，我们希望得到的模型能够在它没有见过的输入 $x$ 上有更准确的预测能力. 在模型训练时，我们总是通过特定的算法去减小训练误差，但是在实践中我们发现，更小的训练误差并不就意味着更小的泛化误差，往往随着训练误差的减小，泛化误差呈现一个先下降后上升的趋势，我们称之为过拟合.\nBias 和 Variance 能够帮助我们去理解模型的泛化能力. 给定测试样本 $x$ ，令 $y_{D}$ 为 $x$ 在训练集中的标记，$y$ 为真实标记，则学习算法的期望预测为 $$ \\bar{f}(x) = E_{D}[f(x; D)] $$\nWhat Is Bias? Bias 是衡量模型与真实标记偏差的量，数学上如下定义 $$ bias^2 = (\\bar{f}(x)-y)^2 $$ 通常，一个简单模型的 $bias$ 会比复杂模型的大。比如在多项式回归中，极端地，我们使用0次多项式也即常数作为模型，那么它的输出和真实标记的偏差显然比我们使用高次多项式作为模型得到的偏差要大，因为总是存在一个 $N-1$ 次多项式能够完全拟合给定的 $N$ 个数据点.\nWhat Is Variance? Variance 是衡量训练集扰动对模型产生的影响的量，数学定义如下 $$ variance = E_{D}[(f(x; D)-\\bar{f}(x))^2] $$ 高的 Variance 说明当训练集发生扰动时，训练得到的模型会有很大的改变，也就是说鲁棒性比较差，这是我们不希望看到的，因为训练集的标记总是和真实标记之间存在误差。通常，一个简单模型的 Variance 会比复杂模型的小。同样以上文中多项式回归为例子，用常数作为模型无论训练集的输入如何变化得到的最终模型都不会改变，但是扰动对高次多项式的影响是较大的。\nDecomposition 假设训练集标记和真实标记之间的误差的期望为0，方差为 $\\epsilon^2$ ，即 $$ E_{D}[y-y_D] = 0, E_{D}[(y-y_D)^2] = \\epsilon^2 $$ 我们对期望泛化误差可以作如下分解 $$ \\begin{align} E_D[(f(x; D) - y_D)^2] \u0026= E_D[(f(x; D) -\\bar{f}(x) + \\bar{f}(x)- y_D)^2]\\\\ \u0026= E_D[(f(x; D)-\\bar{f}(x))^2] + E_D[(\\bar{f}(x)-y+y-y_D)^2] + 2E_D[(f(x; D)-\\bar{f}(x))(\\bar{f}(x)-y_D)]\\\\ \u0026= variance + E_D[(\\bar{f}(x)-y)^2] + E_D[(y-y_D)^2] + 2E_D[(\\bar{f}(x)-y)(y-y_D)]\\\\ \u0026= variance + bias^2 + \\epsilon^2 \\end{align} $$\n也就是说，泛化误差可以分解为偏差、方差与噪声之和. 噪声刻画了泛化误差的下界，反应了学习问题本身的难度.\nTrade-off 监督学习的希望得到一个 bias 和 Variance 都较低的模型，但是一般来说，这两者是冲突的。在训练不足时，模型的拟合能力不足，训练数据扰动不足以对模型产生显著影响，此时 bias 主导了泛化误差；随着训练程度的加深，模型的拟合能力逐渐增强，训练数据的扰动能够被算法学习到，发生了过拟合，此时 Variance 主导了泛化误差. 我们需要在这两者中找到一个好的平衡点，使得得到的模型效果足够令人满意.\nReference   《机器学习》，周志华，清华大学出版社\n  [Gentle Introduction to the Bias-Variance Trade-Off in Machine Learning (machinelearningmastery.com)](https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/#:~:text=Bias is the simplifying assumptions,the bias and the variance.)\n  What Is the Difference Between Bias and Variance? (mastersindatascience.org)\n  Bias–variance tradeoff - Wikipedia\n  ","tags":["Machine Learning"],"title":"Bias and Variance","uri":"/post/variancebias/"},{"categories":["Computer Science","Programming Language","Python"],"content":"Python 是一门面向对象语言，Python 中包括内置类型在内的一切都是对象。Python 对象分为可变对象(Mutable Object)和不可变对象(Immutable Object).\nID and Type Python 中的对象再被实例化时会被分配一个与内存位置相关的id, 可以用内置的id()函数查看对象的id, 用type()函数查看对象的类型。\n1 2 3 4 5  \u003e\u003e\u003e a = 5 \u003e\u003e\u003e id(a) 140279384729648 \u003e\u003e\u003e type(a) \u003cclass 'int'\u003e   Mutable and Immutable Python 的内置类型也分为可变和不可变两种：\n mutable: int float complex sting tuple immutable: list set dict  看一段代码：\n1 2 3 4 5 6 7 8 9  \u003e\u003e\u003e x = 10 \u003e\u003e\u003e y = x \u003e\u003e\u003e id(x) == id(y) True \u003e\u003e\u003e id(y) == id(10) True \u003e\u003e\u003e x = x + 1 \u003e\u003e\u003e id(x) == id(y) False   首先，我们在内存中创建了一个类型为int, 值为10的对象，并把它赋给变量x （或者说给这个对象起了一个名字x）， 再把变量x表示的对象与y绑定（或者说起了一个别名y）. 所以x, y, 10 的id是相同的。然后， 因为int是不可变对象，x + 1会创建一个值为11 类型为 int 的新对象，再把这个新对象重新与 x 绑定，此时 y 还是 10 这个对象，所以 x, y 的id不相等。\n再看下面一段代买：\n1 2 3 4 5 6 7 8  \u003e\u003e\u003e l1 = ['a', 'b', 'c'] \u003e\u003e\u003e l2 = l1 \u003e\u003e\u003e id(l1) == id(l2) True \u003e\u003e\u003e l1.pop() 'c' \u003e\u003e\u003e id(l1) == id(l2) \u003e\u003e\u003e True   同样我们创建一个对象并把它赋给两个变量 l1, 12, 由于 list 是可变对象， pop 可以直接改变它的状态，并不用重新创建一个新的 'list' 对象，所以 l1, l2 的id还是相同的。\n但是，不可变对象的不可变不是绝对的，看下面一个例子：\n1 2 3 4  \u003e\u003e\u003e t = ('abcd', [0, 1, 2]) \u003e\u003e\u003e t[0].append(3) \u003e\u003e\u003e t ('abcd', [0, 1, 2, 3])   我们首先创建了一个 tuple 对象，在 Python 中， tuple 是不可变对象，它的第二个成员是一个可变的 list 对象， 我们改变了这个 list 对象，从内容上看，tuple 被改变了，但是它仍然绑定的是创建时的那个 string 和 list ，从这个角度看，它是没有被改变的。\nCustom Class 用户自定义的类默认是可变的.\nPassed to Function 不严谨地说，传递可变对象类似引用传递(Call by Reference), 传递不可变对象类似值传递(Call by Value).\n1 2 3 4 5 6 7 8 9 10 11 12 13  def func1(l): l.append(3) l = [0, 1, 2] func(l) print(l) # [0, 1, 2, 3] def func(i): i += 3 i = 5 func2(i) print(i) # 5   ","tags":["Python"],"title":"Mutable and Immutable Objects in Python","uri":"/post/mutableandimmutableobjects/"},{"categories":["Math"],"content":"一元函数、多元函数和泛函的导数相关概念。以下均假设导数存在。\n一元函数 $f:\\mathbb{R} \\rightarrow \\mathbb{R}$ 是实数域上的一元函数，函数在某点的导数是函数值在该点关于自变量的变化率，定义如下： $$ \\frac{df(x)}{dx} = \\lim_{h\\to0}\\frac{f(x + h) - f(x)}{h} \\tag{1} $$ 上式极限存在称函数 $f$ 在 $x$ 处可导，相应的可以定义映射$f^{'}:x \\mapsto \\frac{df(x)}{dx}$ 称 $f$ 的导函数，一般记为 $f^{'}(x)$ .\n多元函数 $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ 是定义在 $n$ 维欧氏空间上的函数。\n偏导数 对于多变量函数，如果我们固定除某一个变量外的其他变量，此时它可以看作一个单变量函数，此时该函数关于未固定这个变量的导数，就是多元函数的偏导数： $$ \\frac{\\partial f(x_1, x_2, \\cdots, x_n )}{\\partial x_k} = \\lim_{h\\to0}\\frac{f(x_1, \\cdots, x_k + h, \\cdots, x_n) - f(x_1, \\cdots, x_k, \\cdots, x_n)}{h} $$\n梯度 假设 $f$ 在 $\\mathbf{p}$ 点的偏导数都存在，则可以定义它在该点的梯度向量： $$ grad f(\\mathbf{p}) = \\nabla f(\\mathbf{p}) = \\begin{bmatrix} \\frac{\\partial f(\\mathbf{p})}{\\partial x_1}\\ \\frac{\\partial f(\\mathbf{p})}{\\partial x_2}\\ \\vdots \\ \\frac{\\partial f(\\mathbf{p})}{\\partial x_n} \\end{bmatrix} $$ $\\nabla f: \\mathbf{R}^n \\rightarrow \\mathbf{R}^n, \\mathbf{p} \\mapsto \\nabla f(\\mathbf{p})$ 是函数 $f$ 的梯度场。\n方向导数 为了衡量多变量函数在某点沿着某个方向的变化率，可以引入方向导数的概念，$f$ 在 $\\mathbf{x}$ 点沿 $ \\mathbf{p}$ 方向的方向导数为： $$ \\nabla_{\\mathbf{v}}f(\\mathbf{x}) = \\lim_{h\\to0}\\frac{f(\\mathbf{x} + h\\mathbf{v}) -f(\\mathbf{x})}{h} $$ 特别地，偏导数可以看作函数沿 $\\mathbf{e_k}$ 方向的方向导数： $$ \\nabla_{\\mathbf{e_k}}f(\\mathbf{x}) = \\lim_{h\\to0}\\frac{f(\\mathbf{x} + h\\mathbf{e_k}) - f(\\mathbf{x})}{h} = \\lim_{h\\to0}\\frac{f(x_1, \\cdots, x_k + h, \\cdots, x_n) - f(x_1, \\cdots, x_k, \\cdots, x_n)}{h} = \\frac{\\partial f(\\mathbf{x})}{\\partial x_k} $$ 另外： $$ f(x_1 + h v_1, x_2 + hv_2) = f(x_1, x_2) + \\frac{\\partial f}{\\partial x_1}hv_1 + \\frac{\\partial f}{\\partial x_2}hv_2 + o(h) $$ 所以： $$ \\nabla_{\\mathbf{v}}f(x) = \\nabla f(\\mathbf{x})\\cdot \\mathbf{v} = \\nabla f(\\mathbf{x})^T\\mathbf{v} $$\n全微分 偏导数和方向导数衡量的都可以看作是函数沿着某一方向的近似，而全微分可以看作是函数在某点的最佳线性逼近，和方向无关： $$ f(\\mathbf{x} + \\mathbf{h}) = f(\\mathbf{x}) + df_{\\mathbf{x}}(\\mathbf{h}) + o(||\\mathbf{h}||) $$ $df_{\\mathbf{x}}: \\mathbb{R}^n \\rightarrow R$ 是 $f$ 在 $\\mathbf{x}$ 的线性全微分算子。\n另有： $$ 0 = \\lim_{t\\to 0}\\frac{f(\\mathbf{x} + t\\mathbf{h}) - f(\\mathbf{x}) - df_{\\mathbf{x}}(t\\mathbf{h})}{t} = \\nabla_{\\mathbf{h}}f(\\mathbf{x}) - df_{\\mathbf{x}}(\\mathbf{h}) $$ 即：$\\nabla_{\\mathbf{h}}f(\\mathbf{x}) = df_{\\mathbf{x}}(\\mathbf{h}) = \\nabla f(\\mathbf{x})^T\\mathbf{h}$.\n由希尔伯特空间上的Riesz表示定理， 存在 $\\mathbf{p_x} \\in \\mathbb{R}^n$ 使得： $$ df_{\\mathbf{x}}(\\mathbf{h}) = \\mathbf{p_x}^T\\mathbf{h} $$ 也即 $f$ 在该点的梯度，所以全微分可以看作是梯度的对偶。\nG导数 设 $F: U\\rightarrow R$ 是线性空间 $U$ 上的实泛函。从方向导数推广，可以定义泛函的G导数(Gateaux): $$ dF(u; v) = \\lim_{t \\to 0}\\frac{F(u + tv) - F(u)}{t} $$\nF导数 进一步假设 $U$ 是Banach空间，可以定义泛函的F导数(Frechet): $$ F(u + h) = F(u) + Df_u(h) + o(||h||) $$ $Df_u : U \\rightarrow R$\nF可导一定G可导，G可导不一定F可导。\n","tags":["Caculus","Derivatives"],"title":"Different Derivatives in Mathematics","uri":"/post/derivatives/"},{"categories":["Math"],"content":"Assume that all vectors are column vector, and we use numerator layout\nScalar-by-Vector $f$ is a scalar function of $\\mathbf{x}\\in \\mathbb{R}^n$, then the gradient vector of $f$ with respect to $\\mathbf{x}$ is: $$ \\frac{\\partial f}{\\partial \\mathbf{x}}=\\left[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\cdots, \\frac{\\partial f}{\\partial x_n} \\right] $$ then the gradient vector of f is: $$ \\nabla f = \\sum_{i=1}^n\\frac{\\partial f}{\\partial x_i}e_i = \\left(\\frac{\\partial f}{\\partial \\mathbf{x}}\\right)^T $$\nVector-by-Scalar $\\mathbf{y} \\in\\mathbb{R}^n$ is a n dimensional vector each component of which is a scalar function of x, then: $$ \\frac{\\partial \\mathbf{y}}{\\partial x} = \\left[\\frac{\\partial y_1}{\\partial x}, \\frac{\\partial y_2}{\\partial x}, \\cdots, \\frac{\\partial y_n}{\\partial x} \\right]^T $$\nVector-by-Vector $\\mathbf{y} \\in \\mathbb{R}^m$ is a vector of $\\mathbf{x} \\in \\mathbb{R}^n$ , the Jacobian matrix of it is a m-by-n matrix: $$ \\begin{equation} \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\left[\\nabla y_1, \\nabla y_2, \\cdots, \\nabla y_m \\right]^T = \\begin{bmatrix} \\frac{\\partial y_1}{\\partial x_1} \u0026 \\frac{\\partial y_1}{\\partial x_2} \u0026 \\cdots \u0026 \\frac{\\partial y_1}{\\partial x_n} \\ \\frac{\\partial y_2}{\\partial x_1} \u0026 \\frac{\\partial y_2}{\\partial x_2} \u0026 \\cdots \u0026 \\frac{\\partial y_2}{\\partial x_n} \\ \\vdots\t\u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\ \\frac{\\partial y_m}{\\partial x_1} \u0026 \\frac{\\partial y_m}{\\partial x_2} \u0026 \\cdots \u0026 \\frac{\\partial y_m}{\\partial x_1} \\end{bmatrix} \\end{equation} $$ Let $\\mathbf{y} = \\mathbf{Ax}$ , $\\mathbf{A}$ is independent of $\\mathbf{x}$, then: $$ \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\frac{\\partial \\mathbf{Ax}}{\\partial \\mathbf{x}} = \\mathbf{A} $$ If $y = \\mathbf{x^TAx}$ , $$ \\frac{\\partial y}{\\partial \\mathbf{x}} = \\frac{\\partial \\mathbf{x^TAx}}{\\partial \\mathbf{x}} = \\frac{\\partial \\sum a_{ij}x_ix_j}{\\partial \\mathbf{x}} = \\left[\\sum a_{1j}x_j + \\sum a_{i1}x_i, \\sum a_{2j}x_j + \\sum a_{i2}x_i, \\cdots, \\sum a_{nj}x_j + \\sum a_{in}x_i\\right] = \\mathbf{x}^T(\\mathbf{A} + \\mathbf{A}^T) $$\nReferences  Wikipedia: Matrix Calculus\n ","tags":["Matrix Caculus"],"title":"Matric Caculus","uri":"/post/matriccaculus/"},{"categories":["Computer Science","Programming Language","C\u0026C++"],"content":"静态库和动态库 将频繁复用的程序打包成库文件，并在使用时链接到项目中可以有效的节省编译时间，避免频繁的复制，提高编程的效率。 常用有静态库(static library)和动态库(shared library or dynamic library). 程序的编译运行可分为下面四个步骤：\n 预编译；处理预编译指导语句，也就是程序中以#开头的行，如#include和#define等； 编译；将程序的源文件(.c)转化为目标文件(.o); 链接；将库和所有目标文件链接成可执行程序。对静态库来说，实际的文件被打包进了最终的可执行程序，然而动态库只是把标记放入的可执行程序； 装载；程序被装载程序(loader)装载后开始执行，所有动态库的标记都会被解析被映射到程序中；  动态库 编译和链接使用动态库有如下步骤：\nStep 1: Compiling with Position Independent Code 我们需要将库的源文件编译成位置独立的代码(PIC):\n1  gcc -c -Wall -Werror -fpic source_file.c   Step 2: Creating a shared library from an object file 将目标文件打包成动态库：\n1  gcc -shared -o libshared_lib_name.so source_file.o   Step 3: Linking with a shared library 经过前两步我们已经有了一个动态库了。现在main.c文件需要使用动态库，我们使用-L选项告诉编译器库所在的目录，并用-l选型指定库的名字：\n1  gcc -Wall -L directory_of_library -o test main.c -lshared_lib_name   Step 4: Making the library available at runtime 然而此时执行程序还是会报错：\nerror while loading shared libraries: shared_lib_name.so: cannot open shared object file: No such file or directory 有两种方法解决这个问题，一种是将库目录加到LD_LIBRARY_PATH变量中：\n1  export LD_LIBRARY_PATH=directory_of_library:$LD_LIBRARY_PATH   一种是在编译链接时加上：\n-Wl,-rpath=directory_of_library -Wl是将后面的参数传给链接器的意思，“,”用来处理参数中的空格。\n","tags":["Static Library","Dynamic Link Library"],"title":"Static Library and Dynamic Link Library","uri":"/post/staticlibanddynamiclib/"},{"categories":["Math","PDE"],"content":"Free-space simulation happens in many problems and especially in wave-structure interactions. The key question is how to perform spatial truncation without introducing significant artifacts into the computation when solving the PDE numerically. Various techniques, such as “radiating boundary”, “matched layer” and “one-way approximation of the wave equation”， have been used in computer code. In 1994, Berenger invented a new technique as PML technique to tackle this issue, he put a layer of artificial absorbing material around the grid to absorb the outgoing wave.\nWave Equation Acoustic wave equation has the following form: $$ \\begin{cases} \\frac{\\partial v}{\\partial t} = -\\frac{1}{\\rho}\\nabla p\\ \\frac{\\partial p}{\\partial t} = -\\kappa\\nabla \\cdot v \\end{cases} $$ In two dimensional case, it can be written as: $$ \\frac{\\partial^2 p}{\\partial t^2} = c^2\\nabla^2p = c^2\\left(\\frac{\\partial^2 p}{\\partial x^2}+\\frac{\\partial^2 p}{\\partial z^2}\\right) $$ We will numerically solve it to demonstrate some ideas in the following article. Code can be found here.\nNumerical Reflection Numerical reflection will pollute the solution if we simply truncate the grid with hard-wall(zero condition on the boundary).\nComplex Coordinate Stretching Consider a plane wave solution of the wave equation with the form: $$ w(x, t) = e^{i(kx - wt)} $$ The amplitude of it is invariant as it travel along the real axis: $$ ||w(x, t)|| = ||e^{i(kx-wt)}|| = 1 $$ Things change if we analytically continue it, evaluate the plane wave solution at complex values: $$ w(x, t) = e^{i(k(Rex + iImx)-wt)} = e^{-kImx}e^{i(kRex-wt)} $$ The amplitude decay exponentially as the growing of the imaginary part of x, while the solution is not changed out of the absorbing material. So, it not only acts like an absorbing material, but also like a reflectionless material.\nThe analytically continued solution satisfied the same differential equation. We assume the differential equation was x-invariant in this region, so x only appeared in derivative $\\frac{\\partial}{\\partial x}$ . The entire process of PML can be conceptually summed up by a single transformation of original differential equation: $$ \\frac{\\partial }{\\partial x} \\rightarrow \\frac{1}{s_x}\\frac{\\partial}{\\partial x}, s_x = 1 + i\\frac{\\sigma_x(x)}{w} $$\nReference  Notes on Perfectly Matched Layer  ","tags":["PDE"],"title":"An Introduction to Perfectly Matched Layer","uri":"/post/pml/"},{"categories":["Computer Science","Programming Language","C\u0026C++"],"content":"vector是c++的一个标准类模板，可以用来动态地存储相同类型的实例或基本类型。\n1 2  #inlucde \u003cvector\u003e // Include the header file using std::vector // Using declaration   vector是模板(template)不是具体的类(class)，在使用时，应该声明具体对象的类型：\n1  vector\u003cint\u003e v; // Declare a vector v for int   因为引用不是具体的对象，所以不能定义由引用组成的vector。特别地，可以定义成员是vector的vector:\n1 2  vector\u003cvector\u003cT\u003e\u003e\t// T is a type vector\u003cvector\u003cT\u003e \u003e // Some compile require a space before closing angle bracket   初始化 c++提供了不同的构造函数用来初始化vector:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  vector\u003cT\u003e v1; // Default initialization, v1 is empty  vector\u003cT\u003e v2(v1); // Copy construction, v2 has a copy of each element of v1  vector\u003cT\u003e v2 = v1;\t// Equivalent to vector\u003cT\u003e v2(v1)  vector\u003cT\u003e v3(n, val); // v3 has n elements with value val  vector\u003cT\u003e v4(n); // If T is a primitive type, v4 has n default value of T; \t// If T is a class, v4 has n objects initialize by default constructor  vector\u003cT\u003e v5{a, b, c...}; // v5 has the element created by the corresponding initializers  vector\u003cT\u003e v5 = {a, b, c...}; // Equivalent to vector\u003cT\u003e v5{a, b, c...}   容量 1 2 3 4 5 6 7 8  v.empty(); // Return if the vector is empty, bool type  v.size(); // Return the number of objects in vector, not necessary equal to the capacity  v.capacity(); // Return the size of storage currently allocated for the vector, capacity is equal to or great than size \t// When the capacity is exhausted, it will reallocate memory and copy the current objects  v.reserve(n); // Reserve the capacity to be at least enpugh to contain n objects   访问 同数组(raw array)类似，可以通过方括号和指标访问vector的成员，它返回对该成员的引用，需要注意的一点是，这种方式并不会进行边界检测(bound-check)，可能会导致未定义行为，at方法的作用是相同的，但是会进行边界检测，若出界，则会抛出一个异常：\n1 2 3 4 5  // v is a vector of T type v[n] // Return a reference to the element at position n, if n is  // out of range, it will causes undefined behavior  v.at(n) // The same as [] but it will check bounds   其他常用访问元素的操作包括：\n1 2 3  v.front // Return a reference to the first element of v, if v is empty, it will causes undefined behavior  v.back // Return a reference to the last element of v, if v is empty, it will causes undefined behavior   修改 通常，我们会初始化一个空的vector，然后向其中添加成员：\n1  v.push_back(val) // Add val to the end of v   这种方法会调用到拷贝构造函数，在v内存的相应位置复制一个新的对象。如果增加成员导致新的size超过原先的capacity，那么需要重新分配足够的内存并将原来的成员全都复制过去。另一种方法可以避免插入时拷贝构造函数的调用：\n1  v.emplace_back(arg1, arg2...); // Construct a element at the end of vector according to the args   1 2 3 4 5 6  v.pop_back() v.insert() v.eraser() v.swap() v.clear() v.emplace()   ","tags":["C++","STL"],"title":"Vector in STL","uri":"/post/vector/"},{"categories":["Math","Optimization"],"content":"约束优化问题(optimization problems)一般可以表示为如下形式： $$ \\min_{x\\in R^n} f(x)\\ s.t \\begin{cases} c_i(x) = 0, i\\in \\mathcal{E}\\ c_i(x) \\geq 0, i \\in \\mathcal{I} \\end{cases} $$ 定义如下集合为可行域： $$ \\Omega = {x|c_i(x) = 0, i \\in \\mathcal{E}; c_i(x) \\geq 0 , i\\in\\mathcal{I}} $$ 那么上述优化问题可以表示为： $$ \\min_{x\\in \\Omega}f(x) $$\n同无约束问题类似，可以引入如下几个定义：\n 称$;x^;$是全局最优解(global minimizer)如果$; f(x^)\\leq f(x),\\ \\forall x \\in \\Omega;$; 称$;x^;$是局部最优解(local minimizer)如果存在$;x^;$的一个领域$;\\mathcal{N};$使得$; f(x^*)\\leq f(x),\\ \\forall x \\in \\mathcal{N}\\cap\\Omega;$; 称$;x^;$是严格局部最优解(strict local minimizer)如果存在$;x^;$的一个领域$;\\mathcal{N};$使得$; f(x^)\u003c f(x),\\ \\forall x \\neq x^\\in \\mathcal{N}\\cap\\Omega;$; 称$;x^;$是孤立局部最优解(strict local minimizer)如果存在$;x^;$的一个领域$;\\mathcal{N};$使得$; x^*;$是该领域中的唯一局部最优解；  例子 等式约束 考虑如下等式约束问题： $$ \\min f(x_1, x_2) = x_1 + x_2, s.t \\quad c(x_1, x_2) = x_1^2 + x_2^2 - 2 = 0 $$ 显然它的最优解是$;x^* = (-1, -1);$, 可以计算目标函数和约束在最优解处的梯度，$;\\nabla f(x^) = (1, 1)^T, \\nabla c(x^) = (-2, -2) ;$， 可以发现这两个向量是平行的，也就是说存在$;\\lambda = \\frac{1}{2};$使得$;\\nabla f(x^) = -\\lambda \\nabla c(x^);$.\n对$;c(x+d);$作一阶近似： $$ c(x)\\approx c(x) + \\nabla c(x)^Td = \\nabla c(x)^Td $$ 若要使得$;x+d;$仍然在可行域内，$;c(x)^Td = 0;$. 同样对$;f(x+d);$作一阶近似： $$ f(x + d) = f(x) + \\nabla f(x)^Td $$ 若要使得函数值得到下降，要求$;\\nabla f(x)^Td \u003c 0;$. 若要$;x;$是最优解，则不存在$;d;$同时满足上述两个条件，那么只能是$;\\nabla f(x);$和$;\\nabla c(x);$平行。\n引入拉格朗日(Lagrange)函数： $$ L(x, \\lambda) = f(x) + \\lambda c(x) $$ 上述条件等价于要求存在$;\\lambda;$使得$\\nabla_x L(x^*, \\lambda) = 0$.\n不等式约束 考虑如下不等式约束问题： $$ \\min f(x_1, x_2) = x_1 + x_2, s.t \\quad c(x_1, x_2) = x_1^2 + x_2^2 - 2 \\leq 0 $$ 同样的，若要使得$;x + d;$的函数值得到下降，则： $$ \\nabla f(x)^Td \u003c 0 $$ 又要保持$;x+d;$在可行域内，则： $$ c(x) + \\nabla c(x)^Td \\leq 0 $$ 假如$;x;$在可行域的内部，即$;c(x) \u003c 0;$, 那么对任意一个向量，只要它的模足够小，都能使$;x+d;$在可行域内，取： $$ d = -\\alpha \\nabla f(x) $$ 要使得不存在这样的向量同时满足上述两个条件，只能是$;\\nabla f(x) = 0;$; 假如$;x;$在可行域的边界，即$;c(x) = 0;$, 那么第二个式子变成： $$ \\nabla c(x)^Td \\leq 0 $$ 同样的，要使两个条件不能同时满足，只能是$;\\nabla f(x) = -\\mu \\nabla c(x), \\mu \\geq 0;$.\n引入拉格朗日函数： $$ L(x, \\mu) = f(x) + c(x) $$ 上述条件等价于要求在最优解处： $$ \\nabla_x L(x^, \\mu) = 0, \\mu \\geq 0 $$ 且$;\\mu c(x^)=0;$,这个条件称为互补条件。\n约束限制 我们首先引入几个概念。\n 对可行域内一点$;x;$, 称$;\\mathcal{A}(x) = \\mathcal{E} \\cup {i\\in\\mathcal{I}, c_i(x) = 0 };$为积极集(active set)。也就是说在该点为0的约束是积极约束(active constraint)，非零的是非积极约束(inactive constraint).\n  我们称$;{z_k};$是一个逼近$;x;$的可行序列(feasible sequence)如果$;z_k \\in \\Omega;$且对充分大的$;k;$有$;k\\to x;$.\n  向量$;d;$ 是可行域$;\\Omega;$在$;x;$的切(tagent)如果存在一个逼近$;x;$的可行序列$;{z_k};$和一个逼近0的正实数序列$;t_k;$使得$;\\lim_{k\\to\\infty}\\frac{z_k-x}{t_k} = d;$. 记所有这样的向量$;d;$构成的集合为$;T_{\\Omega}(x);$, 它是一个锥($;d\\in T_{\\Omega}(x), \\Rightarrow\\alpha d \\in T_{\\Omega}(x), \\alpha \u003e 0;$), 称为切锥。\n 根据上面例子的演示，我们利用约束函数的一阶近似，来估计它在某点附近的行为，所以引进下面的线性可行方向集合(linearized feasible direction set): $$ \\mathcal{F(x)} = {d| \\nabla c_i(x)^Td = 0, i \\in \\mathcal{E}; \\nabla c_i(x)^Td \\geq 0, i\\in\\mathcal{A}\\cap \\mathcal {I}} $$ 同样容易验证, $;\\mathcal{F}(x);$也是一个锥。后面我们会证明，在某些特殊情况，$;\\mathcal{F}(x) = T_{\\Omega}(x);$.\n最后介绍一个约束限制条件，线性无关约束限制(Linearly Independent Constraint Qualification), 称LICQ成立如果${\\nabla c_i(x), i\\in\\mathcal{A}}$线性无关。\n一阶必要条件 对于一般的约束优化问题，我们称如下函数是它的拉格朗日函数： $$ L(x, \\lambda) = f(x) - \\sum_{i\\in \\mathcal{I}\\cup\\mathcal {E}}\\lambda_ic_i(x) $$ 一阶必要性条件又称KKT条件，它是很多约束优化问题算法的基础。如果$;x^;$是约束优化问题的局部最优解，且在该点处LICQ条件成立，$;f,c_i;$连续可微，那么存在拉格朗日乘子向量(Lagrange multiplier vector)$;\\lambda^ ;$使得： $$ \\begin{cases} \\nabla L(x^, \\lambda^) = 0\\ c_i(x^) = 0, i\\in\\mathcal{E}\\ c_i(x^) \\geq 0, i\\in\\mathcal{I}\\ \\lambda^_i\\geq 0, i\\in\\mathcal{I}\\ \\lambda^_ic_i(x^*) = 0, i\\in\\mathcal{E}\\cup\\mathcal{I} \\end{cases} $$ 其中最后一个条件称为互补条件，这意味着，非积极约束对应的拉格朗日乘子均为0。进一步的，如果对任意的约束和对应的拉格朗日乘子，一定有一个为0，我们称满足严格互补条件。\n下面我们简要概述一阶必要性条件的证明。\n","tags":["Math","Optimization"],"title":"An Introduction to Constrained Optimization Problems","uri":"/post/constrainedoptimization/"},{"categories":["Math","Optimization"],"content":"优化问题(optimization problems)一般可以表示为如下形式： $$ \\min_{x\\in R^n} f(x)\\ s.t \\begin{cases} c_i(x) = 0, i\\in \\mathcal{E}\\ c_i(x) \\geq 0, i \\in \\mathcal{I} \\end{cases} $$ 称$;f;$为目标函数(object function), $; x;$为决策变量(decision variable), $; c_i;$为约束函数(constraint function).\n凸性 称集合$; S;$是凸(convex)集，如果连接集合内任何两点的线段全都包含在该集合内，即： $$ \\forall x, y \\in S, \\alpha x + (1-\\alpha)y \\in S, \\forall \\alpha \\in [0, 1] $$ 称函数$; f;$是凸函数，如果它的定义域是凸集且对定义域内的任意两点$; x, y;$有如下性质： $$ f(\\alpha x + (1-\\alpha)y)\\leq \\alpha f(x) + (1-\\alpha)f(y), \\forall \\alpha \\in [0, 1] $$ 如果上述不等式在$; x\\neq y, \\alpha\\in(0, 1);$时严格成立，则称函数是严格凸(strictly convex)的。称函数是凹(concave)的，如果$; -f;$是凸的。\n接下来我们考虑无约束优化问题，即$;\\mathcal{I}=\\mathcal{E}=\\empty;$, $$ \\min_{x\\in R^n}\\ f(x) $$\n定解条件  称$;x^;$是全局最优解(global minimizer)如果$; f(x^)\\leq f(x),\\ \\forall x \\in R^n;$; 称$;x^;$是局部最优解(local minimizer)如果存在$;x^;$的一个领域$;\\mathcal{N};$使得$; f(x^*)\\leq f(x),\\ \\forall x \\in \\mathcal{N};$; 称$;x^;$是严格局部最优解(strict local minimizer)如果存在$;x^;$的一个领域$;\\mathcal{N};$使得$; f(x^)\u003c f(x),\\ \\forall x \\neq x^\\in \\mathcal{N};$; 称$;x^;$是孤立局部最优解(strict local minimizer)如果存在$;x^;$的一个领域$;\\mathcal{N};$使得$; x^*;$是该领域中的唯一局部最优解； 一般来说，要得到全局最优解是十分困难的，但是当目标函数$;f;$是凸函数时，可以证明局部最优就是全局最优。   （一阶必要性条件）如果$;x^;$是一个局部最优解，且$;f;$在$;x;$的一个开领域内连续可微，那么$;\\nabla f(x^) = 0;$.\n 假设$;\\nabla f(x^)\\neq 0;$,我们可以沿着负梯度方向，设为$;p;$, 找到一个的点有更小的函数值，由泰勒展开可得： $$ f(x^ + tp) = f(x^) + tp^T\\nabla f(x^ + \\overline{t}p), \\overline{t}\\in (0, t) $$ 而由于$;p = -\\nabla f(x^)$, $; p^T\\nabla f(x^) = - ||\\nabla f(x^)||^2_2 \u003c 0$，由连续可微的条件可知，我们可以选取足够小的$t;$，使得： $$ tp^T\\nabla f(x^ + \\overline{t}p) \u003c 0 $$ 此时$; f(x^* + tp) \u003c f(x^)$, 与$;x^;$是局部最优解矛盾。由此，我们证明了一阶必要性条件。\n我们称梯度为零的点为稳定点(stationary point), 那么由一阶必要性条件可知，局部最优解必定是稳定点。\n （二阶必要性条件）如果$;x^;$是一个局部最优解，且$;\\nabla^2 f(x^);$存在并且在$;x^;$的一个开领域内连续，那么$;\\nabla f(x^) = 0, \\nabla^2f(x^*)$半正定。\n 假如$;\\nabla^2 f(x^);$不是半正定的，则可以选取向量$;p;$使得： $$ p^T\\nabla^2 f(x^)p \u003c 0 $$ 对$;f(x^* + tp);$作泰勒展开： $$ f(x^* + tp) = f(x^) + tp^T\\nabla f(x^) + \\frac{t^2}{2}p^T\\nabla^2 f(x^* + \\overline{t}p)p, \\overline{t}\\in (0, t) $$ 同样的可以选取足够小的$t;$使得$;f(x^+tp)\u003cf(x^);$, 从而得到矛盾。\n特殊的，我们还可以导出一个充分条件。\n （二阶充分条件）假设$;\\nabla^2 f(x^);$在$;x^;$的一个开领域内连续且$;\\nabla f(x^) = 0;$以及$;\\nabla^2 f(x^);$正定，那么$;x^*;$是一个严格局部最优解。\n 同样的作泰勒展开： $$ f(x^* + p) = f(x^) + p^T\\nabla f(x^) + \\frac{1}{2}p^T\\nabla^2 f(z)p \u003e f(x^) $$ 注意，充分条件不是必要条件，也就是说存在$;x^;$是严格局部最优解但是不满足二阶充分条件的情况，比如$;f(x)=x^4, x^*=0.;$\n当$;f(x);$是凸函数时，局部最优解和全局最优解的刻画会变得很容易。\n 当$;f(x);$是凸函数时，局部最优解就是全局最优解。进一步，如果$;f(x);$是可微的，那么稳定点就是全局最优解。\n 假设$;x^;$不是全局最优解，那么存在$;z;$使得$;f(z) \u003c f(x);$, 取$;x = \\lambda z + (1 - \\lambda)x^, \\lambda \\in (0, 1);$, 那么由凸性： $$ f(x) = f(\\lambda z + (1 - \\lambda)x^) \u003c \\lambda f(z) + (1-\\lambda)f(x^) \u003c f(x^) $$ 对$;x^;$的任一个领域，都可以选取合适的$;\\lambda;$使得$;x;$在里面，这与$;x^;$是局部最优解矛盾。\n假如$;f(x);$是可微的，若稳定点$;x^;$不是全局最优解，那么： $$ \\begin{array}{ll} \\nabla f(x^)^T(z - x^) \u0026= \\frac{d}{d\\lambda}f(x^* + \\lambda (z - x^))|{\\lambda = 0}\\ \u0026= \\lim{\\lambda\\to 0}\\frac{f(x^ + \\lambda (z-x^)) - f(x^)}{\\lambda}\\ \u0026\u003c f(z) - f(x^) \u003c 0 \\end{array} $$ 这与$;\\nabla f(x^) = 0;$矛盾。\n因此，无约束凸优化问题全局最优解的充要条件就是$;\\nabla f(x^*) = 0;$。后续的算法，也是在寻找这样的稳定点。\n算法概述 通常我们用迭代法求解无约束优化问题。也就是说，算法需要一个初始点$;x_0;$，我们可以利用对问题的已知信息来得到一个解的估计作为初始点，或者任意选取。求解算法利用当前点或已求出点的信息，依次求出$;x_1, x_2, \\cdots,x_k,\\cdots;$从而得到一个对解的逼近序列，当$;k;$足够大时，$;x_k;$可以作为解的良好估计。\n通常的求解算法可以分为两类：线搜索方法和信赖域方法。\n线搜索 线搜索方法概括的说就是从当前点沿着某一个方向走一定的步长从而使得函数值降低（这个不一定每步都需要）得到新的点，即： $$ x_{k+1} = x_k + \\alpha_k p_k $$ 其中$;p_k;$称为搜索方向(search direction), $;\\alpha_k;$称为步长(step length). 如何选取搜索方向？最自然的选择就是当前点下降最快的方向，最速下降方向(steepest desent direction), 即$;p_k = -\\nabla f(x_k);$，且满足$;p_k^T\\nabla f(x_k) \u003c 0;$(称下降条件，满足该条件的称下降方向)，但是问题复杂时，最速下降方向的计算效率可能很低。其他通常的搜索方向选取还有牛顿方向$;p_k = -(\\nabla^2f(x_k))^{-1}\\nabla f(x_k) ;$和拟牛顿(quasi-Newton)方向$;p_k = -(B_k)^{-1}\\nabla f(x_k);$.\n信赖域 信赖域方法的基本思想是在当前点的附近用一个模型$;m_k(x);$来近似目标函数，求解的问题为： $$ \\min_{||p||\u003c\\Delta} m_k(x_k + p) = f(x_k) + \\nabla f(x_k)^Tp + \\frac{1}{2}p^TB_kp $$ 其中$;\\Delta;$称为信赖域半径，$;x_{k+1} = x_k + p;$. 当$;f(x_{k+1};$m没有使$;f;$产生充分的减小的话，我们认为模型对原目标函数近似的不是很好，从而应该缩小信赖域半径。当$;B_k = \\nabla^2 f(x_k);$时，称之为信赖域牛顿法。\n","tags":["Math","Optimization"],"title":"An Introduction to Unconstrained Optimization Problems","uri":"/post/unconstrainedoptimization/"},{"categories":["Math","Numerical Analysis","Numerical Quadrature"],"content":"谱元法简介 谱元法(Spectral Element Method)结合了谱方法的高精度性和有限元方法对于不规则求解区域的灵活性。\n谱元法的求解一般可以分为五个步骤：\n 将PDE改写成弱形式(Weak Form) 将求解区域分隔为若干个小的单元 用有限空间内的分片多项式函数近未知函数 代入弱形式并数值求解上述过程得到的积分得到单元上的矩阵表示 将矩阵拼装得到最后求解的线性方程组  下面用一个例子具体说明这些步骤。\n考虑如下赫姆霍兹方程(Helmholtz Equation)： $$ -\\nabla^2u + ku = f, x\\in \\Omega = [a, b] $$ 以及如下迪利克雷边界条件(Dirchlet Boundary Condition)： $$ u(a) = u(b) = 0 $$\n弱形式 设好的函数$v$同样满足迪利克雷边界条件，我们称它为测试函数(Test Function). 在方程两端同时乘上$v$并且在整个求解区域上做积分，运用分部积分公式可得： $$ \\int_a^b\\frac{\\partial u}{\\partial x}\\frac{\\partial v}{\\partial x} \\ dx + k\\int_a^buv \\ dx = \\int_a^b fv \\ dx $$ 可以证明，对任意测试函数都满足上式的$u$与原方程的解等价。\n严谨的证明参考有限元方法数学理论的相关书籍。\n剖分 将$\\Omega = [a, b]$剖分成$N_e$个小单元，$\\Omega = \\cup_{e=1}^{N_e}\\Omega_e, \\Omega_e = [X_{e-1}, X_e], X_0 = a, X_{N_e} = b.$ 为方便后续的讨论和求积分，建立一个标准单元（参考单元）到$\\Omega_e$的映射： $$ F^e: [-1, 1] \\longrightarrow \\Omega_e, x = F^e(\\xi) = \\frac{X_{e} - X_{e-1}}{2}\\xi + \\frac{X_e + X_{e-1}}{2} $$ 相反的有： $$ \\xi = (F^e)^{-1}(x) = \\frac{2x - X_e - X_{e-1}}{X_e - X_{e-1}} $$ 二维的情况类似, 其中$\\Omega_e$变成顶点为$P^e_1, P^e_2, P^e_3, P^e_4$(从左下按逆时针顺序编号)的四边形，同样的可以建立标准单元到$\\Omega_e$的映射： $$ F^e: [-1, 1]^2 \\longrightarrow \\Omega_e, F^e(\\xi, \\eta) = \\sum_{a=1}^4P^e_aN_a(\\xi, \\eta) $$ 其中： $$ N_1 = \\frac{1-\\xi}{2}\\cdot\\frac{1-\\eta}{2}, \\ N_2 = \\frac{1 + \\xi}{2}\\cdot\\frac{1 - \\eta}{2} \\ N_3 = \\frac{1 + \\xi}{2}\\cdot\\frac{1 + \\eta}{2}, \\ N_4 = \\frac{1 - \\xi}{2}\\cdot \\frac{1 + \\eta}{2} $$\n多项式近似 在每个单元上我们使用GLL(Gauss-Legendre-Labotto)求积公式节点的拉格朗日(Lagrange)多项式来近似函数。假设GLL点为$\\xi_0 = -1, \\xi_1, \\cdots, \\xi_n = 1$，则各个单元上的节点为： $$ x^e_i = F^e(\\xi_i), i=0,1, \\cdots,n $$ 记全局节点为： $$ x_I = x^e_i , I = I(e, i) = (e - 1)n + i $$ $I$可以取从$0$到$N_e\\times n$的所有整数，共$N_e\\times n + 1$个。 在每个单元上，我们有： $$ u(x) = u(x(\\xi)) = u(F^e(\\xi)) \\coloneqq u^e(\\xi) \\approx \\sum_{i=0}^nu^e_il_i(\\xi) = \\sum_{i=0}^nu^e_il_i((F^e)^{-1}(x)) \\coloneqq \\sum_{i=0}^nu^e_i\\phi^e_i $$ 其中： $$ u^e_i = u^e(\\xi_i) = u(F^e(\\xi_i)), \\phi_i^e(x) = l_i((F^e)^{-1}(x)) $$ 对于一阶导数，我们有:\n$$ \\frac{\\partial u}{\\partial x} \\approx \\sum_{i=0}^n u^e_i\\frac{\\partial \\phi^e_i}{\\partial x}$$\n对于二维的情况，我们选择的插值基函数是拉格朗日多项式的乘积，记： $$ \\phi_I(\\xi, \\eta) = l_i(\\xi)l_j(\\eta), I = i + j(n + 1) $$ 则在每个子区域上： $$ u(x, y) = u(F^e(\\xi, \\eta)) = u^e(\\xi, \\eta) \\approx \\sum_{i,j=0}^{1+n}u^e_{i,j}l_i(\\xi)l_j(\\eta) = \\sum_{I=0}^{(n+1)^2}u^e_I\\phi_I(\\xi, \\eta) = \\sum_{I=0}^{(n+1)^2}u^e_I\\phi_I^e(x, y) $$ 其中： $$ u^e_{i,j} = u^e(\\xi_i, \\eta_j) = u(F^e(\\xi_i, \\eta_j)), u^e_I = u^e_{i, j} \\ \\phi_I^e(x, y) = \\phi_I((F^e)^{-1}(x, y)), I = i + j(n + 1),\\ i,j = 0, 1, \\cdots, n $$ 对于偏导数：\n$$ \\frac{\\partial u}{\\partial x} \\approx \\sum_{I=0}^{(n+1)^2}u^e_I\\frac{\\partial \\phi^e_I}{\\partial x}, \\frac{\\partial u}{\\partial y} \\approx \\sum_{I=0}^{(1+n)^2}u^e_I\\frac{\\partial \\phi^e_I}{\\partial y} $$\n数值积分 在每个单元上, 选取测试函数为任意插值基函数，由方程的弱形式可以得到： $$ \\int_{\\Omega_e} u\\phi^e_j\\ dx \\approx \\sum_{i=0}^nu^e_i\\int_{\\Omega_e} \\phi^e_i\\phi^e_j\\ dx \\coloneqq \\sum_{i=0}^nM^e_{j ,i}u^e_i, \\forall j = 0, 1, \\cdots, n $$ 其中： $$ M^e_{j,i} = \\int_{\\Omega_e}\\phi^e_i\\phi^e_j\\ dx = \\int_{-1}^1l_i(\\xi)l_j(\\xi)\\frac{\\partial x}{\\partial \\xi}\\ d\\xi \\approx \\frac{L_e}{2}w_i\\delta_{j, i} $$ 所以单元质量矩阵(Mass Matrix)是一个对角矩阵。\n再考虑含有导数的部分： $$ \\int_{\\Omega_e}\\frac{\\partial u}{\\partial x}\\frac{\\partial \\phi^e_j}{\\partial x}\\ dx \\approx \\sum_{i=0}^nu^e_i\\int_{\\Omega_e}\\frac{\\partial \\phi^e_i}{\\partial x}\\frac{\\partial \\phi^e_j}{\\partial x}\\ dx \\coloneqq \\sum_{i=0}^nK^e_{j, i}u^e_i, \\forall j = 0, 1, \\cdots, n $$ 其中： $$ K^e_{j, i} = \\int_{\\Omega_e}\\frac{\\partial \\phi^e_i}{\\partial x}\\frac{\\partial \\phi^e_j}{\\partial x}\\ dx = \\int_{-1}^1\\left(\\frac{\\partial \\xi}{\\partial x}\\right)^2\\frac{\\partial l_i}{\\partial \\xi}\\frac{\\partial l_j}{\\partial \\xi}\\frac{\\partial x}{\\partial \\xi}\\ d\\xi = \\frac{2}{L_e}\\sum_{k=0}^nw_kd_{i,k}d_{j, k}\\ d_{i, k} = l'i(\\xi_k), d{j, k} = l_j'(\\xi_k) $$ 我们有： $$ K^e = \\left(\\frac{2}{L_e}\\right)^2DM^eD^t $$ 单元刚度矩阵(Stifness Matrix)$K^e$是对称矩阵。 最后，右端项： $$ f^e_j \\coloneqq \\int_{\\Omega_e}f\\phi^e_j\\ dx = \\frac{L_e}{2}\\int_{-1}^1f(F^e(\\xi))l_j(\\xi)\\ d\\xi \\approx \\frac{w_jL_e}{2}f(F^e(\\xi_j)) $$ 对于二维的情况： $$ \\int_{\\Omega_e}u\\phi^e_J\\ dS \\approx \\sum_{I=0}^{(1+n)^2}u^e_I\\int_{\\Omega_e}\\phi^e_I\\phi^e_J\\ dS = \\sum_{I=0}^{(1+n)^2}M^e_{J, I}u^e_I $$ 其中： $$ M^e_{J, I} = \\int_{\\Omega_e}\\phi^e_I\\phi^e_J\\ dS = \\int_{-1}^1\\int_{-1}^1\\phi_I\\phi_J J^e\\ d\\xi d\\eta = w_iw_jJ^e(\\xi_i, \\xi_j)\\delta_{I, J}, I = I(i, j) = J $$\n线性方程组 弱形式经过上面的近似和数值积分，得到： $$ \\sum_{e=1}^{N_e}\\sum_{i=0}^nK^e_{j,i}u^e_i + k\\sum_{e=1}^{N_e}\\sum_{i=0}^{n}M^e_{j,i}u^e_i = \\sum_{e=1}^{N_e}f^e_j $$ 全局质量矩阵： $$ M = \\sum_{e=1}^{Ne}M^e = \\begin{pmatrix} M^1_{0,0} \u0026 \u0026 \u0026 \\ \u0026 \\ddots \u0026 \u0026 \\ \u0026 \u0026 M^1_{n,n}+M^2_{0,0} \u0026 \\ \u0026 \u0026 \u0026 \\ddots\n\\end{pmatrix} $$ $M$是一个$n\\times N_e + 1$的方阵。\n全局刚度矩阵： $$ K = \\sum_{e=1}^{Ne}K^e = \\begin{pmatrix} K^1_{0,0} \u0026 \\cdots \u0026 K^1_{0, n} \u0026 \\ \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\ K^1_{n, 0} \u0026 \\cdots \u0026 M^1_{n,n}+M^2_{0,0} \u0026 \\ \u0026 \u0026 \u0026 \\ddots\n\\end{pmatrix} $$ 同样也是一个$n\\times N_e + 1$的方阵。\n则最终的线性方程组是： $$ (K +kM)\\underline{u} = \\underline{f} $$ 其中： $$ \\underline{u} = (u_0, u_1, \\cdots, u_{n\\times N_e + 1})^t \\ \\underline{f} = (f^1_0, \\cdots,f^1_n + f^2_0, \\cdots, f^{N_e}_n)^t $$\n二维的情况类似，这里就不再赘述。\n求解上述得到的线性方程组，就可以得到微分方程的数值解。\n","tags":["SEM","PDE"],"title":"SEM","uri":"/post/sem/"},{"categories":["Math","Numerical Analysis","Numerical Quadrature"],"content":"高斯求积 数值积分 考虑带权的积分如下： $$ \\int_a^bf(x)w(x)dx $$ 其中 $w(x) \\geq 0, \\int_a^bw(x)dx \u003e 0$，称$w(x)$为权。一般的数值积分公式有如下的形式： $$ \\int_a^bw(x)f(x)dx \\approx \\sum_{i=0}^nw_if(x_i) $$ 即用$n+1$ 个函数值的加权和来近似积分的值。\n我们记以$x_i(i=0,1,\\cdots,n)$ 为节点的拉格朗日(Langrange)插值多项式为： $$ L_n(x)=\\sum_{i=1}^nf(x_i)l_i(x) $$ 其中$l_i(x)$是拉格朗日插值基函数，即： $$ l_i(x) = \\frac{\\prod_{k=0,k\\neq i}^n(x-x_k)}{\\prod_{k=0,k\\neq i}^n(x_i-x_k)} $$ 则： $$ f(x)=L_n(x)+R[f],\\quad R[f]=\\frac{1}{(n+1)!}f^{(n+1)}(\\xi)(x-x_0)(x-x_1)\\cdots(x-x_n) $$\n有： $$ \\int_a^bw(x)f(x)dx=\\left(\\sum_{i=0}^n\\int_a^bw(x)l_i(x)dx\\right)f(x_i)+\\int_a^bw(x)R[f]dx $$\n一般我们取$w_i =\\int_a^bw(x)l_i(x)dx$ ，则数值积分公式的误差就是上式等号右侧的第二项，当$f(x)$ 是不超过$n$ 次的多项式时，容易看出误差为0。若数值积分公式对不超过$k$ 次的多项式精确成立，我们就称它的代数精度为$k$ 。所以上述数值积分公式的代数精度至少为$n$。\n另一方面，数值积分公式中含有$n+1$ 个$w_i$ 和$n+1$个$x_i$ ，共$2n+2$ 个自由度，所以可以想象通过适当选取节点$x_i$ ，它的代数精度最多可以为$2n+1$ 。我们把具有$2n+1$ 次代数精度的求积公式称为高斯求积公(GaussianQuadrature)，其节点$x_i(i=0,1,\\cdots,n)$ 称为高斯点。接下来讨论怎么选取合适的点作为高斯点。\n正交多项式与高斯点 称多项式$p(x), q(x)$ （带权）正交如果： $$ \\int_a^bw(x)p(x)q(x)dx=0 $$ 假设以$x_i(i=0,1,\\cdots,n)$ 为零点的多项式$p(x)=(x-x_0)(x-x_1)\\cdots(x-x_n)$ 与任何不超过$n$次的多项式正交，由多项式的带余除法可知，对于不超过$2n+1$次的多项式$f(x)$ ，有不超过$n$ 次的多项式$q(x), r(x)$ 使得： $$ f(x)=p(x)q(x)+r(x) $$ 那么： $$ \\int_a^bw(x)f(x)dx=\\int_a^bw(x)p(x)q(x)dx+\\int_a^bw(x)r(x)dx=\\int_a^bw(x)r(x)dx=\\sum_{i=0}^nw_ir(x_i) $$ 又： $$ f(x_i)=p(x_i)q(x_i)+r(x_i)=r(x_i) $$ 所以： $$ \\int_a^bw(x)f(x)dx=\\sum_{i=0}^nw_if(x_i) $$ 通过这种方式，我们发现只要选取节点为正交多项式的零点就可以得到高斯求积公式。\nGauss-Legendre 取$[a,b]=[-1,1],w(x)=1$，由${1,x,x^2,\\cdots}$ 正交化得到的多项式称为勒朗德(Legendre)多项式，一般记为$L_n(x)$ 。我们只要选取节点为$L_{n+1}(x)$ 的零点就可以得到高斯-勒朗德求积公式。\nGauss-Chebyshev 取$[a,b]=[-1,1],w(x)=\\frac{1}{\\sqrt{1-x^2}}$，由${1,x,x^2,\\cdots}$ 正交化得到的多项式称为切比雪夫(chebyshev)多项式，一般记为$T_n(x)$ 。我们只要选取节点为$T_{n+1}(x)$ 的零点就可以得到高斯-切比雪夫求积公式。\nGauss-Labotto 取$[a,b]=[-1,1]$ ，如果我们想在求积节点中包含两个区间端点，即固定$x_0=-1,x_n=1$，这种方式称为Gauss-Labotto求积。此时，自由度只有$2n$($n+1$个权和$n-1$节点)，可以想象至多达到$2n-1$阶代数精度。\n对任意2n-1次多项式$p_{2n-1}$，同样由多项式的带余除法可以得到： $$ p_{2n-1} - L_n= (1-x^2)(x-x_1)\\cdots(x-x_{n-1})q(x) + r(x), $$ 其中$q(x)\\in P_{n-2}, r(x)\\in P_n$，且$r(x_i) = 0(i = 0, 1, \\cdots,n)$，所以$r(x) \\equiv 0$，那么数值积分的误差项为： $$ E(x) = \\int_{-1}^1(1-x^2)(x-x_1)\\cdots(x-x_{n})q(x) $$ 我们选取$x_1, x_2, \\cdots, x_{n-1}$是$n-1$次Labotto多项式的零点，有$E(x)=0$.\n","tags":["Numerical Quadrature"],"title":"Gaussian Quadrature","uri":"/post/gaussianquadrature/"},{"categories":["Computer Science"],"content":"概述 make是控制如何从源文件(source file)生成可执行文件(excutable)及其他非源文件(non-source file)的一种工具。make工具通过makefile中说明的方式，构建(build)整个程序(program)。在一个庞大的项目中可能包含很多个源文件，修改少部分源文件可能需要重新编译整个程序，这个过程耗时耗力，通过使用make工具可以只重新编译依赖于修改过的文件的部分，从而提升效率；\nmakefile makefile的基本语法 makefile主要由一条条如下的规则组成：\n1 2 3 4  target ... : prerequisite ... command ... ...   注意其中命令行前面是Tab。 如果一条规则的目标属于以下情况之一，就称为需要更新：\n  目标没有生成； 某个条件需要更新； 某个条件的修改时间比目标晚；   在一条规则被执行前，规则的条件可能处于以下三种状态之一：\n  需要更新。能够找到以该条件为目标的规则，且该规则中目标需要更新； 不需要更新。能够找到以该条件为目标的规则，但是该规则中目标不需要更新；或者不能找到以该条件为目标的规则且该条件已经生成； 错误。不能找到以该条件为目标的规则，并且该条件没有生成；   执行一条规则A的步骤如下\n   检查它的每个条件P：\n  如果P需要更新，则执行以P为目标的规则B。之后无论是否生成文件P都认为P已经被更新； 如果找不到规则B，并且文件P已经存在，则表示P不需要更新； 如果找不到规则B，并且文件P不存在，则报错退出；     检查完A的所有条件后，检查它的目标T，如果属于一下情况之一，就执行命令列表：\n  文件T不存在； 文件T存在，但是某个条件的修改时间比它晚； 某个条件P已将被更新（并不一定生成文件P，只要执行了命令列表就视为已经更新）；      在shell中通过以下命令执行\n1 2  $ make # 从缺省目标开始更新，即makefile中第一条规则的目标 $ make target # 更新target这个目标   变量 makefile可以用‘=’定义变量和'$‘读取变量的值：\n1 2 3 4 5  $ CC = gcc # 定义变量CC，值是gcc $ $(CC) # 取出CC的值 $ CC := gcc # 读到$(CC)时立刻展开 $ CC ?= gcc # CC没有定义过则等同'='，否则什么也不做 $ CC += gcc # CC可以追加定义   makefile中还有一些特殊变量：\n1 2 3 4  $ $@ # 表示规则中的目标 $ $\u003c # 表示规则中的第一个条件 $ $? # 表示规则中所有比目标新的条件，组成一个列表，以空格分隔 $ $^ # 表示规则中所有的条件，组成一个列表，以空格分隔   makefile中的隐含变量，有的变量已经定义了缺省值：\n1 2 3 4 5 6 7 8 9 10 11 12 13  AR 静态库打包命令，缺省值ar ARFLAGS 静态库打包命令的选型，缺省值rv AS 汇编器的名字，缺省值as ASFLAGS 汇编器的选项，没有定义 CC C编译器的名字，缺省值是cc CFLAGS C编译器的选项，没有定义 CXX C++编译器的名字，缺省值是g++ CXXFLAGS C++编译器的选项，没有定义 CPP C预处理器的名字，缺省值是$(CC) -E CPPFLAGS C预处理器的选项，没有定义 LD 链接器的名字，缺省值是ld OUTPUT_OPTION 输出的命令行选项，缺省值是-o $@。 RM 删除命令的名字，缺省值是rm -f   常用make命令选项 1 2 3 4 5 6  $ make -n # 打印要执行的命令而不执行 # 这个命令可以用于查看命令的执行顺序，确认无误了再执行命令 $ make -C # 可以切换到另一个目录执行makefile    例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  # A sample Makefile # This Makefile demonstrates and explains # Make Macros, Macro Expansions, # Rules, Targets, Dependencies, Commands, Goals # Artificial Targets, Pattern Rule, Dependency Rule.  # Comments start with a # and go to the end of the line.  # Here is a simple Make Macro. LINK_TARGET = test_me.exe # Here is a Make Macro that uses the backslash to extend to multiple lines. OBJS = \\  Test1.o \\  Test2.o \\  Main.o # Here is a Make Macro defined by two Macro Expansions. # A Macro Expansion may be treated as a textual replacement of the Make Macro. # Macro Expansions are introduced with $ and enclosed in (parentheses). REBUILDABLES = $(OBJS) $(LINK_TARGET) # Here is a simple Rule (used for \"cleaning\" your build environment). # It has a Target named \"clean\" (left of the colon \":\" on the first line), # no Dependencies (right of the colon), # and two Commands (indented by tabs on the lines that follow). # The space before the colon is not required but added here for clarity. clean : rm -f $(REBUILDABLES) echo Clean done # There are two standard Targets your Makefile should probably have: # \"all\" and \"clean\", because they are often command-line Goals. # Also, these are both typically Artificial Targets, because they don't typically # correspond to real files named \"all\" or \"clean\".  # The rule for \"all\" is used to incrementally build your system. # It does this by expressing a dependency on the results of that system, # which in turn have their own rules and dependencies. all : $(LINK_TARGET) echo All done # There is no required order to the list of rules as they appear in the Makefile. # Make will build its own dependency tree and only execute each rule only once # its dependencies' rules have been executed successfully.  # Here is a Rule that uses some built-in Make Macros in its command: # $@ expands to the rule's target, in this case \"test_me.exe\". # $^ expands to the rule's dependencies, in this case the three files # main.o, test1.o, and test2.o. $(LINK_TARGET) : $(OBJS) g++ -g -o $@ $^ # Here is a Pattern Rule, often used for compile-line. # It says how to create a file with a .o suffix, given a file with a .cpp suffix. # The rule's command uses some built-in Make Macros: # $@ for the pattern-matched target # $\u003c for the pattern-matched dependency %.o : %.cpp g++ -g -o $@ -c $\u003c # These are Dependency Rules, which are rules without any command. # Dependency Rules indicate that if any file to the right of the colon changes, # the target to the left of the colon should be considered out-of-date. # The commands for making an out-of-date target up-to-date may be found elsewhere # (in this case, by the Pattern Rule above). # Dependency Rules are often used to capture header file dependencies. Main.o : Main.h Test1.h Test2.h Test1.o : Test1.h Test2.h Test2.o : Test2.h # Alternatively to manually capturing dependencies, several automated # dependency generators exist. Here is one possibility (commented out)... # %.dep : %.cpp # g++ -M $(FLAGS) $\u003c \u003e $@ # include $(OBJS:.o=.dep)   参考   Linux C编程一站式学习 GNU make tutorial GCC and Make Compiling, Linking and BuildingC/C++ Applications CMake VS Make   ","tags":["C","Make File"],"title":"An Introduction to Make","uri":"/post/makefiles/"}]
